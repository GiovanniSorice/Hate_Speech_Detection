{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AlBerto.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOmovmNLkyN//pG2jdFYuE9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "50d504e4b11d4b4ca13b78a3edf69c2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_43e556fded544525966f2727b1483f83",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e5c307c8cff5403c83729e014227905a",
              "IPY_MODEL_f5f98ac79408429388357367eb224751"
            ]
          }
        },
        "43e556fded544525966f2727b1483f83": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e5c307c8cff5403c83729e014227905a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b9dffaf6482d4bfdb52cff660b17aa7d",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 625,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 625,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fd376476e8594af687e7e3a3ff5100ca"
          }
        },
        "f5f98ac79408429388357367eb224751": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0231500bc8cd4605bea3064bba130365",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 625/625 [00:00&lt;00:00, 969B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d013c28e553946d089b0953162097ca7"
          }
        },
        "b9dffaf6482d4bfdb52cff660b17aa7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fd376476e8594af687e7e3a3ff5100ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0231500bc8cd4605bea3064bba130365": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d013c28e553946d089b0953162097ca7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3aa91d6acd6f4bd9bebc50ee77055f34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e944c7c7a8c84c04b0459b18067d56b6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4d120a393d074334838d9e545cd3d68c",
              "IPY_MODEL_3ab926188ed64fe693b73cc0bf47da1e"
            ]
          }
        },
        "e944c7c7a8c84c04b0459b18067d56b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4d120a393d074334838d9e545cd3d68c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_76986117f4b64cad9ad71135e4433523",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 740314266,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 740314266,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9ff651304e5c4091876761cb7e27f503"
          }
        },
        "3ab926188ed64fe693b73cc0bf47da1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_49be2a1606a1402bb447382eec415622",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 740M/740M [00:21&lt;00:00, 34.7MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_34213da1c8d243fa9916f3a8538805a5"
          }
        },
        "76986117f4b64cad9ad71135e4433523": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9ff651304e5c4091876761cb7e27f503": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "49be2a1606a1402bb447382eec415622": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "34213da1c8d243fa9916f3a8538805a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GiovanniSorice/Hate_Speech_Detection/blob/main/AlBerto.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCSPLoZGkjUY"
      },
      "source": [
        "# AlBERTo Hate Speech Classifier "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OymXBcAV-Uk_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52877095-668e-4040-e482-0b961ff2aebe"
      },
      "source": [
        "!pip install ekphrasis\n",
        "!pip install bert-tensorflow\n",
        "!pip install transformers==3.5\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import collections\n",
        "import logging\n",
        "import os\n",
        "import re\n",
        "import logger\n",
        "\n",
        "from ekphrasis.classes.preprocessor import TextPreProcessor\n",
        "from ekphrasis.classes.tokenizer import SocialTokenizer\n",
        "from ekphrasis.dicts.emoticons import emoticons\n",
        "from transformers import BertTokenizer, WordpieceTokenizer\n",
        "from transformers.tokenization_bert import load_vocab"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ekphrasis in /usr/local/lib/python3.7/dist-packages (0.5.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from ekphrasis) (3.2.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from ekphrasis) (3.2.2)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.7/dist-packages (from ekphrasis) (0.4.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from ekphrasis) (4.41.1)\n",
            "Requirement already satisfied: ujson in /usr/local/lib/python3.7/dist-packages (from ekphrasis) (4.0.2)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.7/dist-packages (from ekphrasis) (1.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from ekphrasis) (1.19.5)\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.7/dist-packages (from ekphrasis) (5.9)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk->ekphrasis) (1.15.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->ekphrasis) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->ekphrasis) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->ekphrasis) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->ekphrasis) (2.8.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from ftfy->ekphrasis) (0.2.5)\n",
            "Requirement already satisfied: bert-tensorflow in /usr/local/lib/python3.7/dist-packages (1.0.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from bert-tensorflow) (1.15.0)\n",
            "Requirement already satisfied: transformers==3.5 in /usr/local/lib/python3.7/dist-packages (3.5.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3.5) (1.19.5)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==3.5) (0.0.43)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3.5) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3.5) (4.41.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.5) (20.9)\n",
            "Requirement already satisfied: tokenizers==0.9.3 in /usr/local/lib/python3.7/dist-packages (from transformers==3.5) (0.9.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3.5) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.5) (3.0.12)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from transformers==3.5) (3.12.4)\n",
            "Requirement already satisfied: sentencepiece==0.1.91 in /usr/local/lib/python3.7/dist-packages (from transformers==3.5) (0.1.91)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.5) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.5) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.5) (7.1.2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.5) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.5) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.5) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.5) (2020.12.5)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3.5) (2.4.7)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf->transformers==3.5) (53.0.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FwrQH01T_nIS",
        "outputId": "6eaf4149-0466-48c5-ea37-1d784bc96017"
      },
      "source": [
        "from google.colab import drive\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WjePYBOyZZz"
      },
      "source": [
        "## Load the dataset "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ewn7ge0AB8n"
      },
      "source": [
        "# directory name \n",
        "input_dir = '/content/drive/My Drive/HLT/clean_dataset_training/' \n",
        "AlBERTo_path = '/content/drive/MyDrive/HLT/alberto_uncased_L-12_H-768_A-12_italian_ckpt/'\n",
        "\n",
        "# Spec\n",
        "pd.set_option(\"display.max_colwidth\", None)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJL3UvhtALOr"
      },
      "source": [
        "tsv_file = open(input_dir+\"training_dataset.csv\")\n",
        "\n",
        "dataset = pd.read_csv(tsv_file,sep=',')"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IpPTEKmmye2w"
      },
      "source": [
        "## Configure AlBERTo classes "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8b3NtZu48ZdG"
      },
      "source": [
        "class AlBERTo_Preprocessing(object):\n",
        "    def __init__(self, do_lower_case=True, **kwargs):\n",
        "        self.do_lower_case = do_lower_case\n",
        "\n",
        "    def preprocess(self, text):\n",
        "        if self.do_lower_case:\n",
        "            text = text.lower()\n",
        "        text = str(\" \".join(text_processor.pre_process_doc(text)))\n",
        "        text = re.sub(r'[^a-zA-ZÃ€-Ãº</>!?â™¥â™¡\\s\\U00010000-\\U0010ffff]', ' ', text)\n",
        "        text = re.sub(r'\\s+', ' ', text)\n",
        "        text = re.sub(r'(\\w)\\1{2,}', r'\\1\\1', text)\n",
        "        text = re.sub(r'^\\s', '', text)\n",
        "        text = re.sub(r'\\s$', '', text)\n",
        "        return text"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D9Zunxve8fBh"
      },
      "source": [
        "class CharacterTokenizer(object):\n",
        "    \"\"\"Runs Character tokenziation.\"\"\"\n",
        "\n",
        "    def __init__(self, vocab, unk_token,\n",
        "                 max_input_chars_per_word=100, with_markers=True):\n",
        "        \"\"\"Constructs a CharacterTokenizer.\n",
        "        Args:\n",
        "            vocab: Vocabulary object.\n",
        "            unk_token: A special symbol for out-of-vocabulary token.\n",
        "            with_markers: If True, \"#\" is appended to each output character except the\n",
        "                first one.\n",
        "        \"\"\"\n",
        "        self.vocab = vocab\n",
        "        self.unk_token = unk_token\n",
        "        self.max_input_chars_per_word = max_input_chars_per_word\n",
        "        self.with_markers = with_markers\n",
        "\n",
        "    def tokenize(self, text):\n",
        "        \"\"\"Tokenizes a piece of text into characters.\n",
        "        For example:\n",
        "            input = \"apple\"\n",
        "            output = [\"a\", \"##p\", \"##p\", \"##l\", \"##e\"]  (if self.with_markers is True)\n",
        "            output = [\"a\", \"p\", \"p\", \"l\", \"e\"]          (if self.with_markers is False)\n",
        "        Args:\n",
        "            text: A single token or whitespace separated tokens.\n",
        "                This should have already been passed through `BasicTokenizer`.\n",
        "        Returns:\n",
        "            A list of characters.\n",
        "        \"\"\"\n",
        "\n",
        "        output_tokens = []\n",
        "        for i, char in enumerate(text):\n",
        "            if char not in self.vocab:\n",
        "                output_tokens.append(self.unk_token)\n",
        "                continue\n",
        "\n",
        "            if self.with_markers and i != 0:\n",
        "                output_tokens.append('##' + char)\n",
        "            else:\n",
        "                output_tokens.append(char)\n",
        "\n",
        "        return output_tokens"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ea6ZrYE68uHR"
      },
      "source": [
        "## Tokenize dataset "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "emZATemg83p5",
        "outputId": "899321a3-6823-4707-b0ae-54e8f7fe320a"
      },
      "source": [
        "vocab_file_path = AlBERTo_path+\"vocab.txt\"\n",
        "\n",
        "tokenizer = AlBERToTokenizer(do_lower_case=True,vocab_file=vocab_file_path)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-8c88461ea636>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mvocab_file_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAlBERTo_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"vocab.txt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAlBERToTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdo_lower_case\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvocab_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvocab_file_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-22-5810d46c718a>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, vocab_file, do_lower_case, do_basic_tokenize, do_char_tokenize, do_wordpiece_tokenize, do_preprocessing, unk_token, sep_token, pad_token, cls_token, mask_token, **kwargs)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_wordpiece_tokenize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdo_wordpiece_tokenize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_lower_case\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvocab_file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_basic_tokenize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdo_basic_tokenize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: can't set attribute"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 713
        },
        "id": "dTQC4_Vm-ZxJ",
        "outputId": "8cb4d222-0945-4937-8c0f-0cb9ef720257"
      },
      "source": [
        "dataset['text'] = dataset['text'].apply(tokenizer.tokenize)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-64d1db273f4c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[1;32m   4211\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4212\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4213\u001b[0;31m                 \u001b[0mmapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4215\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-7fb82df323c8>\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(self, text, never_split, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnever_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnever_split\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-19-7fb82df323c8>\u001b[0m in \u001b[0;36m_tokenize\u001b[0;34m(self, text, never_split, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnever_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_preprocessing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_lower_case\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m                 \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_processor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpre_process_doc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/tokenization_bert.py\u001b[0m in \u001b[0;36mdo_lower_case\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdo_lower_case\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasic_tokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdo_lower_case\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'AlBERToTokenizer' object has no attribute 'basic_tokenizer'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205,
          "referenced_widgets": [
            "50d504e4b11d4b4ca13b78a3edf69c2c",
            "43e556fded544525966f2727b1483f83",
            "e5c307c8cff5403c83729e014227905a",
            "f5f98ac79408429388357367eb224751",
            "b9dffaf6482d4bfdb52cff660b17aa7d",
            "fd376476e8594af687e7e3a3ff5100ca",
            "0231500bc8cd4605bea3064bba130365",
            "d013c28e553946d089b0953162097ca7",
            "3aa91d6acd6f4bd9bebc50ee77055f34",
            "e944c7c7a8c84c04b0459b18067d56b6",
            "4d120a393d074334838d9e545cd3d68c",
            "3ab926188ed64fe693b73cc0bf47da1e",
            "76986117f4b64cad9ad71135e4433523",
            "9ff651304e5c4091876761cb7e27f503",
            "49be2a1606a1402bb447382eec415622",
            "34213da1c8d243fa9916f3a8538805a5"
          ]
        },
        "id": "68ds_Gk--7JW",
        "outputId": "4a2e87b6-7089-4532-a9de-8d3e958e8e8d"
      },
      "source": [
        "from tokenizer import *\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "\n",
        "model = AutoModel.from_pretrained(\"m-polignano-uniba/bert_uncased_L-12_H-768_A-12_italian_alb3rt0\")"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[26/Feb/2021 15:48:18] INFO - Lock 140075500667280 acquired on /root/.cache/torch/transformers/ddbe3a15a091d937ecbe95bd9c6fc3c82a8c0fde2b2725504806bae3d5b553c7.ae4dca69541bd7de0c171dd17916268b75b9de1cdbd9670add7a62ad5b98a01e.lock\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "50d504e4b11d4b4ca13b78a3edf69c2c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=625.0, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[26/Feb/2021 15:48:19] INFO - Lock 140075500667280 released on /root/.cache/torch/transformers/ddbe3a15a091d937ecbe95bd9c6fc3c82a8c0fde2b2725504806bae3d5b553c7.ae4dca69541bd7de0c171dd17916268b75b9de1cdbd9670add7a62ad5b98a01e.lock\n",
            "[26/Feb/2021 15:48:19] INFO - Lock 140075501099728 acquired on /root/.cache/torch/transformers/8270b211710cba9f85a4fd7242e31b37d94e76042d67de09b6eac7ab6e7ef78e.48dbff3c9ce886c188677656cbfb17029a8a066539b2da658b60d42766b0122c.lock\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3aa91d6acd6f4bd9bebc50ee77055f34",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=740314266.0, style=ProgressStyle(descriâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[26/Feb/2021 15:48:39] INFO - Lock 140075501099728 released on /root/.cache/torch/transformers/8270b211710cba9f85a4fd7242e31b37d94e76042d67de09b6eac7ab6e7ef78e.48dbff3c9ce886c188677656cbfb17029a8a066539b2da658b60d42766b0122c.lock\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qzjFQnK1CMXW",
        "outputId": "71e4c2c0-778e-4982-ae34-e2ba2675448f"
      },
      "source": [
        "\n",
        "\n",
        "tok = AutoTokenizer.from_pretrained(\"m-polignano-uniba/bert_uncased_L-12_H-768_A-12_italian_alb3rt0\")\n",
        "tokens = tok.tokenize(\"notizia del giorno sono morto\")\n",
        "print(tokens)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['notizia', 'del', 'giorno', 'sono', 'morto']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BdTu4Rj6CWIh"
      },
      "source": [
        "dataset['text'] = dataset['text'].apply(tokenizer.tokenize)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6Hhe8v0gDW0Q",
        "outputId": "d8f8f0cb-a899-4128-a709-d59222f5f692"
      },
      "source": [
        "dataset"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>hs</th>\n",
              "      <th>stereotype</th>\n",
              "      <th>text_length</th>\n",
              "      <th>#C-L words</th>\n",
              "      <th>hashtags</th>\n",
              "      <th>#?!</th>\n",
              "      <th>#.,</th>\n",
              "      <th>tokens</th>\n",
              "      <th>#bad_words</th>\n",
              "      <th>%bad_words</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2066</td>\n",
              "      <td>Ãˆ terrorismo anche questo per mettere in uno stato di soggezione le persone e renderle innocue mentre qualcuno</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>120</td>\n",
              "      <td>10</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>['Ãˆ', 'terrorismo', 'anche', 'questo', 'per', 'mettere', 'in', 'uno', 'stato', 'di', 'soggezione', 'le', 'persone', 'e', 'renderle', 'innocue', 'mentre', 'qualcuno']</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2045</td>\n",
              "      <td>infatti finchÃ© ci hanno guadagnato con i campi rom tutto era ok con alemanno ipocriti</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>101</td>\n",
              "      <td>0</td>\n",
              "      <td>['#rom', '#Alemanno', '#Ipocriti']</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>['infatti', 'finchÃ©', 'ci', 'hanno', 'guadagnato', 'con', 'i', 'campi', 'rom', 'tutto', 'era', 'ok', 'con', 'alemanno', 'ipocriti']</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>61</td>\n",
              "      <td>Corriere Tangenti Mafia Capitale dimenticataMazzette su buche e campi rom rom a</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>86</td>\n",
              "      <td>8</td>\n",
              "      <td>['#roma']</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>['Corriere', 'Tangenti', 'Mafia', 'Capitale', 'dimenticataMazzette', 'su', 'buche', 'e', 'campi', 'rom', 'rom', 'a']</td>\n",
              "      <td>3</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1259</td>\n",
              "      <td>ad uno ad uno perchÃ© quando i migranti israeliti arrivarono in terra di Canaan fecero fuori tutti i Cananiti</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>118</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>['ad', 'uno', 'ad', 'uno', 'perchÃ©', 'quando', 'i', 'migranti', 'israeliti', 'arrivarono', 'in', 'terra', 'di', 'Canaan', 'fecero', 'fuori', 'tutti', 'i', 'Cananiti']</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>949</td>\n",
              "      <td>Il divertimento del giorno Trovare i patrioti italiani che inneggiano contro i rom facendo la spesa alla li dl multinazionale tedesca</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>138</td>\n",
              "      <td>0</td>\n",
              "      <td>['#Lidl']</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>['Il', 'divertimento', 'del', 'giorno', 'Trovare', 'i', 'patrioti', 'italiani', 'che', 'inneggiano', 'contro', 'i', 'rom', 'facendo', 'la', 'spesa', 'alla', 'li', 'dl', 'multinazionale', 'tedesca']</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6832</th>\n",
              "      <td>9340</td>\n",
              "      <td>Gli stati nazionali devono essere pronti a rinunciare alla propria sovranitÃ  Lo ha detto la Merkel che ha aggiunto che gli stati nazionali non devono ascoltare la volontÃ  dei loro cittadini quando si tratta di questioni che riguardano immigrazione confini o persino sovranitÃ </td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>285</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>['Gli', 'stati', 'nazionali', 'devono', 'essere', 'pronti', 'a', 'rinunciare', 'alla', 'propria', 'sovranitÃ ', 'Lo', 'ha', 'detto', 'la', 'Merkel', 'che', 'ha', 'aggiunto', 'che', 'gli', 'stati', 'nazionali', 'non', 'devono', 'ascoltare', 'la', 'volontÃ ', 'dei', 'loro', 'cittadini', 'quando', 'si', 'tratta', 'di', 'questioni', 'che', 'riguardano', 'immigrazione', 'confini', 'o', 'persino', 'sovranitÃ ']</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6833</th>\n",
              "      <td>9121</td>\n",
              "      <td>Il ministro dellinterno della Germania HorstSehofersta facendo la proposta di dare soldi agli immigrati che vogliono tornare a casa e aiutarli a creare unattivitÃ  a casa loro e fare busines con la GermaniaChi pagaUna parte i crucchi e il resto lEuropa cioÃ¨ io e voi</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>277</td>\n",
              "      <td>0</td>\n",
              "      <td>['#HorstSeehofer,sta']</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>['Il', 'ministro', 'dellinterno', 'della', 'Germania', 'HorstSehofersta', 'facendo', 'la', 'proposta', 'di', 'dare', 'soldi', 'agli', 'immigrati', 'che', 'vogliono', 'tornare', 'a', 'casa', 'e', 'aiutarli', 'a', 'creare', 'unattivitÃ ', 'a', 'casa', 'loro', 'e', 'fare', 'busines', 'con', 'la', 'GermaniaChi', 'pagaUna', 'parte', 'i', 'crucchi', 'e', 'il', 'resto', 'lEuropa', 'cioÃ¨', 'io', 'e', 'voi']</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6834</th>\n",
              "      <td>8549</td>\n",
              "      <td>Salvini In Italia troppi si sono montati la testa io ringrazio Dio e voi per questi mesi straordinari Vi raccontavano che su immigrazione non si poteva fare nulla Ã¨ bastato usare buonsenso e coraggio io ci sono piazza del popolo</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>233</td>\n",
              "      <td>0</td>\n",
              "      <td>['#Salvini:', '#iocisono', '#piazzadelpopolo']</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>['Salvini', 'In', 'Italia', 'troppi', 'si', 'sono', 'montati', 'la', 'testa', 'io', 'ringrazio', 'Dio', 'e', 'voi', 'per', 'questi', 'mesi', 'straordinari', 'Vi', 'raccontavano', 'che', 'su', 'immigrazione', 'non', 'si', 'poteva', 'fare', 'nulla', 'Ã¨', 'bastato', 'usare', 'buonsenso', 'e', 'coraggio', 'io', 'ci', 'sono', 'piazza', 'del', 'popolo']</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6835</th>\n",
              "      <td>9240</td>\n",
              "      <td>Chi giubila in buona fede non ha capito niente Purtroppo credo che i piÃ¹ non siano in buona fede I migranti sono un grosso busines e chi finora li ha voluti non vuole perdere questo guadagno</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>206</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>['Chi', 'giubila', 'in', 'buona', 'fede', 'non', 'ha', 'capito', 'niente', 'Purtroppo', 'credo', 'che', 'i', 'piÃ¹', 'non', 'siano', 'in', 'buona', 'fede', 'I', 'migranti', 'sono', 'un', 'grosso', 'busines', 'e', 'chi', 'finora', 'li', 'ha', 'voluti', 'non', 'vuole', 'perdere', 'questo', 'guadagno']</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6836</th>\n",
              "      <td>8000</td>\n",
              "      <td>I giovani cristiani in etiopia sono indotti dagli islamisti a convertirsi allIslam con promesse di lavoro istruzione e aiuti abitativi Alcune miniere impiegano solo musulmani Lo riferisce ad ACS un leader cristiano locale anonimo per motivi di sicurezza Preghiamo per loro</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>285</td>\n",
              "      <td>7</td>\n",
              "      <td>['#Etiopia']</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>['I', 'giovani', 'cristiani', 'in', 'etiopia', 'sono', 'indotti', 'dagli', 'islamisti', 'a', 'convertirsi', 'allIslam', 'con', 'promesse', 'di', 'lavoro', 'istruzione', 'e', 'aiuti', 'abitativi', 'Alcune', 'miniere', 'impiegano', 'solo', 'musulmani', 'Lo', 'riferisce', 'ad', 'ACS', 'un', 'leader', 'cristiano', 'locale', 'anonimo', 'per', 'motivi', 'di', 'sicurezza', 'Preghiamo', 'per', 'loro']</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6837 rows Ã— 12 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        id  ... %bad_words\n",
              "0     2066  ...          0\n",
              "1     2045  ...          6\n",
              "2       61  ...         25\n",
              "3     1259  ...          0\n",
              "4      949  ...          4\n",
              "...    ...  ...        ...\n",
              "6832  9340  ...          0\n",
              "6833  9121  ...          0\n",
              "6834  8549  ...          0\n",
              "6835  9240  ...          0\n",
              "6836  8000  ...          0\n",
              "\n",
              "[6837 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    }
  ]
}