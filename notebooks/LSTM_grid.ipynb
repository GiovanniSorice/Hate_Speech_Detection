{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM_grid.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GiovanniSorice/Hate_Speech_Detection/blob/main/LSTM_grid.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0mBfEzg_53t"
      },
      "source": [
        "#Bidirectional LSTM Hate Speech Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OymXBcAV-Uk_"
      },
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Embedding, SpatialDropout1D, LSTM\n",
        "from tensorflow.keras.layers import Bidirectional # new! \n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "import os\n",
        "from sklearn.metrics import roc_auc_score \n",
        "import matplotlib.pyplot as plt\n",
        "from keras.preprocessing.text import one_hot\n",
        "from tensorboard.plugins.hparams import api as hp\n",
        "import numpy as np\n",
        "from sklearn.metrics import f1_score\n",
        "import ast \n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import StratifiedKFold"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FwrQH01T_nIS",
        "outputId": "1e99b57c-5193-42af-fb6c-535584bfc862"
      },
      "source": [
        "from google.colab import drive\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ewn7ge0AB8n"
      },
      "source": [
        "# directory name \n",
        "input_dir = '/content/drive/My Drive/HLT/clean_dataset_training/' \n",
        "input_test_dir = \"/content/drive/My Drive/HLT/dataset_test_evalita_preprocessed/\"\n",
        "# Spec\n",
        "pd.set_option(\"display.max_colwidth\", None)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJL3UvhtALOr"
      },
      "source": [
        "tsv_file = open(input_dir+\"training_dataset.csv\")\n",
        "\n",
        "dataset = pd.read_csv(tsv_file,sep=',')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "niRStx_sEI14"
      },
      "source": [
        "### Vector-space embedding: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rA44wzytEILB"
      },
      "source": [
        "p_val=0.15 # percentage of validation set \n",
        "\n",
        "n_dim = 64 \n",
        "n_unique_words = 25000 \n",
        "max_length = 64 # doubled!\n",
        "pad_type = trunc_type = 'pre'\n",
        "\n",
        "# training \n",
        "batch_size = 64"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cP42BiElvcKH"
      },
      "source": [
        "#### Preprocess data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KU0jvqjPHTsM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a47d0347-f8c1-44cf-e66e-1bdef15e3b61"
      },
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "all_words = []\n",
        "for index, row in dataset.iterrows():\n",
        "  tokenize_word = word_tokenize(row[\"text\"])\n",
        "  for word in tokenize_word:\n",
        "      all_words.append(word)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iaqpZHjMG6Dn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4af8e6f-19a8-438a-c9c0-06c33d18b7f2"
      },
      "source": [
        "unique_words = set(all_words)\n",
        "print(len(unique_words))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "22525\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fAjg3KCQEHl3"
      },
      "source": [
        "parole_non_ric = set()\n",
        "def sentence_to_emb2(sentence, w2v, truncate = None, padding = False):\n",
        "  global parole_non_ric\n",
        "  pad_token = [0]*128\n",
        "  s_emb = [ w2v[word.lower()] for word in sentence if word.lower() in w2v.vocab]\n",
        "  parole_non_ric.update(set([ word.lower() for word in sentence if word.lower() not in w2v.vocab]))\n",
        "  if truncate is not None:\n",
        "    s_emb = s_emb[:truncate] #truncate\n",
        "  if padding:\n",
        "    s_emb += [pad_token] * (truncate - len(s_emb))\n",
        "  return np.array(s_emb)\n",
        "\n",
        "def get_data_to_emb2(data, w2v, truncate = None, padding = False):\n",
        "  X = [sentence_to_emb2(ast.literal_eval(sentence), w2v, truncate, padding) for sentence in data]\n",
        "  print(len(X))\n",
        "  print(X[0])\n",
        "  return np.array(X)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dd6KYgWqEKXs"
      },
      "source": [
        "from gensim.models import KeyedVectors\n",
        "from gensim.test.utils import datapath\n",
        "w2v_felice_path = \"/content/drive/My Drive/HLT/w2v/twitter128.bin\"\n",
        "w2v = KeyedVectors.load_word2vec_format(datapath(w2v_felice_path), binary=True)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V97RhoGzTonm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc02b5b9-e6b1-4169-d038-4a597c3af21d"
      },
      "source": [
        "X_dev = get_data_to_emb2(dataset[\"tokens\"], w2v, max_length , True)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6837\n",
            "[[ 1.47564483  0.12307259  1.0753547  ...  1.06197035  1.90046942\n",
            "  -0.19663759]\n",
            " [-2.10587931  1.7696439  -1.04741096 ... -1.11571276 -0.25399542\n",
            "  -0.97522277]\n",
            " [ 0.89639139  1.24942708  0.72824973 ...  0.68920714  0.98506999\n",
            "  -0.36202168]\n",
            " ...\n",
            " [ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]\n",
            " [ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]\n",
            " [ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "URGejkayq4T3",
        "outputId": "91e88e4d-3d19-4f32-bcbf-2b949db47761",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "len(parole_non_ric)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2159"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMnXywTcqSy1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "b207debf-074c-4a92-aefe-3a6702e394b8"
      },
      "source": [
        "dataset_other = dataset\n",
        "dataset_other = dataset.drop(['text', 'id', 'hs', 'stereotype','tokens', 'hashtags'], axis=1)\n",
        "dataset_other"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text_length</th>\n",
              "      <th>#C-L words</th>\n",
              "      <th>#?!</th>\n",
              "      <th>#.,</th>\n",
              "      <th>#bad_words</th>\n",
              "      <th>%bad_words</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>120</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>101</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>86</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>118</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>138</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6832</th>\n",
              "      <td>285</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6833</th>\n",
              "      <td>277</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6834</th>\n",
              "      <td>233</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6835</th>\n",
              "      <td>206</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6836</th>\n",
              "      <td>285</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6837 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      text_length  #C-L words  #?!  #.,  #bad_words  %bad_words\n",
              "0             120          10    0    5           0           0\n",
              "1             101           0    0    0           1           6\n",
              "2              86           8    0    1           3          25\n",
              "3             118           0    0    2           0           0\n",
              "4             138           0    1    1           1           4\n",
              "...           ...         ...  ...  ...         ...         ...\n",
              "6832          285           2    0    4           0           0\n",
              "6833          277           0    2    3           0           0\n",
              "6834          233           0    0    4           0           0\n",
              "6835          206           2    0    2           0           0\n",
              "6836          285           7    1    5           0           0\n",
              "\n",
              "[6837 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7TX3TS1yTlR"
      },
      "source": [
        "x_train, x_valid, x_train_extra, x_valid_extra, y_train, y_valid = train_test_split(X_dev, dataset_other.values , dataset[['hs']], test_size=p_val, random_state=128)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRF1dwdVpKSo"
      },
      "source": [
        "input_train = {\"text\": x_train, \"other\": x_train_extra}\n",
        "input_val   = {\"text\": x_valid, \"other\": x_valid_extra}"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXitI_XKIZN7"
      },
      "source": [
        "max_sent = 0 "
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCxWTGMOHVzc"
      },
      "source": [
        "\n",
        "def comment_length(text):\n",
        "    global max_sent \n",
        "    text = ast.literal_eval(text)\n",
        "    if len(text)>max_sent: \n",
        "      max_sent = len(text)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vmnRA9uGIKjJ",
        "outputId": "aa0b1244-c4cd-4906-a98a-8ce07cc122a1"
      },
      "source": [
        "dataset['tokens'].apply(comment_length)\n",
        "print(max_sent)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "121\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oVbNT3FOisHf",
        "outputId": "94d8db16-70b1-46c0-932b-af0c86670c8b"
      },
      "source": [
        "x_train_extra.shape"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5811, 6)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uAUJfLg_BGTX"
      },
      "source": [
        "### Design grid search parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PC8zF9NNBJso"
      },
      "source": [
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard\n",
        "\n",
        "# Clear any logs from previous runs\n",
        "!rm -rf ./logs/\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorboard.plugins.hparams import api as hp"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JJ6QHGwBXVJ"
      },
      "source": [
        "HP_NUM_UNITS = hp.HParam('num_units', hp.Discrete([64]))\n",
        "HP_DROPOUT = hp.HParam('dropout', hp.RealInterval(0.0, 0.8))\n",
        "HP_L2 = hp.HParam('L2_reg', hp.RealInterval(0.0, 0.0008))\n",
        "HP_OPTIMIZER = hp.HParam('optimizer', hp.Discrete(['nadam']))\n",
        "\n",
        "METRIC_ACCURACY = 'accuracy'\n",
        "\n",
        "with tf.summary.create_file_writer('logs/hparam_tuning').as_default():\n",
        "  hp.hparams_config(\n",
        "    hparams=[HP_NUM_UNITS, HP_DROPOUT, HP_OPTIMIZER],\n",
        "    metrics=[hp.Metric(METRIC_ACCURACY, display_name='Accuracy')],\n",
        "  )"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXFVlKlA7CUr"
      },
      "source": [
        "class FCallback(tf.keras.callbacks.Callback):\n",
        "  \n",
        "    def __init__(self, validation = (), verbose = 0):\n",
        "        self.validation = validation\n",
        "        self.verbose = verbose\n",
        "\n",
        "    def on_train_begin(self, logs={}):\n",
        "        self.f1 = []\n",
        "        self.val_f1 = []\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        y_t =  self.validation[1]\n",
        "        y_p =  np.where(self.model.predict(self.validation[0]) > 0.5, 1, 0)\n",
        "        logs['val_f1'] =  f1_score(y_t, y_p, average='macro')\n",
        "        if self.verbose >0:\n",
        "          print(\"— val_f1: {}\".format(logs['val_f1']))"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJjzp8CnwARN"
      },
      "source": [
        "def get_model(hparams):\n",
        "  lstml1_in = tf.keras.layers.Input(name=\"text\", shape =(max_length,128,))\n",
        "  lstml1_bd1 = tf.keras.layers.Bidirectional(LSTM(hparams[HP_NUM_UNITS], dropout = hparams[HP_DROPOUT], return_sequences=True))(lstml1_in)\n",
        "  lstml1_bd2 = tf.keras.layers.Bidirectional(LSTM(hparams[HP_NUM_UNITS], dropout = hparams[HP_DROPOUT]))(lstml1_bd1)\n",
        "\n",
        "  other_in = tf.keras.layers.Input(name=\"other\", shape =(6,))\n",
        "\n",
        "  lconcat = tf.keras.layers.Concatenate(axis=1)([lstml1_bd2, other_in])\n",
        "  dense1_layer = Dense(256, activation=\"relu\", kernel_regularizer=tf.keras.regularizers.l2(hparams[HP_L2]))(lconcat)\n",
        "  dense2_layer = Dense(64, activation=\"relu\", kernel_regularizer=tf.keras.regularizers.l2(hparams[HP_L2]))(dense1_layer)\n",
        "  dense3_layer = Dense(32, activation=\"relu\", kernel_regularizer=tf.keras.regularizers.l2(hparams[HP_L2]))(dense2_layer)\n",
        "\n",
        "  lstml1_out = tf.keras.layers.Dense(1, activation='sigmoid')(dense3_layer)\n",
        "\n",
        "\n",
        "  model = tf.keras.Model(inputs = [lstml1_in, other_in], outputs = lstml1_out)\n",
        "  \n",
        "  # model.summary()\n",
        "  \n",
        "  return model\n",
        "\n",
        "  \n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4nNvvQRCcFP"
      },
      "source": [
        "def train_test_model(hparams):\n",
        "  \n",
        "  model = get_model(hparams)\n",
        "  model.compile(\n",
        "      optimizer=hparams[HP_OPTIMIZER],\n",
        "      loss='binary_crossentropy',\n",
        "      metrics=['accuracy'],\n",
        "  )\n",
        "\n",
        "  f1_callback = FCallback(validation = (input_val, y_valid), verbose=True)                                   \n",
        "\n",
        "  #filepath = input_dir + \"model_output/biLSTM/HP_NUM_UNITS={0}/HP_DROPOUT={1}/HP_L2={2}/\".format(hparams[HP_NUM_UNITS],hparams[HP_DROPOUT],hparams[HP_L2])\n",
        "  #filepath += \"saved-model-{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n",
        "  #checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=False, mode='max')\n",
        "\n",
        "  model.fit(input_train, y_train, batch_size=batch_size, validation_data=(input_val, y_valid), epochs=10, callbacks=[f1_callback]) # Run with 1 epoch to speed things up for demo purposes\n",
        "  _, accuracy = model.evaluate(input_val, y_valid)\n",
        "\n",
        "  #y_test_pred_tweets = np.where(model.predict(input_test_tweets) > 0.5, 1, 0)\n",
        "  #y_test_pred_news = np.where(model.predict(input_test_news) > 0.5, 1, 0)\n",
        "\n",
        "  #print(\"f1_score test tweets: {}\".format(f1_score(y_test_tweets, y_test_pred_tweets,average=\"macro\")))\n",
        "  #print(\"f1_score test news: {}\".format(f1_score(y_test_news, y_test_pred_news,average=\"macro\")))\n",
        "  return accuracy"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OaO2zq3-Adck"
      },
      "source": [
        "def run(run_dir, hparams):\n",
        "  with tf.summary.create_file_writer(run_dir).as_default():\n",
        "    hp.hparams(hparams)  # record the values used in this trial\n",
        "    accuracy = train_test_model(hparams)\n",
        "    tf.summary.scalar(METRIC_ACCURACY, accuracy, step=1)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "id": "9CaPr2dcL4tD",
        "outputId": "ff1d0eb6-740a-402b-a89d-f3d1dd8653bc"
      },
      "source": [
        "session_num = 0\n",
        "\n",
        "for num_units in HP_NUM_UNITS.domain.values:\n",
        "  for dropout_rate in np.arange(HP_DROPOUT.domain.min_value, HP_DROPOUT.domain.max_value, 0.2):\n",
        "      for L2_rate in np.arange(HP_L2.domain.min_value, HP_L2.domain.max_value, 0.0002):\n",
        "        for optimizer in HP_OPTIMIZER.domain.values:\n",
        "          hparams = {\n",
        "              HP_NUM_UNITS: num_units,\n",
        "              HP_DROPOUT: dropout_rate,\n",
        "              HP_OPTIMIZER: optimizer,\n",
        "              HP_L2: L2_rate,\n",
        "          }\n",
        "          run_name = \"run-%d\" % session_num\n",
        "          print('--- Starting trial: %s' % run_name)\n",
        "          print({h.name: hparams[h] for h in hparams})\n",
        "          run('logs/hparam_tuning/' + run_name, hparams)\n",
        "          session_num += 1\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--- Starting trial: run-0\n",
            "{'num_units': 64, 'dropout': 0.0, 'optimizer': 'nadam', 'L2_reg': 0.0}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-86ccd94d9c9d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m           \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'--- Starting trial: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mrun_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m           \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mhparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mh\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhparams\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m           \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'logs/hparam_tuning/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrun_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m           \u001b[0msession_num\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-24-fd9c39d06c4d>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(run_dir, hparams)\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_file_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mhp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# record the values used in this trial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMETRIC_ACCURACY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-23-ac746976ba2f>\u001b[0m in \u001b[0;36mtrain_test_model\u001b[0;34m(hparams)\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0;31m#checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=False, mode='max')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf1_callback\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Run with 1 epoch to speed things up for demo purposes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m   \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;31m# Legacy graph support is contained in `training_v1.Model`.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m     \u001b[0mversion_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisallow_legacy_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Model'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1032\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assert_compile_was_called\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_call_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'fit'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m     \u001b[0m_disallow_inside_tf_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'fit'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_assert_compile_was_called\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2590\u001b[0m     \u001b[0;31m# (i.e. whether the model is built and its inputs/outputs are set).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2591\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2592\u001b[0;31m       raise RuntimeError('You must compile your model before '\n\u001b[0m\u001b[1;32m   2593\u001b[0m                          \u001b[0;34m'training/testing. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2594\u001b[0m                          'Use `model.compile(optimizer, loss)`.')\n",
            "\u001b[0;31mRuntimeError\u001b[0m: You must compile your model before training/testing. Use `model.compile(optimizer, loss)`."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUvnMoP9EsnU"
      },
      "source": [
        "### Test phase"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZVkUrF2luNH"
      },
      "source": [
        "csv_test_tweets_file = open(input_test_dir+\"test_dataset_tweets.csv\")\n",
        "\n",
        "testset_tweets = pd.read_csv(csv_test_tweets_file,sep=',')\n",
        "\n",
        "csv_test_news_file = open(input_test_dir+\"test_dataset_news.csv\")\n",
        "\n",
        "testset_news = pd.read_csv(csv_test_news_file,sep=',')"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEA-Q8phFM71",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23483f99-6a63-4178-bf8d-03ab543d52a3"
      },
      "source": [
        "X_test_news = get_data_to_emb2(testset_news[\"tokens\"], w2v, max_length , True)\n",
        "X_test_tweets = get_data_to_emb2(testset_tweets[\"tokens\"], w2v, max_length , True)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "500\n",
            "[[ 0.4473033  -1.85372221  1.80903184 ... -0.81329495 -0.37441084\n",
            "   0.67255157]\n",
            " [ 0.65353721  2.91942644  0.83319777 ...  0.10994434  0.79807943\n",
            "  -0.64684689]\n",
            " [ 0.27626377  0.63812095  1.54855597 ... -0.60746866  1.20815647\n",
            "   0.78223377]\n",
            " ...\n",
            " [ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]\n",
            " [ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]\n",
            " [ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]]\n",
            "1263\n",
            "[[ 0.85021353  0.94971675  0.95175791 ...  0.66373271  0.95456082\n",
            "   0.80749106]\n",
            " [ 1.86031258  0.98840606 -2.10821915 ...  1.14880133  0.14479998\n",
            "  -0.10640591]\n",
            " [-1.32805312  0.75008422  0.24781393 ... -0.08247134 -0.89805609\n",
            "  -0.75278544]\n",
            " ...\n",
            " [ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]\n",
            " [ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]\n",
            " [ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RL4fJuI-7egi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "05604448-a3c0-43e8-f487-d90e67c9bef7"
      },
      "source": [
        "testset_tweets_other = testset_tweets\n",
        "testset_tweets_other = testset_tweets.drop(['text', 'id', 'hs', 'stereotype','tokens', 'hashtags'], axis=1)\n",
        "testset_tweets_other"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text_length</th>\n",
              "      <th>#C-L words</th>\n",
              "      <th>#?!</th>\n",
              "      <th>#.,</th>\n",
              "      <th>#bad_words</th>\n",
              "      <th>%bad_words</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>180</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>227</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>259</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>99</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>257</td>\n",
              "      <td>87</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1258</th>\n",
              "      <td>216</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1259</th>\n",
              "      <td>159</td>\n",
              "      <td>81</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1260</th>\n",
              "      <td>278</td>\n",
              "      <td>32</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1261</th>\n",
              "      <td>128</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1262</th>\n",
              "      <td>284</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1263 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      text_length  #C-L words  #?!  #.,  #bad_words  %bad_words\n",
              "0             180           4    1    4           0           0\n",
              "1             227           5    4    5           0           0\n",
              "2             259           2    2    4           1           2\n",
              "3              99           7    0    2           0           0\n",
              "4             257          87    2    0           0           0\n",
              "...           ...         ...  ...  ...         ...         ...\n",
              "1258          216           0    0    5           0           0\n",
              "1259          159          81    3    1           1           3\n",
              "1260          278          32    4    7           1           2\n",
              "1261          128           0    1    3           0           0\n",
              "1262          284           2    2    9           0           0\n",
              "\n",
              "[1263 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIXr4PJLF36A",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "c7207387-fe42-4069-9fe0-bff1220cde25"
      },
      "source": [
        "testset_news_other = testset_news\n",
        "testset_news_other = testset_news.drop(['text', 'id', 'hs', 'stereotype','tokens', 'hashtags'], axis=1)\n",
        "testset_news_other"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text_length</th>\n",
              "      <th>#C-L words</th>\n",
              "      <th>#?!</th>\n",
              "      <th>#.,</th>\n",
              "      <th>#bad_words</th>\n",
              "      <th>%bad_words</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>102</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>108</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>48</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>112</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>117</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>495</th>\n",
              "      <td>80</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>496</th>\n",
              "      <td>60</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>497</th>\n",
              "      <td>86</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498</th>\n",
              "      <td>92</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499</th>\n",
              "      <td>67</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>500 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     text_length  #C-L words  #?!  #.,  #bad_words  %bad_words\n",
              "0            102           0    1    5           0           0\n",
              "1            108           0    0    1           0           0\n",
              "2             48           0    0    0           0           0\n",
              "3            112           0    0    5           0           0\n",
              "4            117           0    0    6           0           0\n",
              "..           ...         ...  ...  ...         ...         ...\n",
              "495           80           0    0    2           0           0\n",
              "496           60           0    0    0           0           0\n",
              "497           86           0    0    2           0           0\n",
              "498           92           0    0    0           0           0\n",
              "499           67           0    0    1           0           0\n",
              "\n",
              "[500 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CR69UbzM7nN8"
      },
      "source": [
        "input_test_tweets   = {\"text\": X_test_tweets, \"other\": testset_tweets_other.values}\n",
        "y_test_tweets = testset_tweets[['hs']]\n"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vhoi6YkbGJyj"
      },
      "source": [
        "input_test_news   = {\"text\": X_test_news, \"other\": testset_news_other.values}\n",
        "y_test_news = testset_news[['hs']]\n"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imavSMMX17qH"
      },
      "source": [
        "x_kfold = X_dev\n",
        "x_other_kfold = dataset_other\n",
        "y_kfold = dataset[['hs']]"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUsrgeL_xUkK"
      },
      "source": [
        "def train_test_model_with_kfold(hparams):\n",
        "  number_of_splits = 5\n",
        "  cv_kfold = StratifiedKFold(n_splits=number_of_splits, shuffle=True, random_state=100)\n",
        "  models = []\n",
        "  for train_index, validation_index in cv_kfold.split(x_kfold, y_kfold):\n",
        "    model = get_model(hparams)\n",
        "    model.compile(\n",
        "        optimizer=hparams[HP_OPTIMIZER],\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy'],\n",
        "    )\n",
        "\n",
        "    input_train_kfold = {\"text\": x_kfold[train_index], \"other\": x_other_kfold.loc[train_index]}\n",
        "    input_val_kfold   = {\"text\": x_kfold[validation_index], \"other\": x_other_kfold.loc[validation_index]}\n",
        "    y_train_kfold = y_kfold.loc[train_index]\n",
        "    y_valid_kfold = y_kfold.loc[validation_index]\n",
        "\n",
        "    f1_callback = FCallback(validation = (input_val_kfold, y_valid_kfold), verbose=True)                                   \n",
        "\n",
        "    #filepath = input_dir + \"model_output/biLSTM/HP_NUM_UNITS={0}/HP_DROPOUT={1}/HP_L2={2}/\".format(hparams[HP_NUM_UNITS],hparams[HP_DROPOUT],hparams[HP_L2])\n",
        "    #filepath += \"saved-model-{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n",
        "    #checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=False, mode='max')\n",
        "\n",
        "\n",
        "    model.fit(input_train_kfold, y_train_kfold, batch_size=batch_size, validation_data=(input_val_kfold, y_valid_kfold), epochs=10, callbacks=[f1_callback]) # Run with 1 epoch to speed things up for demo purposes\n",
        "    _, accuracy = model.evaluate(input_val_kfold, y_valid_kfold)\n",
        "\n",
        "    #y_test_pred = np.where(model.predict(input_test)[0] > 0.5, 1, 0)\n",
        "    #y_test_pred_tweets = np.where(model.predict(input_test_tweets) > 0.5, 1, 0)\n",
        "    #y_test_pred_news = np.where(model.predict(input_test_news) > 0.5, 1, 0)\n",
        "\n",
        "    #print(\"f1_score test tweets: {}\".format(f1_score(y_test_tweets, y_test_pred_tweets,average=\"macro\")))\n",
        "    #print(\"f1_score test news: {}\".format(f1_score(y_test_news, y_test_pred_news,average=\"macro\")))\n",
        "    models.append(model)\n",
        "\n",
        "  return models"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnwToktaH-uQ"
      },
      "source": [
        "def predict_with_ensemble(models, test_input):\n",
        "  # make predictions\n",
        "  results = []\n",
        "  y_predict = [np.squeeze(np.where(model.predict(test_input) > 0.5, 1,0).reshape(1,-1)) for model in models]\n",
        "  # sum across ensemble members\n",
        "  y_predict = np.array(y_predict)\n",
        "\n",
        "  for i in range(y_predict.shape[1]):\n",
        "    counts = np.bincount(y_predict[:,i])\n",
        "    results.append(np.argmax(counts))\n",
        "  # argmax across classes\n",
        "  return results"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T24mBhARv8Hx"
      },
      "source": [
        "def run_with_kfold(run_dir, hparams):\n",
        "  with tf.summary.create_file_writer(run_dir).as_default():\n",
        "    hp.hparams(hparams)  # record the values used in this trial\n",
        "    models = train_test_model_with_kfold(hparams)\n",
        "    y_test_pred_tweets = predict_with_ensemble(models, input_test_tweets)\n",
        "    y_test_pred_news = predict_with_ensemble(models, input_test_news)\n",
        "\n",
        "    print(\"f1_score test tweets: {}\".format(f1_score(y_test_tweets, y_test_pred_tweets,average=\"macro\")))\n",
        "    print(\"f1_score test news: {}\".format(f1_score(y_test_news, y_test_pred_news,average=\"macro\")))\n",
        "    return models\n"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_Y4HvcNcxJs",
        "outputId": "a558f750-dc0d-44e2-95ff-6468853251f9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y_test_pred_tweets = predict_with_ensemble(models, input_test_tweets)\n",
        "y_test_pred_news = predict_with_ensemble(models, input_test_news)\n",
        "\n",
        "print(\"f1_score test tweets: {}\".format(f1_score(y_test_tweets, y_test_pred_tweets,average=\"macro\")))\n",
        "print(\"f1_score test news: {}\".format(f1_score(y_test_news, y_test_pred_news,average=\"macro\")))\n"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "f1_score test tweets: 0.729492743586192\n",
            "f1_score test news: 0.7092327164505866\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISaRu-AfD6Vz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a93ab950-6a60-4fdf-db74-199e45b7b384"
      },
      "source": [
        "hparams = {\n",
        "    HP_NUM_UNITS: 64,\n",
        "    HP_DROPOUT: 0.4,\n",
        "    HP_OPTIMIZER: \"nadam\",\n",
        "    HP_L2: 0.0000,\n",
        "}\n",
        "run_name = \"run-test\" \n",
        "print('--- Starting trial: %s' % run_name)\n",
        "print({h.name: hparams[h] for h in hparams})\n",
        "models = run_with_kfold('logs/hparam_tuning/' + run_name, hparams)\n"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--- Starting trial: run-test\n",
            "{'num_units': 64, 'dropout': 0.4, 'optimizer': 'nadam', 'L2_reg': 0.0}\n",
            "Epoch 1/10\n",
            "86/86 [==============================] - 8s 35ms/step - loss: 0.8481 - accuracy: 0.5801 - val_loss: 0.6349 - val_accuracy: 0.6250\n",
            "— val_f1: 0.48938845269823394\n",
            "Epoch 2/10\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.6177 - accuracy: 0.6672 - val_loss: 0.5447 - val_accuracy: 0.7390\n",
            "— val_f1: 0.7283756298029515\n",
            "Epoch 3/10\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.5815 - accuracy: 0.7062 - val_loss: 0.5056 - val_accuracy: 0.7624\n",
            "— val_f1: 0.7494792086337827\n",
            "Epoch 4/10\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.5230 - accuracy: 0.7305 - val_loss: 0.5711 - val_accuracy: 0.7200\n",
            "— val_f1: 0.7199859978034722\n",
            "Epoch 5/10\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.5059 - accuracy: 0.7459 - val_loss: 0.4862 - val_accuracy: 0.7697\n",
            "— val_f1: 0.7548603269325399\n",
            "Epoch 6/10\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.5005 - accuracy: 0.7642 - val_loss: 0.4633 - val_accuracy: 0.7844\n",
            "— val_f1: 0.7756832306595155\n",
            "Epoch 7/10\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.4464 - accuracy: 0.7767 - val_loss: 0.4883 - val_accuracy: 0.7697\n",
            "— val_f1: 0.7490237190407547\n",
            "Epoch 8/10\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.4617 - accuracy: 0.7749 - val_loss: 0.5009 - val_accuracy: 0.7756\n",
            "— val_f1: 0.7735713557866338\n",
            "Epoch 9/10\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.4183 - accuracy: 0.8021 - val_loss: 0.5537 - val_accuracy: 0.7251\n",
            "— val_f1: 0.7248615663753926\n",
            "Epoch 10/10\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.4132 - accuracy: 0.8021 - val_loss: 0.5081 - val_accuracy: 0.7858\n",
            "— val_f1: 0.7716288644287104\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.5081 - accuracy: 0.7858\n",
            "Epoch 1/10\n",
            "86/86 [==============================] - 9s 36ms/step - loss: 1.0968 - accuracy: 0.5571 - val_loss: 0.5625 - val_accuracy: 0.7091\n",
            "— val_f1: 0.6974527672816181\n",
            "Epoch 2/10\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.7199 - accuracy: 0.6604 - val_loss: 1.5320 - val_accuracy: 0.6001\n",
            "— val_f1: 0.38834672907203616\n",
            "Epoch 3/10\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.6522 - accuracy: 0.7020 - val_loss: 0.6477 - val_accuracy: 0.7039\n",
            "— val_f1: 0.6425398484452574\n",
            "Epoch 4/10\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.5564 - accuracy: 0.7355 - val_loss: 0.5182 - val_accuracy: 0.7405\n",
            "— val_f1: 0.7382410883444411\n",
            "Epoch 5/10\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.4900 - accuracy: 0.7699 - val_loss: 0.5141 - val_accuracy: 0.7500\n",
            "— val_f1: 0.7452913391999687\n",
            "Epoch 6/10\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.4881 - accuracy: 0.7579 - val_loss: 0.5430 - val_accuracy: 0.7398\n",
            "— val_f1: 0.738733538337407\n",
            "Epoch 7/10\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.4577 - accuracy: 0.7786 - val_loss: 0.5538 - val_accuracy: 0.7208\n",
            "— val_f1: 0.7207118807118807\n",
            "Epoch 8/10\n",
            "86/86 [==============================] - 2s 20ms/step - loss: 0.4749 - accuracy: 0.7832 - val_loss: 0.5701 - val_accuracy: 0.7281\n",
            "— val_f1: 0.7279020974534132\n",
            "Epoch 9/10\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.4160 - accuracy: 0.8106 - val_loss: 0.5056 - val_accuracy: 0.7639\n",
            "— val_f1: 0.7399574740804344\n",
            "Epoch 10/10\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.3965 - accuracy: 0.8185 - val_loss: 0.4934 - val_accuracy: 0.7749\n",
            "— val_f1: 0.7641062390827249\n",
            "43/43 [==============================] - 0s 8ms/step - loss: 0.4934 - accuracy: 0.7749\n",
            "Epoch 1/10\n",
            "86/86 [==============================] - 9s 36ms/step - loss: 0.7932 - accuracy: 0.5973 - val_loss: 0.6704 - val_accuracy: 0.6547\n",
            "— val_f1: 0.6535613343298712\n",
            "Epoch 2/10\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.5818 - accuracy: 0.6950 - val_loss: 0.5502 - val_accuracy: 0.7308\n",
            "— val_f1: 0.7187431510678743\n",
            "Epoch 3/10\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.5306 - accuracy: 0.7247 - val_loss: 0.5210 - val_accuracy: 0.7425\n",
            "— val_f1: 0.7280622832677015\n",
            "Epoch 4/10\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.5174 - accuracy: 0.7492 - val_loss: 0.8453 - val_accuracy: 0.6635\n",
            "— val_f1: 0.6600825981664074\n",
            "Epoch 5/10\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.5184 - accuracy: 0.7548 - val_loss: 0.5959 - val_accuracy: 0.7352\n",
            "— val_f1: 0.7345488681471946\n",
            "Epoch 6/10\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.4736 - accuracy: 0.7621 - val_loss: 0.6741 - val_accuracy: 0.6979\n",
            "— val_f1: 0.6353684898532808\n",
            "Epoch 7/10\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.4646 - accuracy: 0.7814 - val_loss: 0.5384 - val_accuracy: 0.7579\n",
            "— val_f1: 0.7547514245465923\n",
            "Epoch 8/10\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.4344 - accuracy: 0.7944 - val_loss: 0.5483 - val_accuracy: 0.7447\n",
            "— val_f1: 0.7154877165152413\n",
            "Epoch 9/10\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.4336 - accuracy: 0.7952 - val_loss: 0.5088 - val_accuracy: 0.7703\n",
            "— val_f1: 0.7629315677385717\n",
            "Epoch 10/10\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.4061 - accuracy: 0.8076 - val_loss: 0.5249 - val_accuracy: 0.7681\n",
            "— val_f1: 0.7611052888943526\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.5249 - accuracy: 0.7681\n",
            "Epoch 1/10\n",
            "86/86 [==============================] - 8s 35ms/step - loss: 1.0154 - accuracy: 0.5419 - val_loss: 0.8501 - val_accuracy: 0.6057\n",
            "— val_f1: 0.40647803934994053\n",
            "Epoch 2/10\n",
            "86/86 [==============================] - 2s 20ms/step - loss: 0.6079 - accuracy: 0.6890 - val_loss: 0.5495 - val_accuracy: 0.7206\n",
            "— val_f1: 0.6730664242497095\n",
            "Epoch 3/10\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.5369 - accuracy: 0.7224 - val_loss: 0.5769 - val_accuracy: 0.6964\n",
            "— val_f1: 0.6308802124778696\n",
            "Epoch 4/10\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.5383 - accuracy: 0.7241 - val_loss: 0.4726 - val_accuracy: 0.7557\n",
            "— val_f1: 0.7458270427227099\n",
            "Epoch 5/10\n",
            "86/86 [==============================] - 2s 20ms/step - loss: 0.4745 - accuracy: 0.7675 - val_loss: 0.5505 - val_accuracy: 0.7410\n",
            "— val_f1: 0.7047926854264882\n",
            "Epoch 6/10\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.4736 - accuracy: 0.7733 - val_loss: 0.4746 - val_accuracy: 0.7732\n",
            "— val_f1: 0.7570237603779641\n",
            "Epoch 7/10\n",
            "86/86 [==============================] - 2s 20ms/step - loss: 0.4524 - accuracy: 0.7854 - val_loss: 0.5044 - val_accuracy: 0.7564\n",
            "— val_f1: 0.7529310237211966\n",
            "Epoch 8/10\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.4386 - accuracy: 0.7931 - val_loss: 0.5657 - val_accuracy: 0.7198\n",
            "— val_f1: 0.7198220341386643\n",
            "Epoch 9/10\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.4289 - accuracy: 0.7974 - val_loss: 0.4932 - val_accuracy: 0.7623\n",
            "— val_f1: 0.7595853357742324\n",
            "Epoch 10/10\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.4175 - accuracy: 0.8016 - val_loss: 0.5137 - val_accuracy: 0.7762\n",
            "— val_f1: 0.7587647058823529\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.5137 - accuracy: 0.7762\n",
            "Epoch 1/10\n",
            "86/86 [==============================] - 8s 35ms/step - loss: 0.8721 - accuracy: 0.5992 - val_loss: 0.5772 - val_accuracy: 0.7154\n",
            "— val_f1: 0.6738740727793467\n",
            "Epoch 2/10\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.5834 - accuracy: 0.6937 - val_loss: 0.5024 - val_accuracy: 0.7513\n",
            "— val_f1: 0.7474197447134112\n",
            "Epoch 3/10\n",
            "86/86 [==============================] - 2s 20ms/step - loss: 0.5385 - accuracy: 0.7175 - val_loss: 0.6730 - val_accuracy: 0.6898\n",
            "— val_f1: 0.6879909391579963\n",
            "Epoch 4/10\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.5222 - accuracy: 0.7364 - val_loss: 0.4628 - val_accuracy: 0.7710\n",
            "— val_f1: 0.7688764169365272\n",
            "Epoch 5/10\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.4720 - accuracy: 0.7765 - val_loss: 0.5325 - val_accuracy: 0.7564\n",
            "— val_f1: 0.7560745455042335\n",
            "Epoch 6/10\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.4638 - accuracy: 0.7781 - val_loss: 0.4488 - val_accuracy: 0.7835\n",
            "— val_f1: 0.7771025401470146\n",
            "Epoch 7/10\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.4419 - accuracy: 0.7998 - val_loss: 0.5684 - val_accuracy: 0.7330\n",
            "— val_f1: 0.6925104441868448\n",
            "Epoch 8/10\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.4457 - accuracy: 0.7841 - val_loss: 0.4529 - val_accuracy: 0.7901\n",
            "— val_f1: 0.7819174393674684\n",
            "Epoch 9/10\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.4197 - accuracy: 0.7895 - val_loss: 0.5119 - val_accuracy: 0.7681\n",
            "— val_f1: 0.7461526520354873\n",
            "Epoch 10/10\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.4179 - accuracy: 0.8085 - val_loss: 0.4570 - val_accuracy: 0.7915\n",
            "— val_f1: 0.7890414964384052\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.4570 - accuracy: 0.7915\n",
            "f1_score test tweets: 0.7603277015648642\n",
            "f1_score test news: 0.6831647909673162\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_C5IjGnydPvu"
      },
      "source": [
        "for i in range(len(models)):\n",
        "  models[i].save(input_dir+\"model_output/biLSTM/{0}_{1}_{2}_{3}/model_{4}.h5\".format(hparams[HP_NUM_UNITS],hparams[HP_DROPOUT],hparams[HP_OPTIMIZER],hparams[HP_L2],i))"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYp53DG5lKjj"
      },
      "source": [
        "f1_score test tweets: 0.7603277015648642\n",
        "f1_score test news: 0.6831647909673162"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}