{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM_grid.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GiovanniSorice/Hate_Speech_Detection/blob/main/notebooks/Con1D_grid.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0mBfEzg_53t"
      },
      "source": [
        "#1D convolution Hate Speech Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OymXBcAV-Uk_"
      },
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Embedding, SpatialDropout1D, LSTM\n",
        "from tensorflow.keras.layers import Bidirectional # new! \n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "import os\n",
        "from sklearn.metrics import roc_auc_score \n",
        "import matplotlib.pyplot as plt\n",
        "from keras.preprocessing.text import one_hot\n",
        "from tensorboard.plugins.hparams import api as hp\n",
        "import numpy as np\n",
        "from sklearn.metrics import f1_score\n",
        "import ast \n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import StratifiedKFold"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FwrQH01T_nIS",
        "outputId": "b54dba23-f60b-40a6-c941-1121fee04c7e"
      },
      "source": [
        "from google.colab import drive\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ewn7ge0AB8n"
      },
      "source": [
        "# directory name \n",
        "input_dir = '/content/drive/My Drive/HLT/clean_dataset_training/' \n",
        "input_test_dir = \"/content/drive/My Drive/HLT/dataset_test_evalita_preprocessed/\"\n",
        "# Spec\n",
        "pd.set_option(\"display.max_colwidth\", None)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJL3UvhtALOr"
      },
      "source": [
        "tsv_file = open(input_dir+\"training_dataset.csv\")\n",
        "\n",
        "dataset = pd.read_csv(tsv_file,sep=',')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "niRStx_sEI14"
      },
      "source": [
        "### Vector-space embedding: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rA44wzytEILB"
      },
      "source": [
        "p_val=0.15 # percentage of validation set \n",
        "\n",
        "n_dim = 64 \n",
        "n_unique_words = 25000 \n",
        "max_length = 64 # doubled!\n",
        "pad_type = trunc_type = 'pre'\n",
        "\n",
        "# training \n",
        "batch_size = 64"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cP42BiElvcKH"
      },
      "source": [
        "#### Preprocess data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KU0jvqjPHTsM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8beabea1-779f-4ebc-94be-d9fd2997102d"
      },
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "all_words = []\n",
        "for index, row in dataset.iterrows():\n",
        "  tokenize_word = word_tokenize(row[\"text\"])\n",
        "  for word in tokenize_word:\n",
        "      all_words.append(word)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iaqpZHjMG6Dn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89c7fd8b-6c16-48e5-ba37-d1fa8cdb68e4"
      },
      "source": [
        "unique_words = set(all_words)\n",
        "print(len(unique_words))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "22525\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fAjg3KCQEHl3"
      },
      "source": [
        "parole_non_ric = set()\n",
        "def sentence_to_emb2(sentence, w2v, truncate = None, padding = False):\n",
        "  global parole_non_ric\n",
        "  pad_token = [0]*128\n",
        "  s_emb = [ w2v[word.lower()] for word in sentence if word.lower() in w2v.vocab]\n",
        "  parole_non_ric.update(set([ word.lower() for word in sentence if word.lower() not in w2v.vocab]))\n",
        "  if truncate is not None:\n",
        "    s_emb = s_emb[:truncate] #truncate\n",
        "  if padding:\n",
        "    s_emb += [pad_token] * (truncate - len(s_emb))\n",
        "  return np.array(s_emb)\n",
        "\n",
        "def get_data_to_emb2(data, w2v, truncate = None, padding = False):\n",
        "  X = [sentence_to_emb2(ast.literal_eval(sentence), w2v, truncate, padding) for sentence in data]\n",
        "  print(len(X))\n",
        "  print(X[0])\n",
        "  return np.array(X)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dd6KYgWqEKXs"
      },
      "source": [
        "from gensim.models import KeyedVectors\n",
        "from gensim.test.utils import datapath\n",
        "w2v_felice_path = \"/content/drive/My Drive/HLT/w2v/twitter128.bin\"\n",
        "w2v = KeyedVectors.load_word2vec_format(datapath(w2v_felice_path), binary=True)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V97RhoGzTonm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8cad6c7-6a8b-43d9-edd3-6332a7302084"
      },
      "source": [
        "X_dev = get_data_to_emb2(dataset[\"tokens\"], w2v, max_length , True)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6837\n",
            "[[ 1.47564483  0.12307259  1.0753547  ...  1.06197035  1.90046942\n",
            "  -0.19663759]\n",
            " [-2.10587931  1.7696439  -1.04741096 ... -1.11571276 -0.25399542\n",
            "  -0.97522277]\n",
            " [ 0.89639139  1.24942708  0.72824973 ...  0.68920714  0.98506999\n",
            "  -0.36202168]\n",
            " ...\n",
            " [ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]\n",
            " [ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]\n",
            " [ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "URGejkayq4T3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e246a25a-b492-4bf6-c51d-d2297ee59867"
      },
      "source": [
        "len(parole_non_ric)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2159"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMnXywTcqSy1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "adb206a8-3584-4be9-c0ae-d7d4658488c4"
      },
      "source": [
        "dataset_other = dataset\n",
        "dataset_other = dataset.drop(['text', 'id', 'hs', 'stereotype','tokens', 'hashtags'], axis=1)\n",
        "dataset_other"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text_length</th>\n",
              "      <th>#C-L words</th>\n",
              "      <th>#?!</th>\n",
              "      <th>#.,</th>\n",
              "      <th>#bad_words</th>\n",
              "      <th>%bad_words</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>120</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>101</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>86</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>118</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>138</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6832</th>\n",
              "      <td>285</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6833</th>\n",
              "      <td>277</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6834</th>\n",
              "      <td>233</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6835</th>\n",
              "      <td>206</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6836</th>\n",
              "      <td>285</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6837 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      text_length  #C-L words  #?!  #.,  #bad_words  %bad_words\n",
              "0             120          10    0    5           0           0\n",
              "1             101           0    0    0           1           6\n",
              "2              86           8    0    1           3          25\n",
              "3             118           0    0    2           0           0\n",
              "4             138           0    1    1           1           4\n",
              "...           ...         ...  ...  ...         ...         ...\n",
              "6832          285           2    0    4           0           0\n",
              "6833          277           0    2    3           0           0\n",
              "6834          233           0    0    4           0           0\n",
              "6835          206           2    0    2           0           0\n",
              "6836          285           7    1    5           0           0\n",
              "\n",
              "[6837 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7TX3TS1yTlR"
      },
      "source": [
        "x_train, x_valid, x_train_extra, x_valid_extra, y_train, y_valid = train_test_split(X_dev, dataset_other.values , dataset[['hs']], test_size=p_val, random_state=128)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRF1dwdVpKSo"
      },
      "source": [
        "input_train = {\"text\": x_train, \"other\": x_train_extra}\n",
        "input_val   = {\"text\": x_valid, \"other\": x_valid_extra}"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXitI_XKIZN7"
      },
      "source": [
        "max_sent = 0 "
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCxWTGMOHVzc"
      },
      "source": [
        "\n",
        "def comment_length(text):\n",
        "    global max_sent \n",
        "    text = ast.literal_eval(text)\n",
        "    if len(text)>max_sent: \n",
        "      max_sent = len(text)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vmnRA9uGIKjJ",
        "outputId": "ddf6656a-4af1-4165-cf02-1684f51cf012"
      },
      "source": [
        "dataset['tokens'].apply(comment_length)\n",
        "print(max_sent)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "121\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oVbNT3FOisHf",
        "outputId": "7f741fb3-a9fa-48ef-be83-3aa995c2ae11"
      },
      "source": [
        "x_train_extra.shape"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5811, 6)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uAUJfLg_BGTX"
      },
      "source": [
        "### Design grid search parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PC8zF9NNBJso"
      },
      "source": [
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard\n",
        "\n",
        "# Clear any logs from previous runs\n",
        "!rm -rf ./logs/\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorboard.plugins.hparams import api as hp"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JJ6QHGwBXVJ"
      },
      "source": [
        "HP_NUM_UNITS = hp.HParam('num_units', hp.Discrete([64]))\n",
        "HP_DROPOUT = hp.HParam('dropout', hp.RealInterval(0.0, 0.1))\n",
        "HP_L2 = hp.HParam('L2_reg', hp.RealInterval(0.0, 0.0001))\n",
        "HP_OPTIMIZER = hp.HParam('optimizer', hp.Discrete(['nadam']))\n",
        "\n",
        "METRIC_ACCURACY = 'accuracy'\n",
        "\n",
        "with tf.summary.create_file_writer('logs/hparam_tuning').as_default():\n",
        "  hp.hparams_config(\n",
        "    hparams=[HP_NUM_UNITS, HP_DROPOUT, HP_OPTIMIZER],\n",
        "    metrics=[hp.Metric(METRIC_ACCURACY, display_name='Accuracy')],\n",
        "  )"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXFVlKlA7CUr"
      },
      "source": [
        "class FCallback(tf.keras.callbacks.Callback):\n",
        "  \n",
        "    def __init__(self, validation = (), verbose = 0):\n",
        "        self.validation = validation\n",
        "        self.verbose = verbose\n",
        "\n",
        "    def on_train_begin(self, logs={}):\n",
        "        self.f1 = []\n",
        "        self.val_f1 = []\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        y_t =  self.validation[1]\n",
        "        y_p =  np.where(self.model.predict(self.validation[0]) > 0.5, 1, 0)\n",
        "        logs['val_f1'] =  f1_score(y_t, y_p, average='macro')\n",
        "        if self.verbose >0:\n",
        "          print(\"— val_f1: {}\".format(logs['val_f1']))"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJjzp8CnwARN"
      },
      "source": [
        "def get_model(hparams):\n",
        "  embedding_dim =128\n",
        "  num_filters = 256\n",
        "  conv1D_in = tf.keras.layers.Input(name=\"text\", shape =(max_length,128,))\n",
        "\n",
        "  reshape_4 = tf.keras.layers.Reshape((max_length, embedding_dim, 1))(conv1D_in)\n",
        "  conv_0_4 = tf.keras.layers.Conv2D(num_filters, kernel_size=(3, embedding_dim), padding='valid', kernel_initializer='normal', activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.0007))(reshape_4)\n",
        "  conv_1_4 = tf.keras.layers.Conv2D(num_filters, kernel_size=(4, embedding_dim), padding='valid', kernel_initializer='normal', activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.0007))(reshape_4)\n",
        "  conv_2_4 = tf.keras.layers.Conv2D(num_filters, kernel_size=(5, embedding_dim), padding='valid', kernel_initializer='normal', activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.0007))(reshape_4)\n",
        "\n",
        "  maxpool_0_4 = tf.keras.layers.MaxPool2D(pool_size=(max_length - 3 + 1, 1), strides=(1,1), padding='valid')(conv_0_4)\n",
        "  maxpool_1_4 = tf.keras.layers.MaxPool2D(pool_size=(max_length - 4 + 1, 1), strides=(1,1), padding='valid')(conv_1_4)\n",
        "  maxpool_2_4 = tf.keras.layers.MaxPool2D(pool_size=(max_length - 5 + 1, 1), strides=(1,1), padding='valid')(conv_2_4)\n",
        "\n",
        "  concatenated_tensor_4 = tf.keras.layers.Concatenate(axis=1)([maxpool_0_4, maxpool_1_4, maxpool_2_4])\n",
        "  flatten_4 = tf.keras.layers.Flatten()(concatenated_tensor_4)\n",
        "\n",
        "  dropout_4 = tf.keras.layers.Dropout(0.5)(flatten_4)\n",
        "  # note the different activation\n",
        "  other_in = tf.keras.layers.Input(name=\"other\", shape =(6,))\n",
        "  lconcat = tf.keras.layers.Concatenate(axis=1)([dropout_4, other_in])\n",
        "\n",
        "  dense1_layer = Dense(256, activation=\"relu\", kernel_regularizer=tf.keras.regularizers.l2(hparams[HP_L2]))(lconcat)\n",
        "  dense2_layer = Dense(128, activation=\"relu\", kernel_regularizer=tf.keras.regularizers.l2(hparams[HP_L2]))(dense1_layer)\n",
        "  dense3_layer = Dense(32, activation=\"relu\", kernel_regularizer=tf.keras.regularizers.l2(hparams[HP_L2]))(dense2_layer)\n",
        "\n",
        "  output_4 = tf.keras.layers.Dense(units=1, activation='sigmoid')(dense3_layer)\n",
        "\n",
        "  model = tf.keras.Model(inputs = [conv1D_in, other_in], outputs = output_4)\n",
        "  \n",
        "  # model.summary()\n",
        "  \n",
        "  return model"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4nNvvQRCcFP"
      },
      "source": [
        "def train_test_model(hparams):\n",
        "  \n",
        "  model = get_model(hparams)\n",
        "  model.compile(\n",
        "      optimizer=hparams[HP_OPTIMIZER],\n",
        "      loss='binary_crossentropy',\n",
        "      metrics=['accuracy'],\n",
        "  )\n",
        "\n",
        "  model.summary()\n",
        "\n",
        "  f1_callback = FCallback(validation = (input_val, y_valid), verbose=True)                                   \n",
        "\n",
        "  #filepath = input_dir + \"model_output/biLSTM/HP_NUM_UNITS={0}/HP_DROPOUT={1}/HP_L2={2}/\".format(hparams[HP_NUM_UNITS],hparams[HP_DROPOUT],hparams[HP_L2])\n",
        "  #filepath += \"saved-model-{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n",
        "  #checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=False, mode='max')\n",
        "\n",
        "  model.fit(input_train, y_train, batch_size=batch_size, validation_data=(input_val, y_valid), epochs=30, callbacks=[f1_callback]) # Run with 1 epoch to speed things up for demo purposes\n",
        "  _, accuracy = model.evaluate(input_val, y_valid)\n",
        "\n",
        "  y_test_pred_tweets = np.where(model.predict(input_test_tweets) > 0.5, 1, 0)\n",
        "  y_test_pred_news = np.where(model.predict(input_test_news) > 0.5, 1, 0)\n",
        "\n",
        "  print(\"f1_score test tweets: {}\".format(f1_score(y_test_tweets, y_test_pred_tweets,average=\"macro\")))\n",
        "  print(\"f1_score test news: {}\".format(f1_score(y_test_news, y_test_pred_news,average=\"macro\")))\n",
        "  return accuracy"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OaO2zq3-Adck"
      },
      "source": [
        "def run(run_dir, hparams):\n",
        "  with tf.summary.create_file_writer(run_dir).as_default():\n",
        "    hp.hparams(hparams)  # record the values used in this trial\n",
        "    accuracy = train_test_model(hparams)\n",
        "    tf.summary.scalar(METRIC_ACCURACY, accuracy, step=1)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9CaPr2dcL4tD",
        "outputId": "ac4a9b97-b65c-4e3a-8f37-13313ccd2157"
      },
      "source": [
        "session_num = 0\n",
        "\n",
        "for num_units in HP_NUM_UNITS.domain.values:\n",
        "  for dropout_rate in np.arange(HP_DROPOUT.domain.min_value, HP_DROPOUT.domain.max_value, 0.2):\n",
        "      for L2_rate in np.arange(HP_L2.domain.min_value, HP_L2.domain.max_value, 0.0002):\n",
        "        for optimizer in HP_OPTIMIZER.domain.values:\n",
        "          hparams = {\n",
        "              HP_NUM_UNITS: num_units,\n",
        "              HP_DROPOUT: dropout_rate,\n",
        "              HP_OPTIMIZER: optimizer,\n",
        "              HP_L2: 0.0007,\n",
        "          }\n",
        "          run_name = \"run-%d\" % session_num\n",
        "          print('--- Starting trial: %s' % run_name)\n",
        "          print({h.name: hparams[h] for h in hparams})\n",
        "          run('logs/hparam_tuning/' + run_name, hparams)\n",
        "          session_num += 1\n"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--- Starting trial: run-0\n",
            "{'num_units': 64, 'dropout': 0.0, 'optimizer': 'nadam', 'L2_reg': 0.0007}\n",
            "Model: \"model_8\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "text (InputLayer)               [(None, 64, 128)]    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "reshape_12 (Reshape)            (None, 64, 128, 1)   0           text[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 62, 1, 256)   98560       reshape_12[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 61, 1, 256)   131328      reshape_12[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 60, 1, 256)   164096      reshape_12[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_27 (MaxPooling2D) (None, 1, 1, 256)    0           conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_28 (MaxPooling2D) (None, 1, 1, 256)    0           conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_29 (MaxPooling2D) (None, 1, 1, 256)    0           conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_18 (Concatenate)    (None, 3, 1, 256)    0           max_pooling2d_27[0][0]           \n",
            "                                                                 max_pooling2d_28[0][0]           \n",
            "                                                                 max_pooling2d_29[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "flatten_9 (Flatten)             (None, 768)          0           concatenate_18[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dropout_9 (Dropout)             (None, 768)          0           flatten_9[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "other (InputLayer)              [(None, 6)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_19 (Concatenate)    (None, 774)          0           dropout_9[0][0]                  \n",
            "                                                                 other[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_27 (Dense)                (None, 256)          198400      concatenate_19[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dense_28 (Dense)                (None, 128)          32896       dense_27[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_29 (Dense)                (None, 32)           4128        dense_28[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_30 (Dense)                (None, 1)            33          dense_29[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 629,441\n",
            "Trainable params: 629,441\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/30\n",
            "91/91 [==============================] - 14s 134ms/step - loss: 2.2420 - accuracy: 0.5794 - val_loss: 1.5621 - val_accuracy: 0.6559\n",
            "— val_f1: 0.6559372479577752\n",
            "Epoch 2/30\n",
            "91/91 [==============================] - 12s 132ms/step - loss: 1.5125 - accuracy: 0.6855 - val_loss: 1.4079 - val_accuracy: 0.6745\n",
            "— val_f1: 0.674340192116897\n",
            "Epoch 3/30\n",
            "91/91 [==============================] - 12s 132ms/step - loss: 1.3474 - accuracy: 0.7141 - val_loss: 1.2338 - val_accuracy: 0.7300\n",
            "— val_f1: 0.7273776349552747\n",
            "Epoch 4/30\n",
            "91/91 [==============================] - 12s 132ms/step - loss: 1.1686 - accuracy: 0.7642 - val_loss: 1.1133 - val_accuracy: 0.7612\n",
            "— val_f1: 0.7412427389544094\n",
            "Epoch 5/30\n",
            "91/91 [==============================] - 12s 132ms/step - loss: 1.0400 - accuracy: 0.7950 - val_loss: 1.0448 - val_accuracy: 0.7544\n",
            "— val_f1: 0.7244850985473642\n",
            "Epoch 6/30\n",
            "91/91 [==============================] - 12s 134ms/step - loss: 0.9272 - accuracy: 0.8148 - val_loss: 0.9689 - val_accuracy: 0.7554\n",
            "— val_f1: 0.7522480617171949\n",
            "Epoch 7/30\n",
            "91/91 [==============================] - 12s 133ms/step - loss: 0.8322 - accuracy: 0.8429 - val_loss: 1.3841 - val_accuracy: 0.6569\n",
            "— val_f1: 0.5157262390045055\n",
            "Epoch 8/30\n",
            "91/91 [==============================] - 12s 133ms/step - loss: 0.8085 - accuracy: 0.8326 - val_loss: 0.8910 - val_accuracy: 0.7612\n",
            "— val_f1: 0.7543859649122807\n",
            "Epoch 9/30\n",
            "91/91 [==============================] - 12s 132ms/step - loss: 0.7196 - accuracy: 0.8661 - val_loss: 0.9066 - val_accuracy: 0.7485\n",
            "— val_f1: 0.7471506352087114\n",
            "Epoch 10/30\n",
            "91/91 [==============================] - 12s 131ms/step - loss: 0.6604 - accuracy: 0.8902 - val_loss: 0.8726 - val_accuracy: 0.7593\n",
            "— val_f1: 0.7533353773378302\n",
            "Epoch 11/30\n",
            "91/91 [==============================] - 12s 133ms/step - loss: 0.6404 - accuracy: 0.8887 - val_loss: 0.8628 - val_accuracy: 0.7544\n",
            "— val_f1: 0.7519342359767892\n",
            "Epoch 12/30\n",
            "91/91 [==============================] - 12s 134ms/step - loss: 0.6085 - accuracy: 0.9055 - val_loss: 0.8263 - val_accuracy: 0.7632\n",
            "— val_f1: 0.7533095005100672\n",
            "Epoch 13/30\n",
            "91/91 [==============================] - 12s 134ms/step - loss: 0.5718 - accuracy: 0.9178 - val_loss: 0.8799 - val_accuracy: 0.7739\n",
            "— val_f1: 0.7695890718591856\n",
            "Epoch 14/30\n",
            "91/91 [==============================] - 12s 134ms/step - loss: 0.5597 - accuracy: 0.9158 - val_loss: 0.8792 - val_accuracy: 0.7690\n",
            "— val_f1: 0.7519552388772996\n",
            "Epoch 15/30\n",
            "91/91 [==============================] - 12s 135ms/step - loss: 0.5352 - accuracy: 0.9264 - val_loss: 1.1013 - val_accuracy: 0.6852\n",
            "— val_f1: 0.6844053996143133\n",
            "Epoch 16/30\n",
            "91/91 [==============================] - 12s 133ms/step - loss: 0.5113 - accuracy: 0.9302 - val_loss: 0.9222 - val_accuracy: 0.7758\n",
            "— val_f1: 0.768040325085616\n",
            "Epoch 17/30\n",
            "91/91 [==============================] - 12s 134ms/step - loss: 0.4799 - accuracy: 0.9414 - val_loss: 0.8965 - val_accuracy: 0.7583\n",
            "— val_f1: 0.7350217649386624\n",
            "Epoch 18/30\n",
            "91/91 [==============================] - 12s 134ms/step - loss: 0.4763 - accuracy: 0.9442 - val_loss: 1.4792 - val_accuracy: 0.6559\n",
            "— val_f1: 0.6524426932241401\n",
            "Epoch 19/30\n",
            "91/91 [==============================] - 12s 134ms/step - loss: 0.4961 - accuracy: 0.9309 - val_loss: 0.9727 - val_accuracy: 0.7719\n",
            "— val_f1: 0.7541382488479262\n",
            "Epoch 20/30\n",
            "91/91 [==============================] - 12s 133ms/step - loss: 0.4396 - accuracy: 0.9524 - val_loss: 0.9858 - val_accuracy: 0.7534\n",
            "— val_f1: 0.7227900618862766\n",
            "Epoch 21/30\n",
            "91/91 [==============================] - 12s 133ms/step - loss: 0.4391 - accuracy: 0.9494 - val_loss: 0.8884 - val_accuracy: 0.7690\n",
            "— val_f1: 0.7571165872743962\n",
            "Epoch 22/30\n",
            "91/91 [==============================] - 12s 135ms/step - loss: 0.4136 - accuracy: 0.9601 - val_loss: 0.8479 - val_accuracy: 0.7563\n",
            "— val_f1: 0.7463058572191561\n",
            "Epoch 23/30\n",
            "91/91 [==============================] - 12s 135ms/step - loss: 0.4163 - accuracy: 0.9589 - val_loss: 1.1003 - val_accuracy: 0.7446\n",
            "— val_f1: 0.7151739395788832\n",
            "Epoch 24/30\n",
            "91/91 [==============================] - 13s 138ms/step - loss: 0.4030 - accuracy: 0.9622 - val_loss: 1.0341 - val_accuracy: 0.7534\n",
            "— val_f1: 0.7498156710009282\n",
            "Epoch 25/30\n",
            "91/91 [==============================] - 12s 137ms/step - loss: 0.3982 - accuracy: 0.9607 - val_loss: 0.9286 - val_accuracy: 0.7602\n",
            "— val_f1: 0.7397260273972602\n",
            "Epoch 26/30\n",
            "91/91 [==============================] - 12s 137ms/step - loss: 0.3848 - accuracy: 0.9652 - val_loss: 1.0926 - val_accuracy: 0.7281\n",
            "— val_f1: 0.7277533617829076\n",
            "Epoch 27/30\n",
            "91/91 [==============================] - 12s 136ms/step - loss: 0.4131 - accuracy: 0.9530 - val_loss: 0.9924 - val_accuracy: 0.7749\n",
            "— val_f1: 0.7682652699054605\n",
            "Epoch 28/30\n",
            "91/91 [==============================] - 12s 136ms/step - loss: 0.3854 - accuracy: 0.9592 - val_loss: 0.9210 - val_accuracy: 0.7719\n",
            "— val_f1: 0.7623495407031993\n",
            "Epoch 29/30\n",
            "91/91 [==============================] - 12s 135ms/step - loss: 0.3757 - accuracy: 0.9659 - val_loss: 0.9723 - val_accuracy: 0.7388\n",
            "— val_f1: 0.7360797036070106\n",
            "Epoch 30/30\n",
            "91/91 [==============================] - 12s 135ms/step - loss: 0.3991 - accuracy: 0.9485 - val_loss: 0.9825 - val_accuracy: 0.7554\n",
            "— val_f1: 0.7280758903163611\n",
            "33/33 [==============================] - 1s 22ms/step - loss: 0.9825 - accuracy: 0.7554\n",
            "f1_score test tweets: 0.732100135387838\n",
            "f1_score test news: 0.5723809038338459\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUvnMoP9EsnU"
      },
      "source": [
        "### Test phase"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZVkUrF2luNH"
      },
      "source": [
        "csv_test_tweets_file = open(input_test_dir+\"test_dataset_tweets.csv\")\n",
        "\n",
        "testset_tweets = pd.read_csv(csv_test_tweets_file,sep=',')\n",
        "\n",
        "csv_test_news_file = open(input_test_dir+\"test_dataset_news.csv\")\n",
        "\n",
        "testset_news = pd.read_csv(csv_test_news_file,sep=',')"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEA-Q8phFM71",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a98b3ad-2403-4584-9857-e79a2dde5d1e"
      },
      "source": [
        "X_test_news = get_data_to_emb2(testset_news[\"tokens\"], w2v, max_length , True)\n",
        "X_test_tweets = get_data_to_emb2(testset_tweets[\"tokens\"], w2v, max_length , True)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "500\n",
            "[[ 0.4473033  -1.85372221  1.80903184 ... -0.81329495 -0.37441084\n",
            "   0.67255157]\n",
            " [ 0.65353721  2.91942644  0.83319777 ...  0.10994434  0.79807943\n",
            "  -0.64684689]\n",
            " [ 0.27626377  0.63812095  1.54855597 ... -0.60746866  1.20815647\n",
            "   0.78223377]\n",
            " ...\n",
            " [ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]\n",
            " [ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]\n",
            " [ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]]\n",
            "1263\n",
            "[[ 0.85021353  0.94971675  0.95175791 ...  0.66373271  0.95456082\n",
            "   0.80749106]\n",
            " [ 1.86031258  0.98840606 -2.10821915 ...  1.14880133  0.14479998\n",
            "  -0.10640591]\n",
            " [-1.32805312  0.75008422  0.24781393 ... -0.08247134 -0.89805609\n",
            "  -0.75278544]\n",
            " ...\n",
            " [ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]\n",
            " [ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]\n",
            " [ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RL4fJuI-7egi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "2853da7d-5867-4b3d-8361-5c8aac47fbf3"
      },
      "source": [
        "testset_tweets_other = testset_tweets\n",
        "testset_tweets_other = testset_tweets.drop(['text', 'id', 'hs', 'stereotype','tokens', 'hashtags'], axis=1)\n",
        "testset_tweets_other"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text_length</th>\n",
              "      <th>#C-L words</th>\n",
              "      <th>#?!</th>\n",
              "      <th>#.,</th>\n",
              "      <th>#bad_words</th>\n",
              "      <th>%bad_words</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>180</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>227</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>259</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>99</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>257</td>\n",
              "      <td>87</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1258</th>\n",
              "      <td>216</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1259</th>\n",
              "      <td>159</td>\n",
              "      <td>81</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1260</th>\n",
              "      <td>278</td>\n",
              "      <td>32</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1261</th>\n",
              "      <td>128</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1262</th>\n",
              "      <td>284</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1263 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      text_length  #C-L words  #?!  #.,  #bad_words  %bad_words\n",
              "0             180           4    1    4           0           0\n",
              "1             227           5    4    5           0           0\n",
              "2             259           2    2    4           1           2\n",
              "3              99           7    0    2           0           0\n",
              "4             257          87    2    0           0           0\n",
              "...           ...         ...  ...  ...         ...         ...\n",
              "1258          216           0    0    5           0           0\n",
              "1259          159          81    3    1           1           3\n",
              "1260          278          32    4    7           1           2\n",
              "1261          128           0    1    3           0           0\n",
              "1262          284           2    2    9           0           0\n",
              "\n",
              "[1263 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIXr4PJLF36A",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "7b812adc-a443-41f0-d7e0-326e134b98da"
      },
      "source": [
        "testset_news_other = testset_news\n",
        "testset_news_other = testset_news.drop(['text', 'id', 'hs', 'stereotype','tokens', 'hashtags'], axis=1)\n",
        "testset_news_other"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text_length</th>\n",
              "      <th>#C-L words</th>\n",
              "      <th>#?!</th>\n",
              "      <th>#.,</th>\n",
              "      <th>#bad_words</th>\n",
              "      <th>%bad_words</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>102</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>108</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>48</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>112</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>117</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>495</th>\n",
              "      <td>80</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>496</th>\n",
              "      <td>60</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>497</th>\n",
              "      <td>86</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498</th>\n",
              "      <td>92</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499</th>\n",
              "      <td>67</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>500 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     text_length  #C-L words  #?!  #.,  #bad_words  %bad_words\n",
              "0            102           0    1    5           0           0\n",
              "1            108           0    0    1           0           0\n",
              "2             48           0    0    0           0           0\n",
              "3            112           0    0    5           0           0\n",
              "4            117           0    0    6           0           0\n",
              "..           ...         ...  ...  ...         ...         ...\n",
              "495           80           0    0    2           0           0\n",
              "496           60           0    0    0           0           0\n",
              "497           86           0    0    2           0           0\n",
              "498           92           0    0    0           0           0\n",
              "499           67           0    0    1           0           0\n",
              "\n",
              "[500 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CR69UbzM7nN8"
      },
      "source": [
        "input_test_tweets   = {\"text\": X_test_tweets, \"other\": testset_tweets_other.values}\n",
        "y_test_tweets = testset_tweets[['hs']]\n"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vhoi6YkbGJyj"
      },
      "source": [
        "input_test_news   = {\"text\": X_test_news, \"other\": testset_news_other.values}\n",
        "y_test_news = testset_news[['hs']]\n"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imavSMMX17qH"
      },
      "source": [
        "x_kfold = X_dev\n",
        "x_other_kfold = dataset_other\n",
        "y_kfold = dataset[['hs']]"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUsrgeL_xUkK"
      },
      "source": [
        "def train_test_model_with_kfold(hparams):\n",
        "  number_of_splits = 5\n",
        "  cv_kfold = StratifiedKFold(n_splits=number_of_splits, shuffle=True, random_state=100)\n",
        "  models = []\n",
        "  for train_index, validation_index in cv_kfold.split(x_kfold, y_kfold):\n",
        "    model = get_model(hparams)\n",
        "    model.compile(\n",
        "        optimizer=hparams[HP_OPTIMIZER],\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy'],\n",
        "    )\n",
        "\n",
        "    input_train_kfold = {\"text\": x_kfold[train_index], \"other\": x_other_kfold.loc[train_index]}\n",
        "    input_val_kfold   = {\"text\": x_kfold[validation_index], \"other\": x_other_kfold.loc[validation_index]}\n",
        "    y_train_kfold = y_kfold.loc[train_index]\n",
        "    y_valid_kfold = y_kfold.loc[validation_index]\n",
        "\n",
        "    f1_callback = FCallback(validation = (input_val_kfold, y_valid_kfold), verbose=True)                                   \n",
        "\n",
        "    #filepath = input_dir + \"model_output/biLSTM/HP_NUM_UNITS={0}/HP_DROPOUT={1}/HP_L2={2}/\".format(hparams[HP_NUM_UNITS],hparams[HP_DROPOUT],hparams[HP_L2])\n",
        "    #filepath += \"saved-model-{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n",
        "    #checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=False, mode='max')\n",
        "\n",
        "\n",
        "    model.fit(input_train_kfold, y_train_kfold, batch_size=batch_size, validation_data=(input_val_kfold, y_valid_kfold), epochs=10, callbacks=[f1_callback]) # Run with 1 epoch to speed things up for demo purposes\n",
        "    _, accuracy = model.evaluate(input_val_kfold, y_valid_kfold)\n",
        "\n",
        "    #y_test_pred = np.where(model.predict(input_test)[0] > 0.5, 1, 0)\n",
        "    #y_test_pred_tweets = np.where(model.predict(input_test_tweets) > 0.5, 1, 0)\n",
        "    #y_test_pred_news = np.where(model.predict(input_test_news) > 0.5, 1, 0)\n",
        "\n",
        "    #print(\"f1_score test tweets: {}\".format(f1_score(y_test_tweets, y_test_pred_tweets,average=\"macro\")))\n",
        "    #print(\"f1_score test news: {}\".format(f1_score(y_test_news, y_test_pred_news,average=\"macro\")))\n",
        "    models.append(model)\n",
        "\n",
        "  return models"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnwToktaH-uQ"
      },
      "source": [
        "def predict_with_ensemble(models, test_input):\n",
        "  # make predictions\n",
        "  results = []\n",
        "  y_predict = [np.squeeze(np.where(model.predict(test_input) > 0.5, 1,0).reshape(1,-1)) for model in models]\n",
        "  # sum across ensemble members\n",
        "  y_predict = np.array(y_predict)\n",
        "\n",
        "  for i in range(y_predict.shape[1]):\n",
        "    counts = np.bincount(y_predict[:,i])\n",
        "    results.append(np.argmax(counts))\n",
        "  # argmax across classes\n",
        "  return results"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T24mBhARv8Hx"
      },
      "source": [
        "def run_with_kfold(run_dir, hparams):\n",
        "  with tf.summary.create_file_writer(run_dir).as_default():\n",
        "    hp.hparams(hparams)  # record the values used in this trial\n",
        "    models = train_test_model_with_kfold(hparams)\n",
        "    y_test_pred_tweets = predict_with_ensemble(models, input_test_tweets)\n",
        "    y_test_pred_news = predict_with_ensemble(models, input_test_news)\n",
        "\n",
        "    print(\"f1_score test tweets: {}\".format(f1_score(y_test_tweets, y_test_pred_tweets,average=\"macro\")))\n",
        "    print(\"f1_score test news: {}\".format(f1_score(y_test_news, y_test_pred_news,average=\"macro\")))\n",
        "    return models\n"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_Y4HvcNcxJs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a558f750-dc0d-44e2-95ff-6468853251f9"
      },
      "source": [
        "y_test_pred_tweets = predict_with_ensemble(models, input_test_tweets)\n",
        "y_test_pred_news = predict_with_ensemble(models, input_test_news)\n",
        "\n",
        "print(\"f1_score test tweets: {}\".format(f1_score(y_test_tweets, y_test_pred_tweets,average=\"macro\")))\n",
        "print(\"f1_score test news: {}\".format(f1_score(y_test_news, y_test_pred_news,average=\"macro\")))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "f1_score test tweets: 0.729492743586192\n",
            "f1_score test news: 0.7092327164505866\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISaRu-AfD6Vz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a93ab950-6a60-4fdf-db74-199e45b7b384"
      },
      "source": [
        "hparams = {\n",
        "    HP_NUM_UNITS: 64,\n",
        "    HP_DROPOUT: 0.4,\n",
        "    HP_OPTIMIZER: \"nadam\",\n",
        "    HP_L2: 0.0000,\n",
        "}\n",
        "run_name = \"run-test\" \n",
        "print('--- Starting trial: %s' % run_name)\n",
        "print({h.name: hparams[h] for h in hparams})\n",
        "models = run_with_kfold('logs/hparam_tuning/' + run_name, hparams)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--- Starting trial: run-test\n",
            "{'num_units': 64, 'dropout': 0.4, 'optimizer': 'nadam', 'L2_reg': 0.0}\n",
            "Epoch 1/10\n",
            "86/86 [==============================] - 8s 35ms/step - loss: 0.8481 - accuracy: 0.5801 - val_loss: 0.6349 - val_accuracy: 0.6250\n",
            "— val_f1: 0.48938845269823394\n",
            "Epoch 2/10\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.6177 - accuracy: 0.6672 - val_loss: 0.5447 - val_accuracy: 0.7390\n",
            "— val_f1: 0.7283756298029515\n",
            "Epoch 3/10\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.5815 - accuracy: 0.7062 - val_loss: 0.5056 - val_accuracy: 0.7624\n",
            "— val_f1: 0.7494792086337827\n",
            "Epoch 4/10\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.5230 - accuracy: 0.7305 - val_loss: 0.5711 - val_accuracy: 0.7200\n",
            "— val_f1: 0.7199859978034722\n",
            "Epoch 5/10\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.5059 - accuracy: 0.7459 - val_loss: 0.4862 - val_accuracy: 0.7697\n",
            "— val_f1: 0.7548603269325399\n",
            "Epoch 6/10\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.5005 - accuracy: 0.7642 - val_loss: 0.4633 - val_accuracy: 0.7844\n",
            "— val_f1: 0.7756832306595155\n",
            "Epoch 7/10\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.4464 - accuracy: 0.7767 - val_loss: 0.4883 - val_accuracy: 0.7697\n",
            "— val_f1: 0.7490237190407547\n",
            "Epoch 8/10\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.4617 - accuracy: 0.7749 - val_loss: 0.5009 - val_accuracy: 0.7756\n",
            "— val_f1: 0.7735713557866338\n",
            "Epoch 9/10\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.4183 - accuracy: 0.8021 - val_loss: 0.5537 - val_accuracy: 0.7251\n",
            "— val_f1: 0.7248615663753926\n",
            "Epoch 10/10\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.4132 - accuracy: 0.8021 - val_loss: 0.5081 - val_accuracy: 0.7858\n",
            "— val_f1: 0.7716288644287104\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.5081 - accuracy: 0.7858\n",
            "Epoch 1/10\n",
            "86/86 [==============================] - 9s 36ms/step - loss: 1.0968 - accuracy: 0.5571 - val_loss: 0.5625 - val_accuracy: 0.7091\n",
            "— val_f1: 0.6974527672816181\n",
            "Epoch 2/10\n",
            "86/86 [==============================] - 2s 23ms/step - loss: 0.7199 - accuracy: 0.6604 - val_loss: 1.5320 - val_accuracy: 0.6001\n",
            "— val_f1: 0.38834672907203616\n",
            "Epoch 3/10\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.6522 - accuracy: 0.7020 - val_loss: 0.6477 - val_accuracy: 0.7039\n",
            "— val_f1: 0.6425398484452574\n",
            "Epoch 4/10\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.5564 - accuracy: 0.7355 - val_loss: 0.5182 - val_accuracy: 0.7405\n",
            "— val_f1: 0.7382410883444411\n",
            "Epoch 5/10\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.4900 - accuracy: 0.7699 - val_loss: 0.5141 - val_accuracy: 0.7500\n",
            "— val_f1: 0.7452913391999687\n",
            "Epoch 6/10\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.4881 - accuracy: 0.7579 - val_loss: 0.5430 - val_accuracy: 0.7398\n",
            "— val_f1: 0.738733538337407\n",
            "Epoch 7/10\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.4577 - accuracy: 0.7786 - val_loss: 0.5538 - val_accuracy: 0.7208\n",
            "— val_f1: 0.7207118807118807\n",
            "Epoch 8/10\n",
            "86/86 [==============================] - 2s 20ms/step - loss: 0.4749 - accuracy: 0.7832 - val_loss: 0.5701 - val_accuracy: 0.7281\n",
            "— val_f1: 0.7279020974534132\n",
            "Epoch 9/10\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.4160 - accuracy: 0.8106 - val_loss: 0.5056 - val_accuracy: 0.7639\n",
            "— val_f1: 0.7399574740804344\n",
            "Epoch 10/10\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.3965 - accuracy: 0.8185 - val_loss: 0.4934 - val_accuracy: 0.7749\n",
            "— val_f1: 0.7641062390827249\n",
            "43/43 [==============================] - 0s 8ms/step - loss: 0.4934 - accuracy: 0.7749\n",
            "Epoch 1/10\n",
            "86/86 [==============================] - 9s 36ms/step - loss: 0.7932 - accuracy: 0.5973 - val_loss: 0.6704 - val_accuracy: 0.6547\n",
            "— val_f1: 0.6535613343298712\n",
            "Epoch 2/10\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.5818 - accuracy: 0.6950 - val_loss: 0.5502 - val_accuracy: 0.7308\n",
            "— val_f1: 0.7187431510678743\n",
            "Epoch 3/10\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.5306 - accuracy: 0.7247 - val_loss: 0.5210 - val_accuracy: 0.7425\n",
            "— val_f1: 0.7280622832677015\n",
            "Epoch 4/10\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.5174 - accuracy: 0.7492 - val_loss: 0.8453 - val_accuracy: 0.6635\n",
            "— val_f1: 0.6600825981664074\n",
            "Epoch 5/10\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.5184 - accuracy: 0.7548 - val_loss: 0.5959 - val_accuracy: 0.7352\n",
            "— val_f1: 0.7345488681471946\n",
            "Epoch 6/10\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.4736 - accuracy: 0.7621 - val_loss: 0.6741 - val_accuracy: 0.6979\n",
            "— val_f1: 0.6353684898532808\n",
            "Epoch 7/10\n",
            "86/86 [==============================] - 2s 22ms/step - loss: 0.4646 - accuracy: 0.7814 - val_loss: 0.5384 - val_accuracy: 0.7579\n",
            "— val_f1: 0.7547514245465923\n",
            "Epoch 8/10\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.4344 - accuracy: 0.7944 - val_loss: 0.5483 - val_accuracy: 0.7447\n",
            "— val_f1: 0.7154877165152413\n",
            "Epoch 9/10\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.4336 - accuracy: 0.7952 - val_loss: 0.5088 - val_accuracy: 0.7703\n",
            "— val_f1: 0.7629315677385717\n",
            "Epoch 10/10\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.4061 - accuracy: 0.8076 - val_loss: 0.5249 - val_accuracy: 0.7681\n",
            "— val_f1: 0.7611052888943526\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.5249 - accuracy: 0.7681\n",
            "Epoch 1/10\n",
            "86/86 [==============================] - 8s 35ms/step - loss: 1.0154 - accuracy: 0.5419 - val_loss: 0.8501 - val_accuracy: 0.6057\n",
            "— val_f1: 0.40647803934994053\n",
            "Epoch 2/10\n",
            "86/86 [==============================] - 2s 20ms/step - loss: 0.6079 - accuracy: 0.6890 - val_loss: 0.5495 - val_accuracy: 0.7206\n",
            "— val_f1: 0.6730664242497095\n",
            "Epoch 3/10\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.5369 - accuracy: 0.7224 - val_loss: 0.5769 - val_accuracy: 0.6964\n",
            "— val_f1: 0.6308802124778696\n",
            "Epoch 4/10\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.5383 - accuracy: 0.7241 - val_loss: 0.4726 - val_accuracy: 0.7557\n",
            "— val_f1: 0.7458270427227099\n",
            "Epoch 5/10\n",
            "86/86 [==============================] - 2s 20ms/step - loss: 0.4745 - accuracy: 0.7675 - val_loss: 0.5505 - val_accuracy: 0.7410\n",
            "— val_f1: 0.7047926854264882\n",
            "Epoch 6/10\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.4736 - accuracy: 0.7733 - val_loss: 0.4746 - val_accuracy: 0.7732\n",
            "— val_f1: 0.7570237603779641\n",
            "Epoch 7/10\n",
            "86/86 [==============================] - 2s 20ms/step - loss: 0.4524 - accuracy: 0.7854 - val_loss: 0.5044 - val_accuracy: 0.7564\n",
            "— val_f1: 0.7529310237211966\n",
            "Epoch 8/10\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.4386 - accuracy: 0.7931 - val_loss: 0.5657 - val_accuracy: 0.7198\n",
            "— val_f1: 0.7198220341386643\n",
            "Epoch 9/10\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.4289 - accuracy: 0.7974 - val_loss: 0.4932 - val_accuracy: 0.7623\n",
            "— val_f1: 0.7595853357742324\n",
            "Epoch 10/10\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.4175 - accuracy: 0.8016 - val_loss: 0.5137 - val_accuracy: 0.7762\n",
            "— val_f1: 0.7587647058823529\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.5137 - accuracy: 0.7762\n",
            "Epoch 1/10\n",
            "86/86 [==============================] - 8s 35ms/step - loss: 0.8721 - accuracy: 0.5992 - val_loss: 0.5772 - val_accuracy: 0.7154\n",
            "— val_f1: 0.6738740727793467\n",
            "Epoch 2/10\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.5834 - accuracy: 0.6937 - val_loss: 0.5024 - val_accuracy: 0.7513\n",
            "— val_f1: 0.7474197447134112\n",
            "Epoch 3/10\n",
            "86/86 [==============================] - 2s 20ms/step - loss: 0.5385 - accuracy: 0.7175 - val_loss: 0.6730 - val_accuracy: 0.6898\n",
            "— val_f1: 0.6879909391579963\n",
            "Epoch 4/10\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.5222 - accuracy: 0.7364 - val_loss: 0.4628 - val_accuracy: 0.7710\n",
            "— val_f1: 0.7688764169365272\n",
            "Epoch 5/10\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.4720 - accuracy: 0.7765 - val_loss: 0.5325 - val_accuracy: 0.7564\n",
            "— val_f1: 0.7560745455042335\n",
            "Epoch 6/10\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.4638 - accuracy: 0.7781 - val_loss: 0.4488 - val_accuracy: 0.7835\n",
            "— val_f1: 0.7771025401470146\n",
            "Epoch 7/10\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.4419 - accuracy: 0.7998 - val_loss: 0.5684 - val_accuracy: 0.7330\n",
            "— val_f1: 0.6925104441868448\n",
            "Epoch 8/10\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.4457 - accuracy: 0.7841 - val_loss: 0.4529 - val_accuracy: 0.7901\n",
            "— val_f1: 0.7819174393674684\n",
            "Epoch 9/10\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.4197 - accuracy: 0.7895 - val_loss: 0.5119 - val_accuracy: 0.7681\n",
            "— val_f1: 0.7461526520354873\n",
            "Epoch 10/10\n",
            "86/86 [==============================] - 2s 21ms/step - loss: 0.4179 - accuracy: 0.8085 - val_loss: 0.4570 - val_accuracy: 0.7915\n",
            "— val_f1: 0.7890414964384052\n",
            "43/43 [==============================] - 0s 7ms/step - loss: 0.4570 - accuracy: 0.7915\n",
            "f1_score test tweets: 0.7603277015648642\n",
            "f1_score test news: 0.6831647909673162\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_C5IjGnydPvu"
      },
      "source": [
        "for i in range(len(models)):\n",
        "  models[i].save(input_dir+\"model_output/biLSTM/{0}_{1}_{2}_{3}/model_{4}.h5\".format(hparams[HP_NUM_UNITS],hparams[HP_DROPOUT],hparams[HP_OPTIMIZER],hparams[HP_L2],i))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYp53DG5lKjj"
      },
      "source": [
        "f1_score test tweets: 0.7603277015648642\n",
        "f1_score test news: 0.6831647909673162"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}