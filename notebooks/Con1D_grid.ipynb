{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM_grid.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GiovanniSorice/Hate_Speech_Detection/blob/main/notebooks/Con1D_grid.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0mBfEzg_53t"
      },
      "source": [
        "#1D convolution Hate Speech Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OymXBcAV-Uk_"
      },
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Embedding, SpatialDropout1D, LSTM\n",
        "from tensorflow.keras.layers import Bidirectional # new! \n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "import os\n",
        "from sklearn.metrics import roc_auc_score \n",
        "import matplotlib.pyplot as plt\n",
        "from keras.preprocessing.text import one_hot\n",
        "from tensorboard.plugins.hparams import api as hp\n",
        "import numpy as np\n",
        "from sklearn.metrics import f1_score\n",
        "import ast \n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import StratifiedKFold"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FwrQH01T_nIS",
        "outputId": "8265fbff-b103-4d80-8fab-6c774750ec15"
      },
      "source": [
        "from google.colab import drive\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ewn7ge0AB8n"
      },
      "source": [
        "# directory name \n",
        "input_dir = '/content/drive/My Drive/HLT/clean_dataset_training/' \n",
        "input_test_dir = \"/content/drive/My Drive/HLT/dataset_test_evalita_preprocessed/\"\n",
        "# Spec\n",
        "pd.set_option(\"display.max_colwidth\", None)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJL3UvhtALOr"
      },
      "source": [
        "tsv_file = open(input_dir+\"training_dataset.csv\")\n",
        "\n",
        "dataset = pd.read_csv(tsv_file,sep=',')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "niRStx_sEI14"
      },
      "source": [
        "### Vector-space embedding: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rA44wzytEILB"
      },
      "source": [
        "p_val=0.15 # percentage of validation set \n",
        "\n",
        "n_dim = 64 \n",
        "n_unique_words = 25000 \n",
        "max_length = 64 # doubled!\n",
        "pad_type = trunc_type = 'pre'\n",
        "\n",
        "# training \n",
        "batch_size = 64"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cP42BiElvcKH"
      },
      "source": [
        "#### Preprocess data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KU0jvqjPHTsM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "669bae3f-2602-4ca6-ece5-a535a7f4f11e"
      },
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "all_words = []\n",
        "for index, row in dataset.iterrows():\n",
        "  tokenize_word = word_tokenize(row[\"text\"])\n",
        "  for word in tokenize_word:\n",
        "      all_words.append(word)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iaqpZHjMG6Dn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d654510c-1ba9-4479-9665-672a4ca1ef81"
      },
      "source": [
        "unique_words = set(all_words)\n",
        "print(len(unique_words))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "22525\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fAjg3KCQEHl3"
      },
      "source": [
        "parole_non_ric = set()\n",
        "def sentence_to_emb2(sentence, w2v, truncate = None, padding = False):\n",
        "  global parole_non_ric\n",
        "  pad_token = [0]*128\n",
        "  s_emb = [ w2v[word.lower()] for word in sentence if word.lower() in w2v.vocab]\n",
        "  parole_non_ric.update(set([ word.lower() for word in sentence if word.lower() not in w2v.vocab]))\n",
        "  if truncate is not None:\n",
        "    s_emb = s_emb[:truncate] #truncate\n",
        "  if padding:\n",
        "    s_emb += [pad_token] * (truncate - len(s_emb))\n",
        "  return np.array(s_emb)\n",
        "\n",
        "def get_data_to_emb2(data, w2v, truncate = None, padding = False):\n",
        "  X = [sentence_to_emb2(ast.literal_eval(sentence), w2v, truncate, padding) for sentence in data]\n",
        "  print(len(X))\n",
        "  print(X[0])\n",
        "  return np.array(X)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dd6KYgWqEKXs"
      },
      "source": [
        "from gensim.models import KeyedVectors\n",
        "from gensim.test.utils import datapath\n",
        "w2v_felice_path = \"/content/drive/My Drive/HLT/w2v/twitter128.bin\"\n",
        "w2v = KeyedVectors.load_word2vec_format(datapath(w2v_felice_path), binary=True)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V97RhoGzTonm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40114c4b-4681-415b-929a-3a2f43da8a89"
      },
      "source": [
        "X_dev = get_data_to_emb2(dataset[\"tokens\"], w2v, max_length , True)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6837\n",
            "[[ 1.47564483  0.12307259  1.0753547  ...  1.06197035  1.90046942\n",
            "  -0.19663759]\n",
            " [-2.10587931  1.7696439  -1.04741096 ... -1.11571276 -0.25399542\n",
            "  -0.97522277]\n",
            " [ 0.89639139  1.24942708  0.72824973 ...  0.68920714  0.98506999\n",
            "  -0.36202168]\n",
            " ...\n",
            " [ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]\n",
            " [ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]\n",
            " [ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "URGejkayq4T3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d64dc18e-6aef-4853-d4a4-45df0c5a14f5"
      },
      "source": [
        "len(parole_non_ric)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2159"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMnXywTcqSy1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "8c0ac544-e17d-48f9-a767-86dfcd78d4a6"
      },
      "source": [
        "dataset_other = dataset\n",
        "dataset_other = dataset.drop(['text', 'id', 'hs', 'stereotype','tokens', 'hashtags'], axis=1)\n",
        "dataset_other"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text_length</th>\n",
              "      <th>#C-L words</th>\n",
              "      <th>#?!</th>\n",
              "      <th>#.,</th>\n",
              "      <th>#bad_words</th>\n",
              "      <th>%bad_words</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>120</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>101</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>86</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>118</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>138</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6832</th>\n",
              "      <td>285</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6833</th>\n",
              "      <td>277</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6834</th>\n",
              "      <td>233</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6835</th>\n",
              "      <td>206</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6836</th>\n",
              "      <td>285</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6837 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      text_length  #C-L words  #?!  #.,  #bad_words  %bad_words\n",
              "0             120          10    0    5           0           0\n",
              "1             101           0    0    0           1           6\n",
              "2              86           8    0    1           3          25\n",
              "3             118           0    0    2           0           0\n",
              "4             138           0    1    1           1           4\n",
              "...           ...         ...  ...  ...         ...         ...\n",
              "6832          285           2    0    4           0           0\n",
              "6833          277           0    2    3           0           0\n",
              "6834          233           0    0    4           0           0\n",
              "6835          206           2    0    2           0           0\n",
              "6836          285           7    1    5           0           0\n",
              "\n",
              "[6837 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7TX3TS1yTlR"
      },
      "source": [
        "x_train, x_valid, x_train_extra, x_valid_extra, y_train, y_valid = train_test_split(X_dev, dataset_other.values , dataset[['hs']], test_size=p_val, random_state=128)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRF1dwdVpKSo"
      },
      "source": [
        "input_train = {\"text\": x_train, \"other\": x_train_extra}\n",
        "input_val   = {\"text\": x_valid, \"other\": x_valid_extra}"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXitI_XKIZN7"
      },
      "source": [
        "max_sent = 0 "
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCxWTGMOHVzc"
      },
      "source": [
        "\n",
        "def comment_length(text):\n",
        "    global max_sent \n",
        "    text = ast.literal_eval(text)\n",
        "    if len(text)>max_sent: \n",
        "      max_sent = len(text)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vmnRA9uGIKjJ",
        "outputId": "f9a0f10c-f6c0-4ace-93bf-13fd88a40e85"
      },
      "source": [
        "dataset['tokens'].apply(comment_length)\n",
        "print(max_sent)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "121\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oVbNT3FOisHf",
        "outputId": "f79c1e44-8f60-41ca-dc7a-cb8c8318b913"
      },
      "source": [
        "x_train_extra.shape"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5811, 6)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uAUJfLg_BGTX"
      },
      "source": [
        "### Design grid search parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PC8zF9NNBJso"
      },
      "source": [
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard\n",
        "\n",
        "# Clear any logs from previous runs\n",
        "!rm -rf ./logs/\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorboard.plugins.hparams import api as hp"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JJ6QHGwBXVJ"
      },
      "source": [
        "HP_NUM_FILTERS = hp.HParam('num_filters', hp.Discrete([1024]))\n",
        "HP_L2_CONVOLUTION = hp.HParam('dropout', hp.RealInterval(0.0, 0.0008))\n",
        "HP_L2_DENSE = hp.HParam('L2_reg', hp.RealInterval(0.0, 0.0008))\n",
        "HP_OPTIMIZER = hp.HParam('optimizer', hp.Discrete(['nadam']))\n",
        "\n",
        "METRIC_ACCURACY = 'accuracy'\n",
        "\n",
        "with tf.summary.create_file_writer('logs/hparam_tuning').as_default():\n",
        "  hp.hparams_config(\n",
        "    hparams=[HP_NUM_FILTERS, HP_L2_CONVOLUTION, HP_L2_DENSE, HP_OPTIMIZER],\n",
        "    metrics=[hp.Metric(METRIC_ACCURACY, display_name='Accuracy')],\n",
        "  )"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXFVlKlA7CUr"
      },
      "source": [
        "class FCallback(tf.keras.callbacks.Callback):\n",
        "  \n",
        "    def __init__(self, validation = (), verbose = 0):\n",
        "        self.validation = validation\n",
        "        self.verbose = verbose\n",
        "\n",
        "    def on_train_begin(self, logs={}):\n",
        "        self.f1 = []\n",
        "        self.val_f1 = []\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        y_t =  self.validation[1]\n",
        "        y_p =  np.where(self.model.predict(self.validation[0]) > 0.5, 1, 0)\n",
        "        logs['val_f1'] =  f1_score(y_t, y_p, average='macro')\n",
        "        if self.verbose >0:\n",
        "          print(\"— val_f1: {}\".format(logs['val_f1']))"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJjzp8CnwARN"
      },
      "source": [
        "def get_model(hparams):\n",
        "  embedding_dim = 128\n",
        "  num_filters = hparams[HP_NUM_FILTERS]\n",
        "  conv1D_in = tf.keras.layers.Input(name=\"text\", shape =(max_length,128,))\n",
        "\n",
        "  reshape_4 = tf.keras.layers.Reshape((max_length, embedding_dim, 1))(conv1D_in)\n",
        "  conv_0_4 = tf.keras.layers.Conv2D(num_filters, kernel_size=(3, embedding_dim), padding='valid', kernel_initializer='normal', activation='relu', kernel_regularizer=tf.keras.regularizers.l2(hparams[HP_L2_CONVOLUTION]))(reshape_4)\n",
        "  conv_1_4 = tf.keras.layers.Conv2D(num_filters, kernel_size=(4, embedding_dim), padding='valid', kernel_initializer='normal', activation='relu', kernel_regularizer=tf.keras.regularizers.l2(hparams[HP_L2_CONVOLUTION]))(reshape_4)\n",
        "  conv_2_4 = tf.keras.layers.Conv2D(num_filters, kernel_size=(5, embedding_dim), padding='valid', kernel_initializer='normal', activation='relu', kernel_regularizer=tf.keras.regularizers.l2(hparams[HP_L2_CONVOLUTION]))(reshape_4)\n",
        "\n",
        "  maxpool_0_4 = tf.keras.layers.MaxPool2D(pool_size=(max_length - 3 + 1, 1), strides=(1,1), padding='valid')(conv_0_4)\n",
        "  maxpool_1_4 = tf.keras.layers.MaxPool2D(pool_size=(max_length - 4 + 1, 1), strides=(1,1), padding='valid')(conv_1_4)\n",
        "  maxpool_2_4 = tf.keras.layers.MaxPool2D(pool_size=(max_length - 5 + 1, 1), strides=(1,1), padding='valid')(conv_2_4)\n",
        "\n",
        "  concatenated_tensor_4 = tf.keras.layers.Concatenate(axis=1)([maxpool_0_4, maxpool_1_4, maxpool_2_4])\n",
        "  flatten_4 = tf.keras.layers.Flatten()(concatenated_tensor_4)\n",
        "\n",
        "  dropout_4 = tf.keras.layers.Dropout(0.5)(flatten_4)\n",
        "  # note the different activation\n",
        "  other_in = tf.keras.layers.Input(name=\"other\", shape =(6,))\n",
        "  lconcat = tf.keras.layers.Concatenate(axis=1)([dropout_4, other_in])\n",
        "\n",
        "  dense1_layer = Dense(256, activation=\"relu\", kernel_regularizer=tf.keras.regularizers.l2(hparams[HP_L2_DENSE]))(lconcat)\n",
        "  dense2_layer = Dense(128, activation=\"relu\", kernel_regularizer=tf.keras.regularizers.l2(hparams[HP_L2_DENSE]))(dense1_layer)\n",
        "  dense3_layer = Dense(32, activation=\"relu\", kernel_regularizer=tf.keras.regularizers.l2(hparams[HP_L2_DENSE]))(dense2_layer)\n",
        "\n",
        "  output_4 = tf.keras.layers.Dense(units=1, activation='sigmoid')(dense3_layer)\n",
        "\n",
        "  model = tf.keras.Model(inputs = [conv1D_in, other_in], outputs = output_4)\n",
        "  \n",
        "  # model.summary()\n",
        "  \n",
        "  return model"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4nNvvQRCcFP"
      },
      "source": [
        "def train_test_model(hparams):\n",
        "  \n",
        "  model = get_model(hparams)\n",
        "  model.compile(\n",
        "      optimizer=hparams[HP_OPTIMIZER],\n",
        "      loss='binary_crossentropy',\n",
        "      metrics=['accuracy'],\n",
        "  )\n",
        "\n",
        "  #model.summary()\n",
        "\n",
        "  f1_callback = FCallback(validation = (input_val, y_valid), verbose=True)                                   \n",
        "\n",
        "  #filepath = input_dir + \"model_output/biLSTM/HP_NUM_UNITS={0}/HP_DROPOUT={1}/HP_L2={2}/\".format(hparams[HP_NUM_UNITS],hparams[HP_DROPOUT],hparams[HP_L2])\n",
        "  #filepath += \"saved-model-{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n",
        "  #checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=False, mode='max')\n",
        "\n",
        "  model.fit(input_train, y_train, batch_size=batch_size, validation_data=(input_val, y_valid), epochs=20, callbacks=[f1_callback]) # Run with 1 epoch to speed things up for demo purposes\n",
        "  _, accuracy = model.evaluate(input_val, y_valid)\n",
        "\n",
        "  y_test_pred_tweets = np.where(model.predict(input_test_tweets) > 0.5, 1, 0)\n",
        "  y_test_pred_news = np.where(model.predict(input_test_news) > 0.5, 1, 0)\n",
        "\n",
        "  print(\"f1_score test tweets: {}\".format(f1_score(y_test_tweets, y_test_pred_tweets,average=\"macro\")))\n",
        "  print(\"f1_score test news: {}\".format(f1_score(y_test_news, y_test_pred_news,average=\"macro\")))\n",
        "  return accuracy"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OaO2zq3-Adck"
      },
      "source": [
        "def run(run_dir, hparams):\n",
        "  with tf.summary.create_file_writer(run_dir).as_default():\n",
        "    hp.hparams(hparams)  # record the values used in this trial\n",
        "    accuracy = train_test_model(hparams)\n",
        "    tf.summary.scalar(METRIC_ACCURACY, accuracy, step=1)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9CaPr2dcL4tD",
        "outputId": "0241fb16-332f-4874-8d31-c31bc9008ac5"
      },
      "source": [
        "session_num = 0\n",
        "\n",
        "for num_filters in HP_NUM_FILTERS.domain.values:\n",
        "  for L2_rate_conv in np.arange(HP_L2_CONVOLUTION.domain.min_value, HP_L2_CONVOLUTION.domain.max_value, 0.0002):\n",
        "      for L2_rate_dense in np.arange(HP_L2_DENSE.domain.min_value, HP_L2_DENSE.domain.max_value, 0.0002):\n",
        "        for optimizer in HP_OPTIMIZER.domain.values:\n",
        "          hparams = {\n",
        "              HP_NUM_FILTERS: num_filters,\n",
        "              HP_L2_CONVOLUTION: L2_rate_conv,\n",
        "              HP_OPTIMIZER: optimizer,\n",
        "              HP_L2_DENSE: L2_rate_dense,\n",
        "          }\n",
        "          run_name = \"run-%d\" % session_num\n",
        "          print('--- Starting trial: %s' % run_name)\n",
        "          print({h.name: hparams[h] for h in hparams})\n",
        "          run('logs/hparam_tuning/' + run_name, hparams)\n",
        "          session_num += 1\n"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--- Starting trial: run-0\n",
            "{'num_filters': 1024, 'dropout': 0.0, 'optimizer': 'nadam', 'L2_reg': 0.0}\n",
            "Epoch 1/20\n",
            "91/91 [==============================] - 53s 566ms/step - loss: 1.3983 - accuracy: 0.5620 - val_loss: 0.5581 - val_accuracy: 0.7154\n",
            "— val_f1: 0.7098416289592759\n",
            "Epoch 2/20\n",
            "91/91 [==============================] - 50s 552ms/step - loss: 0.5657 - accuracy: 0.6943 - val_loss: 0.5598 - val_accuracy: 0.7115\n",
            "— val_f1: 0.7112859495081245\n",
            "Epoch 3/20\n",
            "91/91 [==============================] - 50s 549ms/step - loss: 0.5266 - accuracy: 0.7387 - val_loss: 0.5178 - val_accuracy: 0.7320\n",
            "— val_f1: 0.7302031866909802\n",
            "Epoch 4/20\n",
            "91/91 [==============================] - 51s 559ms/step - loss: 0.4379 - accuracy: 0.7895 - val_loss: 0.5698 - val_accuracy: 0.7037\n",
            "— val_f1: 0.7036935704514364\n",
            "Epoch 5/20\n",
            "91/91 [==============================] - 50s 552ms/step - loss: 0.4095 - accuracy: 0.8062 - val_loss: 0.4935 - val_accuracy: 0.7612\n",
            "— val_f1: 0.7477488868618083\n",
            "Epoch 6/20\n",
            "91/91 [==============================] - 50s 549ms/step - loss: 0.3350 - accuracy: 0.8472 - val_loss: 0.9640 - val_accuracy: 0.6745\n",
            "— val_f1: 0.5535178236397749\n",
            "Epoch 7/20\n",
            "91/91 [==============================] - 50s 548ms/step - loss: 0.3013 - accuracy: 0.8749 - val_loss: 0.5010 - val_accuracy: 0.7544\n",
            "— val_f1: 0.7484197907585004\n",
            "Epoch 8/20\n",
            "91/91 [==============================] - 53s 578ms/step - loss: 0.3231 - accuracy: 0.8710 - val_loss: 0.5680 - val_accuracy: 0.7602\n",
            "— val_f1: 0.7325678974671956\n",
            "Epoch 9/20\n",
            "91/91 [==============================] - 51s 565ms/step - loss: 0.2684 - accuracy: 0.9017 - val_loss: 0.5282 - val_accuracy: 0.7710\n",
            "— val_f1: 0.7593835044324091\n",
            "Epoch 10/20\n",
            "91/91 [==============================] - 50s 551ms/step - loss: 0.2544 - accuracy: 0.9228 - val_loss: 0.6450 - val_accuracy: 0.7544\n",
            "— val_f1: 0.724880291131967\n",
            "Epoch 11/20\n",
            "91/91 [==============================] - 50s 549ms/step - loss: 0.1370 - accuracy: 0.9568 - val_loss: 0.6568 - val_accuracy: 0.7700\n",
            "— val_f1: 0.7595185126330843\n",
            "Epoch 12/20\n",
            "91/91 [==============================] - 50s 548ms/step - loss: 0.0948 - accuracy: 0.9700 - val_loss: 0.7138 - val_accuracy: 0.7622\n",
            "— val_f1: 0.7513665978070873\n",
            "Epoch 13/20\n",
            "91/91 [==============================] - 51s 561ms/step - loss: 0.1735 - accuracy: 0.9521 - val_loss: 0.7157 - val_accuracy: 0.7622\n",
            "— val_f1: 0.7567019126107914\n",
            "Epoch 14/20\n",
            "91/91 [==============================] - 50s 550ms/step - loss: 0.0982 - accuracy: 0.9730 - val_loss: 0.9586 - val_accuracy: 0.7407\n",
            "— val_f1: 0.7398510689406679\n",
            "Epoch 15/20\n",
            "91/91 [==============================] - 50s 549ms/step - loss: 0.0920 - accuracy: 0.9684 - val_loss: 0.5999 - val_accuracy: 0.7612\n",
            "— val_f1: 0.7449560925126446\n",
            "Epoch 16/20\n",
            "91/91 [==============================] - 50s 548ms/step - loss: 0.0593 - accuracy: 0.9833 - val_loss: 0.8124 - val_accuracy: 0.7534\n",
            "— val_f1: 0.7500488678545808\n",
            "Epoch 17/20\n",
            "91/91 [==============================] - 51s 564ms/step - loss: 0.0452 - accuracy: 0.9837 - val_loss: 1.0220 - val_accuracy: 0.7495\n",
            "— val_f1: 0.7127606382225455\n",
            "Epoch 18/20\n",
            "91/91 [==============================] - 50s 550ms/step - loss: 0.0424 - accuracy: 0.9868 - val_loss: 0.9135 - val_accuracy: 0.7632\n",
            "— val_f1: 0.7568699040714768\n",
            "Epoch 19/20\n",
            "91/91 [==============================] - 50s 550ms/step - loss: 0.0436 - accuracy: 0.9844 - val_loss: 0.7063 - val_accuracy: 0.7661\n",
            "— val_f1: 0.7527790271798498\n",
            "Epoch 20/20\n",
            "91/91 [==============================] - 51s 557ms/step - loss: 0.0442 - accuracy: 0.9861 - val_loss: 0.9190 - val_accuracy: 0.7622\n",
            "— val_f1: 0.7412229742860332\n",
            "33/33 [==============================] - 4s 108ms/step - loss: 0.9190 - accuracy: 0.7622\n",
            "f1_score test tweets: 0.740507009121188\n",
            "f1_score test news: 0.6267232941254541\n",
            "--- Starting trial: run-1\n",
            "{'num_filters': 1024, 'dropout': 0.0, 'optimizer': 'nadam', 'L2_reg': 0.0002}\n",
            "Epoch 1/20\n",
            "91/91 [==============================] - 52s 557ms/step - loss: 1.2726 - accuracy: 0.5774 - val_loss: 0.6941 - val_accuracy: 0.7339\n",
            "— val_f1: 0.7133230506902914\n",
            "Epoch 2/20\n",
            "91/91 [==============================] - 51s 565ms/step - loss: 0.7008 - accuracy: 0.6922 - val_loss: 0.6369 - val_accuracy: 0.7563\n",
            "— val_f1: 0.7436773752563226\n",
            "Epoch 3/20\n",
            "91/91 [==============================] - 50s 554ms/step - loss: 0.6238 - accuracy: 0.7455 - val_loss: 0.6724 - val_accuracy: 0.6949\n",
            "— val_f1: 0.6949245286424465\n",
            "Epoch 4/20\n",
            "91/91 [==============================] - 50s 554ms/step - loss: 0.6071 - accuracy: 0.7647 - val_loss: 0.8035 - val_accuracy: 0.6725\n",
            "— val_f1: 0.5444459127309248\n",
            "Epoch 5/20\n",
            "91/91 [==============================] - 51s 560ms/step - loss: 0.5048 - accuracy: 0.8137 - val_loss: 0.7173 - val_accuracy: 0.7563\n",
            "— val_f1: 0.7234083850931676\n",
            "Epoch 6/20\n",
            "91/91 [==============================] - 51s 559ms/step - loss: 0.4837 - accuracy: 0.8310 - val_loss: 0.5786 - val_accuracy: 0.7671\n",
            "— val_f1: 0.755936758185157\n",
            "Epoch 7/20\n",
            "91/91 [==============================] - 50s 552ms/step - loss: 0.3923 - accuracy: 0.8718 - val_loss: 0.6416 - val_accuracy: 0.7505\n",
            "— val_f1: 0.721305700449466\n",
            "Epoch 8/20\n",
            "91/91 [==============================] - 50s 552ms/step - loss: 0.3763 - accuracy: 0.8881 - val_loss: 0.6178 - val_accuracy: 0.7622\n",
            "— val_f1: 0.7576712652312124\n",
            "Epoch 9/20\n",
            "91/91 [==============================] - 50s 554ms/step - loss: 0.3076 - accuracy: 0.9171 - val_loss: 0.6592 - val_accuracy: 0.7739\n",
            "— val_f1: 0.7548286090969017\n",
            "Epoch 10/20\n",
            "91/91 [==============================] - 51s 566ms/step - loss: 0.2731 - accuracy: 0.9387 - val_loss: 0.7263 - val_accuracy: 0.7612\n",
            "— val_f1: 0.7390464820534115\n",
            "Epoch 11/20\n",
            "91/91 [==============================] - 51s 556ms/step - loss: 0.2127 - accuracy: 0.9584 - val_loss: 0.7716 - val_accuracy: 0.7602\n",
            "— val_f1: 0.7364869097484683\n",
            "Epoch 12/20\n",
            "91/91 [==============================] - 50s 555ms/step - loss: 0.1665 - accuracy: 0.9707 - val_loss: 0.8210 - val_accuracy: 0.7700\n",
            "— val_f1: 0.7458743519237631\n",
            "Epoch 13/20\n",
            "91/91 [==============================] - 50s 552ms/step - loss: 0.1822 - accuracy: 0.9660 - val_loss: 0.9569 - val_accuracy: 0.7700\n",
            "— val_f1: 0.749403874813711\n",
            "Epoch 14/20\n",
            "91/91 [==============================] - 50s 551ms/step - loss: 0.1299 - accuracy: 0.9830 - val_loss: 0.8284 - val_accuracy: 0.7593\n",
            "— val_f1: 0.7530257565731449\n",
            "Epoch 15/20\n",
            "91/91 [==============================] - 51s 566ms/step - loss: 0.2674 - accuracy: 0.9514 - val_loss: 0.7817 - val_accuracy: 0.7749\n",
            "— val_f1: 0.7587604878004093\n",
            "Epoch 16/20\n",
            "91/91 [==============================] - 50s 551ms/step - loss: 0.1074 - accuracy: 0.9885 - val_loss: 0.9994 - val_accuracy: 0.7602\n",
            "— val_f1: 0.7354561462351166\n",
            "Epoch 17/20\n",
            "91/91 [==============================] - 50s 551ms/step - loss: 0.1081 - accuracy: 0.9896 - val_loss: 0.9134 - val_accuracy: 0.7700\n",
            "— val_f1: 0.7605127292148834\n",
            "Epoch 18/20\n",
            "91/91 [==============================] - 50s 552ms/step - loss: 0.0934 - accuracy: 0.9914 - val_loss: 0.9288 - val_accuracy: 0.7700\n",
            "— val_f1: 0.7626759817931619\n",
            "Epoch 19/20\n",
            "91/91 [==============================] - 51s 562ms/step - loss: 0.1245 - accuracy: 0.9811 - val_loss: 0.7760 - val_accuracy: 0.7651\n",
            "— val_f1: 0.7485874528600203\n",
            "Epoch 20/20\n",
            "91/91 [==============================] - 50s 550ms/step - loss: 0.0845 - accuracy: 0.9921 - val_loss: 0.9515 - val_accuracy: 0.7524\n",
            "— val_f1: 0.7302906110283159\n",
            "33/33 [==============================] - 4s 106ms/step - loss: 0.9515 - accuracy: 0.7524\n",
            "f1_score test tweets: 0.7409464776646854\n",
            "f1_score test news: 0.6439269153198406\n",
            "--- Starting trial: run-2\n",
            "{'num_filters': 1024, 'dropout': 0.0, 'optimizer': 'nadam', 'L2_reg': 0.0004}\n",
            "Epoch 1/20\n",
            "91/91 [==============================] - 52s 550ms/step - loss: 1.7387 - accuracy: 0.5711 - val_loss: 0.8488 - val_accuracy: 0.6404\n",
            "— val_f1: 0.5032585235286786\n",
            "Epoch 2/20\n",
            "91/91 [==============================] - 50s 547ms/step - loss: 0.8271 - accuracy: 0.6824 - val_loss: 0.8069 - val_accuracy: 0.7398\n",
            "— val_f1: 0.7293798621915981\n",
            "Epoch 3/20\n",
            "91/91 [==============================] - 52s 568ms/step - loss: 0.7562 - accuracy: 0.7463 - val_loss: 0.7727 - val_accuracy: 0.6910\n",
            "— val_f1: 0.6909976200768606\n",
            "Epoch 4/20\n",
            "91/91 [==============================] - 50s 550ms/step - loss: 0.6781 - accuracy: 0.7719 - val_loss: 0.6830 - val_accuracy: 0.7554\n",
            "— val_f1: 0.7461925331961433\n",
            "Epoch 5/20\n",
            "91/91 [==============================] - 50s 549ms/step - loss: 0.6245 - accuracy: 0.8024 - val_loss: 0.8457 - val_accuracy: 0.6930\n",
            "— val_f1: 0.5958442701774613\n",
            "Epoch 6/20\n",
            "91/91 [==============================] - 50s 547ms/step - loss: 0.5692 - accuracy: 0.8274 - val_loss: 0.6896 - val_accuracy: 0.7602\n",
            "— val_f1: 0.7374900153098582\n",
            "Epoch 7/20\n",
            "91/91 [==============================] - 51s 556ms/step - loss: 0.5359 - accuracy: 0.8461 - val_loss: 0.7453 - val_accuracy: 0.7339\n",
            "— val_f1: 0.6824670929943873\n",
            "Epoch 8/20\n",
            "91/91 [==============================] - 50s 553ms/step - loss: 0.4477 - accuracy: 0.8791 - val_loss: 0.8741 - val_accuracy: 0.7359\n",
            "— val_f1: 0.6805343156235386\n",
            "Epoch 9/20\n",
            "91/91 [==============================] - 50s 553ms/step - loss: 0.3712 - accuracy: 0.9144 - val_loss: 0.6566 - val_accuracy: 0.7661\n",
            "— val_f1: 0.758822791951357\n",
            "Epoch 10/20\n",
            "91/91 [==============================] - 50s 550ms/step - loss: 0.3309 - accuracy: 0.9392 - val_loss: 0.6624 - val_accuracy: 0.7661\n",
            "— val_f1: 0.7599485269745949\n",
            "Epoch 11/20\n",
            "91/91 [==============================] - 51s 562ms/step - loss: 0.2485 - accuracy: 0.9684 - val_loss: 1.2235 - val_accuracy: 0.6969\n",
            "— val_f1: 0.6105796162253001\n",
            "Epoch 12/20\n",
            "91/91 [==============================] - 50s 551ms/step - loss: 0.2503 - accuracy: 0.9648 - val_loss: 1.8452 - val_accuracy: 0.5526\n",
            "— val_f1: 0.5269633521000848\n",
            "Epoch 13/20\n",
            "91/91 [==============================] - 50s 549ms/step - loss: 0.3073 - accuracy: 0.9434 - val_loss: 0.8850 - val_accuracy: 0.7505\n",
            "— val_f1: 0.7420084865629419\n",
            "Epoch 14/20\n",
            "91/91 [==============================] - 50s 547ms/step - loss: 0.1983 - accuracy: 0.9695 - val_loss: 0.9180 - val_accuracy: 0.7612\n",
            "— val_f1: 0.757840535242068\n",
            "Epoch 15/20\n",
            "91/91 [==============================] - 50s 550ms/step - loss: 0.1755 - accuracy: 0.9828 - val_loss: 1.1015 - val_accuracy: 0.7310\n",
            "— val_f1: 0.7306625577812018\n",
            "Epoch 16/20\n",
            "91/91 [==============================] - 51s 560ms/step - loss: 0.1990 - accuracy: 0.9706 - val_loss: 0.9942 - val_accuracy: 0.7485\n",
            "— val_f1: 0.712330196265948\n",
            "Epoch 17/20\n",
            "91/91 [==============================] - 50s 550ms/step - loss: 0.1484 - accuracy: 0.9855 - val_loss: 0.9838 - val_accuracy: 0.7018\n",
            "— val_f1: 0.6225474166121648\n",
            "Epoch 18/20\n",
            "91/91 [==============================] - 50s 549ms/step - loss: 0.2032 - accuracy: 0.9662 - val_loss: 0.9811 - val_accuracy: 0.7193\n",
            "— val_f1: 0.650954450954451\n",
            "Epoch 19/20\n",
            "91/91 [==============================] - 50s 548ms/step - loss: 0.1495 - accuracy: 0.9799 - val_loss: 0.9661 - val_accuracy: 0.7563\n",
            "— val_f1: 0.7300784193223864\n",
            "Epoch 20/20\n",
            "91/91 [==============================] - 50s 549ms/step - loss: 0.1202 - accuracy: 0.9896 - val_loss: 0.9776 - val_accuracy: 0.7622\n",
            "— val_f1: 0.7531757143138841\n",
            "33/33 [==============================] - 4s 109ms/step - loss: 0.9776 - accuracy: 0.7622\n",
            "f1_score test tweets: 0.7066607946959351\n",
            "f1_score test news: 0.6649384544845343\n",
            "--- Starting trial: run-3\n",
            "{'num_filters': 1024, 'dropout': 0.0, 'optimizer': 'nadam', 'L2_reg': 0.0006000000000000001}\n",
            "Epoch 1/20\n",
            "91/91 [==============================] - 53s 565ms/step - loss: 2.1660 - accuracy: 0.5494 - val_loss: 0.9352 - val_accuracy: 0.6988\n",
            "— val_f1: 0.6979624656195251\n",
            "Epoch 2/20\n",
            "91/91 [==============================] - 50s 554ms/step - loss: 0.9265 - accuracy: 0.7116 - val_loss: 0.8826 - val_accuracy: 0.7251\n",
            "— val_f1: 0.723785957315187\n",
            "Epoch 3/20\n",
            "91/91 [==============================] - 50s 552ms/step - loss: 0.8424 - accuracy: 0.7458 - val_loss: 0.9227 - val_accuracy: 0.6998\n",
            "— val_f1: 0.6101612115290669\n",
            "Epoch 4/20\n",
            "91/91 [==============================] - 50s 550ms/step - loss: 0.7554 - accuracy: 0.7763 - val_loss: 0.7870 - val_accuracy: 0.7456\n",
            "— val_f1: 0.7422624152178997\n",
            "Epoch 5/20\n",
            "91/91 [==============================] - 51s 564ms/step - loss: 0.6834 - accuracy: 0.8152 - val_loss: 0.7404 - val_accuracy: 0.7612\n",
            "— val_f1: 0.7531840019794767\n",
            "Epoch 6/20\n",
            "91/91 [==============================] - 50s 551ms/step - loss: 0.5913 - accuracy: 0.8538 - val_loss: 0.8045 - val_accuracy: 0.7593\n",
            "— val_f1: 0.7305314152465147\n",
            "Epoch 7/20\n",
            "91/91 [==============================] - 50s 551ms/step - loss: 0.5222 - accuracy: 0.8797 - val_loss: 0.8175 - val_accuracy: 0.7349\n",
            "— val_f1: 0.7344892281814066\n",
            "Epoch 8/20\n",
            "91/91 [==============================] - 51s 557ms/step - loss: 0.4663 - accuracy: 0.8991 - val_loss: 0.7933 - val_accuracy: 0.7524\n",
            "— val_f1: 0.7504299893125151\n",
            "Epoch 9/20\n",
            "91/91 [==============================] - 50s 552ms/step - loss: 0.4204 - accuracy: 0.9179 - val_loss: 0.8319 - val_accuracy: 0.7524\n",
            "— val_f1: 0.7292920982760553\n",
            "Epoch 10/20\n",
            "91/91 [==============================] - 50s 549ms/step - loss: 0.3472 - accuracy: 0.9366 - val_loss: 0.8434 - val_accuracy: 0.7563\n",
            "— val_f1: 0.7293447293447293\n",
            "Epoch 11/20\n",
            "91/91 [==============================] - 50s 550ms/step - loss: 0.3174 - accuracy: 0.9525 - val_loss: 0.9128 - val_accuracy: 0.7515\n",
            "— val_f1: 0.7221983314698546\n",
            "Epoch 12/20\n",
            "91/91 [==============================] - 50s 551ms/step - loss: 0.3437 - accuracy: 0.9402 - val_loss: 0.8457 - val_accuracy: 0.7583\n",
            "— val_f1: 0.7477155910908053\n",
            "Epoch 13/20\n",
            "91/91 [==============================] - 51s 560ms/step - loss: 0.2459 - accuracy: 0.9721 - val_loss: 0.8097 - val_accuracy: 0.7602\n",
            "— val_f1: 0.7511525644312109\n",
            "Epoch 14/20\n",
            "91/91 [==============================] - 50s 553ms/step - loss: 0.2661 - accuracy: 0.9623 - val_loss: 0.8158 - val_accuracy: 0.7710\n",
            "— val_f1: 0.7566204860322507\n",
            "Epoch 15/20\n",
            "91/91 [==============================] - 50s 548ms/step - loss: 0.1674 - accuracy: 0.9902 - val_loss: 0.9068 - val_accuracy: 0.7690\n",
            "— val_f1: 0.7590057433386685\n",
            "Epoch 16/20\n",
            "91/91 [==============================] - 50s 548ms/step - loss: 0.1872 - accuracy: 0.9822 - val_loss: 0.6967 - val_accuracy: 0.7641\n",
            "— val_f1: 0.7516523701309092\n",
            "Epoch 17/20\n",
            "91/91 [==============================] - 50s 550ms/step - loss: 0.1755 - accuracy: 0.9816 - val_loss: 0.9162 - val_accuracy: 0.7661\n",
            "— val_f1: 0.750809585492228\n",
            "Epoch 18/20\n",
            "91/91 [==============================] - 51s 565ms/step - loss: 0.1361 - accuracy: 0.9924 - val_loss: 1.1350 - val_accuracy: 0.7671\n",
            "— val_f1: 0.7548436117512385\n",
            "Epoch 19/20\n",
            "91/91 [==============================] - 50s 554ms/step - loss: 0.1666 - accuracy: 0.9780 - val_loss: 0.7550 - val_accuracy: 0.7534\n",
            "— val_f1: 0.7395121158205612\n",
            "Epoch 20/20\n",
            "91/91 [==============================] - 52s 575ms/step - loss: 0.1623 - accuracy: 0.9797 - val_loss: 0.7672 - val_accuracy: 0.7768\n",
            "— val_f1: 0.7651012012177139\n",
            "33/33 [==============================] - 4s 107ms/step - loss: 0.7672 - accuracy: 0.7768\n",
            "f1_score test tweets: 0.7364781297134237\n",
            "f1_score test news: 0.681355648885267\n",
            "--- Starting trial: run-4\n",
            "{'num_filters': 1024, 'dropout': 0.0002, 'optimizer': 'nadam', 'L2_reg': 0.0}\n",
            "Epoch 1/20\n",
            "91/91 [==============================] - 52s 556ms/step - loss: 2.2940 - accuracy: 0.5732 - val_loss: 1.2876 - val_accuracy: 0.7115\n",
            "— val_f1: 0.6699602251733356\n",
            "Epoch 2/20\n",
            "91/91 [==============================] - 52s 569ms/step - loss: 1.2857 - accuracy: 0.6965 - val_loss: 1.1606 - val_accuracy: 0.7378\n",
            "— val_f1: 0.7299606379720778\n",
            "Epoch 3/20\n",
            "91/91 [==============================] - 50s 555ms/step - loss: 1.1562 - accuracy: 0.7366 - val_loss: 1.1077 - val_accuracy: 0.7076\n",
            "— val_f1: 0.7074911905241591\n",
            "Epoch 4/20\n",
            "91/91 [==============================] - 50s 553ms/step - loss: 1.0060 - accuracy: 0.7825 - val_loss: 1.1243 - val_accuracy: 0.7135\n",
            "— val_f1: 0.6495901639344261\n",
            "Epoch 5/20\n",
            "91/91 [==============================] - 50s 555ms/step - loss: 0.8906 - accuracy: 0.8078 - val_loss: 0.9468 - val_accuracy: 0.7427\n",
            "— val_f1: 0.741116110854115\n",
            "Epoch 6/20\n",
            "91/91 [==============================] - 51s 566ms/step - loss: 0.7855 - accuracy: 0.8428 - val_loss: 0.8999 - val_accuracy: 0.7563\n",
            "— val_f1: 0.75444582299421\n",
            "Epoch 7/20\n",
            "91/91 [==============================] - 51s 556ms/step - loss: 0.7168 - accuracy: 0.8533 - val_loss: 0.8627 - val_accuracy: 0.7612\n",
            "— val_f1: 0.7572512228214946\n",
            "Epoch 8/20\n",
            "91/91 [==============================] - 50s 555ms/step - loss: 0.6537 - accuracy: 0.8673 - val_loss: 0.8839 - val_accuracy: 0.7671\n",
            "— val_f1: 0.7417807894612141\n",
            "Epoch 9/20\n",
            "91/91 [==============================] - 50s 555ms/step - loss: 0.6221 - accuracy: 0.8817 - val_loss: 0.8045 - val_accuracy: 0.7710\n",
            "— val_f1: 0.760021498633941\n",
            "Epoch 10/20\n",
            "91/91 [==============================] - 52s 573ms/step - loss: 0.5625 - accuracy: 0.9110 - val_loss: 0.8512 - val_accuracy: 0.7739\n",
            "— val_f1: 0.7663650105023458\n",
            "Epoch 11/20\n",
            "91/91 [==============================] - 50s 555ms/step - loss: 0.5271 - accuracy: 0.9243 - val_loss: 0.8273 - val_accuracy: 0.7758\n",
            "— val_f1: 0.7616787318618103\n",
            "Epoch 12/20\n",
            "91/91 [==============================] - 50s 555ms/step - loss: 0.4767 - accuracy: 0.9365 - val_loss: 0.8824 - val_accuracy: 0.7427\n",
            "— val_f1: 0.7412704174228675\n",
            "Epoch 13/20\n",
            "91/91 [==============================] - 51s 556ms/step - loss: 0.4488 - accuracy: 0.9441 - val_loss: 0.8237 - val_accuracy: 0.7710\n",
            "— val_f1: 0.7571049643832526\n",
            "Epoch 14/20\n",
            "91/91 [==============================] - 51s 557ms/step - loss: 0.4178 - accuracy: 0.9567 - val_loss: 2.6713 - val_accuracy: 0.4464\n",
            "— val_f1: 0.3725392238353439\n",
            "Epoch 15/20\n",
            "91/91 [==============================] - 50s 554ms/step - loss: 0.5261 - accuracy: 0.9260 - val_loss: 0.9063 - val_accuracy: 0.7407\n",
            "— val_f1: 0.7395968902306373\n",
            "Epoch 16/20\n",
            "91/91 [==============================] - 52s 569ms/step - loss: 0.4131 - accuracy: 0.9555 - val_loss: 2.1309 - val_accuracy: 0.6745\n",
            "— val_f1: 0.5547546163720747\n",
            "Epoch 17/20\n",
            "91/91 [==============================] - 51s 556ms/step - loss: 0.4517 - accuracy: 0.9339 - val_loss: 0.9325 - val_accuracy: 0.7797\n",
            "— val_f1: 0.7727320842595533\n",
            "Epoch 18/20\n",
            "91/91 [==============================] - 51s 556ms/step - loss: 0.4452 - accuracy: 0.9454 - val_loss: 0.9277 - val_accuracy: 0.7788\n",
            "— val_f1: 0.7687874699570241\n",
            "Epoch 19/20\n",
            "91/91 [==============================] - 52s 567ms/step - loss: 0.4053 - accuracy: 0.9536 - val_loss: 0.8733 - val_accuracy: 0.7632\n",
            "— val_f1: 0.7568699040714768\n",
            "Epoch 20/20\n",
            "91/91 [==============================] - 51s 556ms/step - loss: 0.3260 - accuracy: 0.9788 - val_loss: 0.9218 - val_accuracy: 0.7700\n",
            "— val_f1: 0.7582507987220447\n",
            "33/33 [==============================] - 4s 108ms/step - loss: 0.9218 - accuracy: 0.7700\n",
            "f1_score test tweets: 0.7285676921671009\n",
            "f1_score test news: 0.6046031930365922\n",
            "--- Starting trial: run-5\n",
            "{'num_filters': 1024, 'dropout': 0.0002, 'optimizer': 'nadam', 'L2_reg': 0.0002}\n",
            "Epoch 1/20\n",
            "91/91 [==============================] - 53s 560ms/step - loss: 2.5830 - accuracy: 0.5665 - val_loss: 1.4150 - val_accuracy: 0.7329\n",
            "— val_f1: 0.7203169271911114\n",
            "Epoch 2/20\n",
            "91/91 [==============================] - 51s 563ms/step - loss: 1.4211 - accuracy: 0.6838 - val_loss: 1.2987 - val_accuracy: 0.7466\n",
            "— val_f1: 0.7392609853268328\n",
            "Epoch 3/20\n",
            "91/91 [==============================] - 52s 567ms/step - loss: 1.2901 - accuracy: 0.7252 - val_loss: 1.1962 - val_accuracy: 0.7544\n",
            "— val_f1: 0.7346214009171939\n",
            "Epoch 4/20\n",
            "91/91 [==============================] - 51s 562ms/step - loss: 1.1243 - accuracy: 0.7977 - val_loss: 1.1197 - val_accuracy: 0.7485\n",
            "— val_f1: 0.7183298218732044\n",
            "Epoch 5/20\n",
            "91/91 [==============================] - 51s 559ms/step - loss: 1.0237 - accuracy: 0.8050 - val_loss: 1.0528 - val_accuracy: 0.7612\n",
            "— val_f1: 0.7475076716002633\n",
            "Epoch 6/20\n",
            "91/91 [==============================] - 51s 556ms/step - loss: 0.9427 - accuracy: 0.8212 - val_loss: 1.0072 - val_accuracy: 0.7641\n",
            "— val_f1: 0.7600394309571671\n",
            "Epoch 7/20\n",
            "91/91 [==============================] - 52s 573ms/step - loss: 0.8498 - accuracy: 0.8529 - val_loss: 1.1653 - val_accuracy: 0.7008\n",
            "— val_f1: 0.7005063158745478\n",
            "Epoch 8/20\n",
            "91/91 [==============================] - 51s 562ms/step - loss: 0.7905 - accuracy: 0.8692 - val_loss: 0.9484 - val_accuracy: 0.7749\n",
            "— val_f1: 0.7600306181029534\n",
            "Epoch 9/20\n",
            "91/91 [==============================] - 51s 560ms/step - loss: 0.6963 - accuracy: 0.9051 - val_loss: 0.9472 - val_accuracy: 0.7641\n",
            "— val_f1: 0.761287990370453\n",
            "Epoch 10/20\n",
            "91/91 [==============================] - 51s 559ms/step - loss: 0.6520 - accuracy: 0.9158 - val_loss: 0.9564 - val_accuracy: 0.7622\n",
            "— val_f1: 0.7585416666666667\n",
            "Epoch 11/20\n",
            "91/91 [==============================] - 51s 561ms/step - loss: 0.6097 - accuracy: 0.9256 - val_loss: 0.9642 - val_accuracy: 0.7593\n",
            "— val_f1: 0.7571774472500865\n",
            "Epoch 12/20\n",
            "91/91 [==============================] - 52s 569ms/step - loss: 0.5704 - accuracy: 0.9463 - val_loss: 0.9071 - val_accuracy: 0.7729\n",
            "— val_f1: 0.7626761255506018\n",
            "Epoch 13/20\n",
            "91/91 [==============================] - 51s 556ms/step - loss: 0.5371 - accuracy: 0.9499 - val_loss: 1.1579 - val_accuracy: 0.7310\n",
            "— val_f1: 0.7306246385193753\n",
            "Epoch 14/20\n",
            "91/91 [==============================] - 51s 564ms/step - loss: 0.4980 - accuracy: 0.9582 - val_loss: 0.9432 - val_accuracy: 0.7554\n",
            "— val_f1: 0.7370130765342333\n",
            "Epoch 15/20\n",
            "91/91 [==============================] - 51s 559ms/step - loss: 0.4839 - accuracy: 0.9638 - val_loss: 1.0125 - val_accuracy: 0.7583\n",
            "— val_f1: 0.7303936527311565\n",
            "Epoch 16/20\n",
            "91/91 [==============================] - 52s 572ms/step - loss: 0.4993 - accuracy: 0.9539 - val_loss: 0.9612 - val_accuracy: 0.7739\n",
            "— val_f1: 0.7629814911438688\n",
            "Epoch 17/20\n",
            "91/91 [==============================] - 51s 560ms/step - loss: 0.4631 - accuracy: 0.9544 - val_loss: 1.0806 - val_accuracy: 0.7456\n",
            "— val_f1: 0.7049238855556106\n",
            "Epoch 18/20\n",
            "91/91 [==============================] - 51s 560ms/step - loss: 0.4221 - accuracy: 0.9702 - val_loss: 1.0724 - val_accuracy: 0.7544\n",
            "— val_f1: 0.7199017199017199\n",
            "Epoch 19/20\n",
            "91/91 [==============================] - 50s 555ms/step - loss: 0.3950 - accuracy: 0.9755 - val_loss: 1.0529 - val_accuracy: 0.7700\n",
            "— val_f1: 0.7601217342373581\n",
            "Epoch 20/20\n",
            "91/91 [==============================] - 51s 562ms/step - loss: 0.4903 - accuracy: 0.9525 - val_loss: 1.0139 - val_accuracy: 0.7651\n",
            "— val_f1: 0.7523345155736203\n",
            "33/33 [==============================] - 4s 110ms/step - loss: 1.0139 - accuracy: 0.7651\n",
            "f1_score test tweets: 0.7276348672939149\n",
            "f1_score test news: 0.6743417796049376\n",
            "--- Starting trial: run-6\n",
            "{'num_filters': 1024, 'dropout': 0.0002, 'optimizer': 'nadam', 'L2_reg': 0.0004}\n",
            "Epoch 1/20\n",
            "91/91 [==============================] - 54s 578ms/step - loss: 2.5078 - accuracy: 0.5689 - val_loss: 1.5524 - val_accuracy: 0.6881\n",
            "— val_f1: 0.6881091617933723\n",
            "Epoch 2/20\n",
            "91/91 [==============================] - 51s 564ms/step - loss: 1.4823 - accuracy: 0.7067 - val_loss: 1.3800 - val_accuracy: 0.7057\n",
            "— val_f1: 0.6547379211980745\n",
            "Epoch 3/20\n",
            "91/91 [==============================] - 51s 561ms/step - loss: 1.3119 - accuracy: 0.7591 - val_loss: 1.2936 - val_accuracy: 0.7018\n",
            "— val_f1: 0.7017543859649122\n",
            "Epoch 4/20\n",
            "91/91 [==============================] - 52s 574ms/step - loss: 1.1707 - accuracy: 0.7852 - val_loss: 1.1356 - val_accuracy: 0.7641\n",
            "— val_f1: 0.7562945368171021\n",
            "Epoch 5/20\n",
            "91/91 [==============================] - 51s 561ms/step - loss: 1.0387 - accuracy: 0.8134 - val_loss: 1.1261 - val_accuracy: 0.7251\n",
            "— val_f1: 0.7249695817490495\n",
            "Epoch 6/20\n",
            "91/91 [==============================] - 52s 572ms/step - loss: 0.9469 - accuracy: 0.8482 - val_loss: 1.0550 - val_accuracy: 0.7476\n",
            "— val_f1: 0.7136693794736801\n",
            "Epoch 7/20\n",
            "91/91 [==============================] - 51s 561ms/step - loss: 0.8266 - accuracy: 0.8707 - val_loss: 1.0145 - val_accuracy: 0.7476\n",
            "— val_f1: 0.7066911556126082\n",
            "Epoch 8/20\n",
            "91/91 [==============================] - 51s 560ms/step - loss: 0.7512 - accuracy: 0.8932 - val_loss: 0.9947 - val_accuracy: 0.7583\n",
            "— val_f1: 0.7329527088012427\n",
            "Epoch 9/20\n",
            "91/91 [==============================] - 51s 557ms/step - loss: 0.6834 - accuracy: 0.9111 - val_loss: 0.9489 - val_accuracy: 0.7456\n",
            "— val_f1: 0.7105726486581131\n",
            "Epoch 10/20\n",
            "91/91 [==============================] - 51s 557ms/step - loss: 0.6567 - accuracy: 0.9178 - val_loss: 1.0706 - val_accuracy: 0.7485\n",
            "— val_f1: 0.70757605885862\n",
            "Epoch 11/20\n",
            "91/91 [==============================] - 52s 573ms/step - loss: 0.6331 - accuracy: 0.9228 - val_loss: 0.9846 - val_accuracy: 0.7359\n",
            "— val_f1: 0.7352131990572102\n",
            "Epoch 12/20\n",
            "91/91 [==============================] - 51s 563ms/step - loss: 0.5703 - accuracy: 0.9424 - val_loss: 1.0017 - val_accuracy: 0.7417\n",
            "— val_f1: 0.7411249434671872\n",
            "Epoch 13/20\n",
            "91/91 [==============================] - 51s 561ms/step - loss: 0.5823 - accuracy: 0.9179 - val_loss: 0.9419 - val_accuracy: 0.7827\n",
            "— val_f1: 0.7724731922747609\n",
            "Epoch 14/20\n",
            "91/91 [==============================] - 51s 560ms/step - loss: 0.5107 - accuracy: 0.9521 - val_loss: 1.1459 - val_accuracy: 0.7057\n",
            "— val_f1: 0.7052901900359527\n",
            "Epoch 15/20\n",
            "91/91 [==============================] - 52s 573ms/step - loss: 0.5091 - accuracy: 0.9412 - val_loss: 1.4368 - val_accuracy: 0.6452\n",
            "— val_f1: 0.6401359810058278\n",
            "Epoch 16/20\n",
            "91/91 [==============================] - 51s 561ms/step - loss: 0.5055 - accuracy: 0.9492 - val_loss: 0.9310 - val_accuracy: 0.7641\n",
            "— val_f1: 0.7494965555927731\n",
            "Epoch 17/20\n",
            "91/91 [==============================] - 51s 560ms/step - loss: 0.4338 - accuracy: 0.9692 - val_loss: 0.9962 - val_accuracy: 0.7739\n",
            "— val_f1: 0.766532751639936\n",
            "Epoch 18/20\n",
            "91/91 [==============================] - 51s 559ms/step - loss: 0.4338 - accuracy: 0.9669 - val_loss: 1.0619 - val_accuracy: 0.7544\n",
            "— val_f1: 0.7264266335975758\n",
            "Epoch 19/20\n",
            "91/91 [==============================] - 52s 572ms/step - loss: 0.4229 - accuracy: 0.9685 - val_loss: 0.9932 - val_accuracy: 0.7690\n",
            "— val_f1: 0.7519552388772996\n",
            "Epoch 20/20\n",
            "91/91 [==============================] - 52s 572ms/step - loss: 0.3922 - accuracy: 0.9775 - val_loss: 0.9186 - val_accuracy: 0.7632\n",
            "— val_f1: 0.7488361972133206\n",
            "33/33 [==============================] - 4s 110ms/step - loss: 0.9186 - accuracy: 0.7632\n",
            "f1_score test tweets: 0.7242538006354049\n",
            "f1_score test news: 0.6534996534996536\n",
            "--- Starting trial: run-7\n",
            "{'num_filters': 1024, 'dropout': 0.0002, 'optimizer': 'nadam', 'L2_reg': 0.0006000000000000001}\n",
            "Epoch 1/20\n",
            "91/91 [==============================] - 53s 568ms/step - loss: 2.5214 - accuracy: 0.5699 - val_loss: 1.8007 - val_accuracy: 0.6209\n",
            "— val_f1: 0.42678024378578905\n",
            "Epoch 2/20\n",
            "91/91 [==============================] - 51s 560ms/step - loss: 1.6073 - accuracy: 0.6971 - val_loss: 1.6361 - val_accuracy: 0.6540\n",
            "— val_f1: 0.5079269651916049\n",
            "Epoch 3/20\n",
            "91/91 [==============================] - 52s 572ms/step - loss: 1.4155 - accuracy: 0.7370 - val_loss: 1.3284 - val_accuracy: 0.7622\n",
            "— val_f1: 0.745046439628483\n",
            "Epoch 4/20\n",
            "91/91 [==============================] - 51s 558ms/step - loss: 1.2389 - accuracy: 0.7904 - val_loss: 1.2662 - val_accuracy: 0.6998\n",
            "— val_f1: 0.6120373416882332\n",
            "Epoch 5/20\n",
            "91/91 [==============================] - 51s 557ms/step - loss: 1.1260 - accuracy: 0.8027 - val_loss: 1.1350 - val_accuracy: 0.7505\n",
            "— val_f1: 0.7197068327435555\n",
            "Epoch 6/20\n",
            "91/91 [==============================] - 51s 557ms/step - loss: 0.9607 - accuracy: 0.8552 - val_loss: 1.0711 - val_accuracy: 0.7641\n",
            "— val_f1: 0.7540231342603416\n",
            "Epoch 7/20\n",
            "91/91 [==============================] - 51s 557ms/step - loss: 0.8835 - accuracy: 0.8533 - val_loss: 1.0186 - val_accuracy: 0.7622\n",
            "— val_f1: 0.7576712652312124\n",
            "Epoch 8/20\n",
            "91/91 [==============================] - 53s 582ms/step - loss: 0.7978 - accuracy: 0.8915 - val_loss: 0.9989 - val_accuracy: 0.7544\n",
            "— val_f1: 0.7518361392125621\n",
            "Epoch 9/20\n",
            "91/91 [==============================] - 51s 562ms/step - loss: 0.7387 - accuracy: 0.8965 - val_loss: 1.1295 - val_accuracy: 0.7388\n",
            "— val_f1: 0.6936084863612052\n",
            "Epoch 10/20\n",
            "91/91 [==============================] - 51s 558ms/step - loss: 0.6838 - accuracy: 0.9224 - val_loss: 0.9537 - val_accuracy: 0.7729\n",
            "— val_f1: 0.7612158853794697\n",
            "Epoch 11/20\n",
            "91/91 [==============================] - 51s 560ms/step - loss: 0.6136 - accuracy: 0.9378 - val_loss: 0.9736 - val_accuracy: 0.7690\n",
            "— val_f1: 0.7562165961034677\n",
            "Epoch 12/20\n",
            "91/91 [==============================] - 53s 577ms/step - loss: 0.5798 - accuracy: 0.9478 - val_loss: 1.0751 - val_accuracy: 0.7641\n",
            "— val_f1: 0.7509558867780697\n",
            "Epoch 13/20\n",
            "91/91 [==============================] - 51s 566ms/step - loss: 0.5747 - accuracy: 0.9434 - val_loss: 1.1933 - val_accuracy: 0.7251\n",
            "— val_f1: 0.66457372069837\n",
            "Epoch 14/20\n",
            "91/91 [==============================] - 51s 562ms/step - loss: 0.5124 - accuracy: 0.9588 - val_loss: 0.9712 - val_accuracy: 0.7602\n",
            "— val_f1: 0.7524442107906218\n",
            "Epoch 15/20\n",
            "91/91 [==============================] - 51s 563ms/step - loss: 0.4995 - accuracy: 0.9576 - val_loss: 1.3845 - val_accuracy: 0.7037\n",
            "— val_f1: 0.6188949439163265\n",
            "Epoch 16/20\n",
            "91/91 [==============================] - 52s 572ms/step - loss: 0.4913 - accuracy: 0.9514 - val_loss: 1.0141 - val_accuracy: 0.7554\n",
            "— val_f1: 0.7432306991296649\n",
            "Epoch 17/20\n",
            "91/91 [==============================] - 52s 575ms/step - loss: 0.4712 - accuracy: 0.9616 - val_loss: 0.8950 - val_accuracy: 0.7573\n",
            "— val_f1: 0.741063238691015\n",
            "Epoch 18/20\n",
            "91/91 [==============================] - 51s 560ms/step - loss: 0.4368 - accuracy: 0.9724 - val_loss: 1.0533 - val_accuracy: 0.7632\n",
            "— val_f1: 0.758858388617158\n",
            "Epoch 19/20\n",
            "91/91 [==============================] - 51s 559ms/step - loss: 0.4119 - accuracy: 0.9741 - val_loss: 1.0561 - val_accuracy: 0.7700\n",
            "— val_f1: 0.7539348313875971\n",
            "Epoch 20/20\n",
            "91/91 [==============================] - 51s 564ms/step - loss: 0.4293 - accuracy: 0.9623 - val_loss: 1.1589 - val_accuracy: 0.7544\n",
            "— val_f1: 0.7199017199017199\n",
            "33/33 [==============================] - 4s 112ms/step - loss: 1.1589 - accuracy: 0.7544\n",
            "f1_score test tweets: 0.7135923072219166\n",
            "f1_score test news: 0.6103896103896105\n",
            "--- Starting trial: run-8\n",
            "{'num_filters': 1024, 'dropout': 0.0004, 'optimizer': 'nadam', 'L2_reg': 0.0}\n",
            "Epoch 1/20\n",
            "91/91 [==============================] - 54s 580ms/step - loss: 3.2698 - accuracy: 0.5654 - val_loss: 1.9788 - val_accuracy: 0.6667\n",
            "— val_f1: 0.666564039408867\n",
            "Epoch 2/20\n",
            "91/91 [==============================] - 51s 563ms/step - loss: 1.8603 - accuracy: 0.7067 - val_loss: 1.6905 - val_accuracy: 0.6979\n",
            "— val_f1: 0.6305202408832385\n",
            "Epoch 3/20\n",
            "91/91 [==============================] - 51s 561ms/step - loss: 1.5585 - accuracy: 0.7385 - val_loss: 1.4194 - val_accuracy: 0.6949\n",
            "— val_f1: 0.6949082980633577\n",
            "Epoch 4/20\n",
            "91/91 [==============================] - 51s 561ms/step - loss: 1.2973 - accuracy: 0.7647 - val_loss: 1.1872 - val_accuracy: 0.7544\n",
            "— val_f1: 0.7503784602076125\n",
            "Epoch 5/20\n",
            "91/91 [==============================] - 52s 570ms/step - loss: 1.1324 - accuracy: 0.7795 - val_loss: 1.0398 - val_accuracy: 0.7554\n",
            "— val_f1: 0.7306086583573494\n",
            "Epoch 6/20\n",
            "91/91 [==============================] - 51s 562ms/step - loss: 0.9223 - accuracy: 0.8323 - val_loss: 1.1265 - val_accuracy: 0.7222\n",
            "— val_f1: 0.6564227594512821\n",
            "Epoch 7/20\n",
            "91/91 [==============================] - 51s 561ms/step - loss: 0.8458 - accuracy: 0.8114 - val_loss: 0.9287 - val_accuracy: 0.7622\n",
            "— val_f1: 0.7343694957408972\n",
            "Epoch 8/20\n",
            "91/91 [==============================] - 51s 561ms/step - loss: 0.7167 - accuracy: 0.8591 - val_loss: 0.8413 - val_accuracy: 0.7466\n",
            "— val_f1: 0.7436419829017775\n",
            "Epoch 9/20\n",
            "91/91 [==============================] - 51s 559ms/step - loss: 0.6484 - accuracy: 0.8684 - val_loss: 0.8227 - val_accuracy: 0.7573\n",
            "— val_f1: 0.7541124191159272\n",
            "Epoch 10/20\n",
            "91/91 [==============================] - 52s 575ms/step - loss: 0.6167 - accuracy: 0.8743 - val_loss: 0.8572 - val_accuracy: 0.7690\n",
            "— val_f1: 0.740697730217381\n",
            "Epoch 11/20\n",
            "91/91 [==============================] - 51s 560ms/step - loss: 0.5811 - accuracy: 0.8888 - val_loss: 0.7604 - val_accuracy: 0.7680\n",
            "— val_f1: 0.7641269951663943\n",
            "Epoch 12/20\n",
            "91/91 [==============================] - 52s 569ms/step - loss: 0.5381 - accuracy: 0.9031 - val_loss: 0.8179 - val_accuracy: 0.7856\n",
            "— val_f1: 0.7711010514018692\n",
            "Epoch 13/20\n",
            "91/91 [==============================] - 51s 559ms/step - loss: 0.5056 - accuracy: 0.9152 - val_loss: 1.0979 - val_accuracy: 0.7329\n",
            "— val_f1: 0.6785655482785116\n",
            "Epoch 14/20\n",
            "91/91 [==============================] - 52s 571ms/step - loss: 0.5163 - accuracy: 0.9105 - val_loss: 0.7984 - val_accuracy: 0.7719\n",
            "— val_f1: 0.7600820232399179\n",
            "Epoch 15/20\n",
            "91/91 [==============================] - 51s 559ms/step - loss: 0.4404 - accuracy: 0.9399 - val_loss: 0.8887 - val_accuracy: 0.7749\n",
            "— val_f1: 0.7590195087579448\n",
            "Epoch 16/20\n",
            "91/91 [==============================] - 51s 558ms/step - loss: 0.4915 - accuracy: 0.9166 - val_loss: 0.8171 - val_accuracy: 0.7719\n",
            "— val_f1: 0.7670833123134893\n",
            "Epoch 17/20\n",
            "91/91 [==============================] - 51s 559ms/step - loss: 0.4242 - accuracy: 0.9470 - val_loss: 0.9189 - val_accuracy: 0.7661\n",
            "— val_f1: 0.7618983155736914\n",
            "Epoch 18/20\n",
            "91/91 [==============================] - 52s 575ms/step - loss: 0.4175 - accuracy: 0.9562 - val_loss: 0.9726 - val_accuracy: 0.7515\n",
            "— val_f1: 0.7244941477515046\n",
            "Epoch 19/20\n",
            "91/91 [==============================] - 51s 560ms/step - loss: 0.3968 - accuracy: 0.9562 - val_loss: 1.2147 - val_accuracy: 0.7495\n",
            "— val_f1: 0.7084618182742901\n",
            "Epoch 20/20\n",
            "91/91 [==============================] - 51s 562ms/step - loss: 0.3777 - accuracy: 0.9589 - val_loss: 0.9029 - val_accuracy: 0.7719\n",
            "— val_f1: 0.7653348867941494\n",
            "33/33 [==============================] - 4s 110ms/step - loss: 0.9029 - accuracy: 0.7719\n",
            "f1_score test tweets: 0.7204278096698611\n",
            "f1_score test news: 0.6758051663292731\n",
            "--- Starting trial: run-9\n",
            "{'num_filters': 1024, 'dropout': 0.0004, 'optimizer': 'nadam', 'L2_reg': 0.0002}\n",
            "Epoch 1/20\n",
            "91/91 [==============================] - 54s 574ms/step - loss: 2.8193 - accuracy: 0.5544 - val_loss: 1.9276 - val_accuracy: 0.7212\n",
            "— val_f1: 0.7156462585034014\n",
            "Epoch 2/20\n",
            "91/91 [==============================] - 51s 566ms/step - loss: 1.8585 - accuracy: 0.6886 - val_loss: 1.5093 - val_accuracy: 0.7466\n",
            "— val_f1: 0.7365791230363907\n",
            "Epoch 3/20\n",
            "91/91 [==============================] - 52s 570ms/step - loss: 1.4516 - accuracy: 0.7323 - val_loss: 1.2196 - val_accuracy: 0.7495\n",
            "— val_f1: 0.7363799507115828\n",
            "Epoch 4/20\n",
            "91/91 [==============================] - 51s 565ms/step - loss: 1.1393 - accuracy: 0.7666 - val_loss: 1.0596 - val_accuracy: 0.7417\n",
            "— val_f1: 0.7129088085013373\n",
            "Epoch 5/20\n",
            "91/91 [==============================] - 52s 566ms/step - loss: 0.9419 - accuracy: 0.8085 - val_loss: 1.0211 - val_accuracy: 0.7320\n",
            "— val_f1: 0.6819149811674278\n",
            "Epoch 6/20\n",
            "91/91 [==============================] - 52s 568ms/step - loss: 0.8546 - accuracy: 0.8097 - val_loss: 0.8687 - val_accuracy: 0.7544\n",
            "— val_f1: 0.7472837242398533\n",
            "Epoch 7/20\n",
            "91/91 [==============================] - 51s 562ms/step - loss: 0.7609 - accuracy: 0.8352 - val_loss: 0.9138 - val_accuracy: 0.7173\n",
            "— val_f1: 0.7173220746055392\n",
            "Epoch 8/20\n",
            "91/91 [==============================] - 51s 561ms/step - loss: 0.6893 - accuracy: 0.8456 - val_loss: 0.8133 - val_accuracy: 0.7710\n",
            "— val_f1: 0.7545831802298537\n",
            "Epoch 9/20\n",
            "91/91 [==============================] - 51s 565ms/step - loss: 0.6310 - accuracy: 0.8700 - val_loss: 0.8283 - val_accuracy: 0.7680\n",
            "— val_f1: 0.7533892964483082\n",
            "Epoch 10/20\n",
            "91/91 [==============================] - 51s 560ms/step - loss: 0.6128 - accuracy: 0.8674 - val_loss: 0.7953 - val_accuracy: 0.7729\n",
            "— val_f1: 0.7553269993070986\n",
            "Epoch 11/20\n",
            "91/91 [==============================] - 51s 560ms/step - loss: 0.5747 - accuracy: 0.8895 - val_loss: 0.9570 - val_accuracy: 0.7066\n",
            "— val_f1: 0.7060107552164894\n",
            "Epoch 12/20\n",
            "91/91 [==============================] - 51s 560ms/step - loss: 0.5530 - accuracy: 0.8900 - val_loss: 0.9263 - val_accuracy: 0.7427\n",
            "— val_f1: 0.7070194870374857\n",
            "Epoch 13/20\n",
            "91/91 [==============================] - 51s 562ms/step - loss: 0.4962 - accuracy: 0.9212 - val_loss: 0.8642 - val_accuracy: 0.7524\n",
            "— val_f1: 0.7440240452616691\n",
            "Epoch 14/20\n",
            "91/91 [==============================] - 51s 561ms/step - loss: 0.4865 - accuracy: 0.9251 - val_loss: 0.9168 - val_accuracy: 0.7222\n",
            "— val_f1: 0.7222008464794152\n",
            "Epoch 15/20\n",
            "91/91 [==============================] - 51s 561ms/step - loss: 0.4720 - accuracy: 0.9335 - val_loss: 0.8940 - val_accuracy: 0.7651\n",
            "— val_f1: 0.7429867733804536\n",
            "Epoch 16/20\n",
            "91/91 [==============================] - 51s 558ms/step - loss: 0.4335 - accuracy: 0.9475 - val_loss: 0.9849 - val_accuracy: 0.7661\n",
            "— val_f1: 0.7376048557593944\n",
            "Epoch 17/20\n",
            "91/91 [==============================] - 51s 557ms/step - loss: 0.4312 - accuracy: 0.9454 - val_loss: 0.9693 - val_accuracy: 0.7680\n",
            "— val_f1: 0.7543657052726453\n",
            "Epoch 18/20\n",
            "91/91 [==============================] - 51s 557ms/step - loss: 0.4490 - accuracy: 0.9426 - val_loss: 1.1743 - val_accuracy: 0.7349\n",
            "— val_f1: 0.6850956655969452\n",
            "Epoch 19/20\n",
            "91/91 [==============================] - 51s 557ms/step - loss: 0.4322 - accuracy: 0.9556 - val_loss: 1.1502 - val_accuracy: 0.7018\n",
            "— val_f1: 0.7016410143346422\n",
            "Epoch 20/20\n",
            "91/91 [==============================] - 51s 558ms/step - loss: 0.4195 - accuracy: 0.9469 - val_loss: 0.9460 - val_accuracy: 0.7632\n",
            "— val_f1: 0.7593536897884725\n",
            "33/33 [==============================] - 4s 112ms/step - loss: 0.9460 - accuracy: 0.7632\n",
            "f1_score test tweets: 0.7079897389600237\n",
            "f1_score test news: 0.6971899224806202\n",
            "--- Starting trial: run-10\n",
            "{'num_filters': 1024, 'dropout': 0.0004, 'optimizer': 'nadam', 'L2_reg': 0.0004}\n",
            "Epoch 1/20\n",
            "91/91 [==============================] - 54s 570ms/step - loss: 4.0410 - accuracy: 0.5684 - val_loss: 2.2518 - val_accuracy: 0.6550\n",
            "— val_f1: 0.5405574979886962\n",
            "Epoch 2/20\n",
            "91/91 [==============================] - 51s 561ms/step - loss: 2.1820 - accuracy: 0.6990 - val_loss: 1.9763 - val_accuracy: 0.7086\n",
            "— val_f1: 0.708375041708375\n",
            "Epoch 3/20\n",
            "91/91 [==============================] - 51s 562ms/step - loss: 1.8984 - accuracy: 0.7317 - val_loss: 1.7166 - val_accuracy: 0.7466\n",
            "— val_f1: 0.7192815560952818\n",
            "Epoch 4/20\n",
            "91/91 [==============================] - 51s 559ms/step - loss: 1.6300 - accuracy: 0.7631 - val_loss: 1.5142 - val_accuracy: 0.7368\n",
            "— val_f1: 0.7337820591672305\n",
            "Epoch 5/20\n",
            "91/91 [==============================] - 51s 561ms/step - loss: 1.3900 - accuracy: 0.7948 - val_loss: 1.3745 - val_accuracy: 0.7125\n",
            "— val_f1: 0.6451146544537425\n",
            "Epoch 6/20\n",
            "91/91 [==============================] - 51s 564ms/step - loss: 1.1955 - accuracy: 0.8331 - val_loss: 1.3166 - val_accuracy: 0.7446\n",
            "— val_f1: 0.7030423543448001\n",
            "Epoch 7/20\n",
            "91/91 [==============================] - 51s 562ms/step - loss: 1.0716 - accuracy: 0.8386 - val_loss: 1.1271 - val_accuracy: 0.7710\n",
            "— val_f1: 0.7645674558033033\n",
            "Epoch 8/20\n",
            "91/91 [==============================] - 51s 561ms/step - loss: 0.9519 - accuracy: 0.8588 - val_loss: 1.0878 - val_accuracy: 0.7602\n",
            "— val_f1: 0.7347533292978208\n",
            "Epoch 9/20\n",
            "91/91 [==============================] - 51s 561ms/step - loss: 0.8902 - accuracy: 0.8623 - val_loss: 1.1777 - val_accuracy: 0.7271\n",
            "— val_f1: 0.6649061251912957\n",
            "Epoch 10/20\n",
            "91/91 [==============================] - 51s 562ms/step - loss: 0.8121 - accuracy: 0.8757 - val_loss: 1.3302 - val_accuracy: 0.5994\n",
            "— val_f1: 0.586547898599393\n",
            "Epoch 11/20\n",
            "91/91 [==============================] - 51s 561ms/step - loss: 0.7559 - accuracy: 0.8851 - val_loss: 0.9869 - val_accuracy: 0.7622\n",
            "— val_f1: 0.7575388954317237\n",
            "Epoch 12/20\n",
            "91/91 [==============================] - 51s 564ms/step - loss: 0.7152 - accuracy: 0.8997 - val_loss: 0.9522 - val_accuracy: 0.7680\n",
            "— val_f1: 0.7619489559164733\n",
            "Epoch 13/20\n",
            "91/91 [==============================] - 51s 561ms/step - loss: 0.6771 - accuracy: 0.9137 - val_loss: 1.0410 - val_accuracy: 0.7671\n",
            "— val_f1: 0.7421283710952082\n",
            "Epoch 14/20\n",
            "91/91 [==============================] - 51s 561ms/step - loss: 0.6100 - accuracy: 0.9351 - val_loss: 1.4193 - val_accuracy: 0.7096\n",
            "— val_f1: 0.6264167542337675\n",
            "Epoch 15/20\n",
            "91/91 [==============================] - 51s 559ms/step - loss: 0.6124 - accuracy: 0.9220 - val_loss: 0.9359 - val_accuracy: 0.7719\n",
            "— val_f1: 0.7560201294266853\n",
            "Epoch 16/20\n",
            "91/91 [==============================] - 51s 562ms/step - loss: 0.5612 - accuracy: 0.9459 - val_loss: 0.9391 - val_accuracy: 0.7671\n",
            "— val_f1: 0.7524778560072677\n",
            "Epoch 17/20\n",
            "91/91 [==============================] - 51s 561ms/step - loss: 0.5156 - accuracy: 0.9540 - val_loss: 1.3887 - val_accuracy: 0.7242\n",
            "— val_f1: 0.6657307154328342\n",
            "Epoch 18/20\n",
            "91/91 [==============================] - 51s 563ms/step - loss: 0.5395 - accuracy: 0.9343 - val_loss: 1.0129 - val_accuracy: 0.7534\n",
            "— val_f1: 0.7500488678545808\n",
            "Epoch 19/20\n",
            "91/91 [==============================] - 51s 562ms/step - loss: 0.5006 - accuracy: 0.9530 - val_loss: 1.2466 - val_accuracy: 0.7193\n",
            "— val_f1: 0.7191915429031926\n",
            "Epoch 20/20\n",
            "91/91 [==============================] - 51s 562ms/step - loss: 0.4973 - accuracy: 0.9526 - val_loss: 0.9702 - val_accuracy: 0.7593\n",
            "— val_f1: 0.7466375401780583\n",
            "33/33 [==============================] - 4s 113ms/step - loss: 0.9702 - accuracy: 0.7593\n",
            "f1_score test tweets: 0.7245556311927994\n",
            "f1_score test news: 0.6322576207332624\n",
            "--- Starting trial: run-11\n",
            "{'num_filters': 1024, 'dropout': 0.0004, 'optimizer': 'nadam', 'L2_reg': 0.0006000000000000001}\n",
            "Epoch 1/20\n",
            "91/91 [==============================] - 54s 570ms/step - loss: 3.1643 - accuracy: 0.5662 - val_loss: 2.1918 - val_accuracy: 0.7329\n",
            "— val_f1: 0.7166545718432511\n",
            "Epoch 2/20\n",
            "91/91 [==============================] - 51s 564ms/step - loss: 2.1022 - accuracy: 0.7047 - val_loss: 1.7810 - val_accuracy: 0.7378\n",
            "— val_f1: 0.7316932565077952\n",
            "Epoch 3/20\n",
            "91/91 [==============================] - 51s 566ms/step - loss: 1.6736 - accuracy: 0.7572 - val_loss: 1.4578 - val_accuracy: 0.7622\n",
            "— val_f1: 0.7479267776949876\n",
            "Epoch 4/20\n",
            "91/91 [==============================] - 51s 564ms/step - loss: 1.3531 - accuracy: 0.7957 - val_loss: 1.2419 - val_accuracy: 0.7632\n",
            "— val_f1: 0.751852017736373\n",
            "Epoch 5/20\n",
            "91/91 [==============================] - 51s 563ms/step - loss: 1.1538 - accuracy: 0.8063 - val_loss: 1.1738 - val_accuracy: 0.7203\n",
            "— val_f1: 0.7201556686481632\n",
            "Epoch 6/20\n",
            "91/91 [==============================] - 51s 562ms/step - loss: 1.0213 - accuracy: 0.8078 - val_loss: 1.0652 - val_accuracy: 0.7281\n",
            "— val_f1: 0.7277885709884204\n",
            "Epoch 7/20\n",
            "91/91 [==============================] - 51s 565ms/step - loss: 0.8787 - accuracy: 0.8423 - val_loss: 1.0017 - val_accuracy: 0.7378\n",
            "— val_f1: 0.7373974186366252\n",
            "Epoch 8/20\n",
            "91/91 [==============================] - 51s 565ms/step - loss: 0.8146 - accuracy: 0.8553 - val_loss: 0.9719 - val_accuracy: 0.7407\n",
            "— val_f1: 0.740123560241331\n",
            "Epoch 9/20\n",
            "91/91 [==============================] - 51s 564ms/step - loss: 0.7579 - accuracy: 0.8637 - val_loss: 0.9168 - val_accuracy: 0.7671\n",
            "— val_f1: 0.7610249223521524\n",
            "Epoch 10/20\n",
            "91/91 [==============================] - 51s 563ms/step - loss: 0.6928 - accuracy: 0.8856 - val_loss: 0.9041 - val_accuracy: 0.7719\n",
            "— val_f1: 0.7549603174603174\n",
            "Epoch 11/20\n",
            "91/91 [==============================] - 51s 559ms/step - loss: 0.6634 - accuracy: 0.8879 - val_loss: 1.0868 - val_accuracy: 0.7388\n",
            "— val_f1: 0.6908596226924202\n",
            "Epoch 12/20\n",
            "91/91 [==============================] - 51s 560ms/step - loss: 0.6242 - accuracy: 0.8939 - val_loss: 1.1531 - val_accuracy: 0.7290\n",
            "— val_f1: 0.6713114905229\n",
            "Epoch 13/20\n",
            "91/91 [==============================] - 51s 561ms/step - loss: 0.5713 - accuracy: 0.9175 - val_loss: 0.9452 - val_accuracy: 0.7398\n",
            "— val_f1: 0.7393895286613297\n",
            "Epoch 14/20\n",
            "91/91 [==============================] - 51s 561ms/step - loss: 0.5636 - accuracy: 0.9107 - val_loss: 1.0829 - val_accuracy: 0.7466\n",
            "— val_f1: 0.7072753209700428\n",
            "Epoch 15/20\n",
            "91/91 [==============================] - 51s 561ms/step - loss: 0.5064 - accuracy: 0.9342 - val_loss: 0.9899 - val_accuracy: 0.7641\n",
            "— val_f1: 0.7433440974476231\n",
            "Epoch 16/20\n",
            "91/91 [==============================] - 51s 558ms/step - loss: 0.5198 - accuracy: 0.9368 - val_loss: 1.1050 - val_accuracy: 0.6959\n",
            "— val_f1: 0.6949978085637518\n",
            "Epoch 17/20\n",
            "91/91 [==============================] - 51s 559ms/step - loss: 0.4791 - accuracy: 0.9358 - val_loss: 0.9228 - val_accuracy: 0.7641\n",
            "— val_f1: 0.7465828924162258\n",
            "Epoch 18/20\n",
            "91/91 [==============================] - 51s 562ms/step - loss: 0.4371 - accuracy: 0.9632 - val_loss: 1.3239 - val_accuracy: 0.7398\n",
            "— val_f1: 0.6864744599981458\n",
            "Epoch 19/20\n",
            "91/91 [==============================] - 51s 560ms/step - loss: 0.5315 - accuracy: 0.9114 - val_loss: 0.8687 - val_accuracy: 0.7671\n",
            "— val_f1: 0.7611757429961383\n",
            "Epoch 20/20\n",
            "91/91 [==============================] - 51s 562ms/step - loss: 0.4240 - accuracy: 0.9627 - val_loss: 0.9317 - val_accuracy: 0.7690\n",
            "— val_f1: 0.7608920748705694\n",
            "33/33 [==============================] - 4s 113ms/step - loss: 0.9317 - accuracy: 0.7690\n",
            "f1_score test tweets: 0.7260866587526253\n",
            "f1_score test news: 0.681843891402715\n",
            "--- Starting trial: run-12\n",
            "{'num_filters': 1024, 'dropout': 0.0006000000000000001, 'optimizer': 'nadam', 'L2_reg': 0.0}\n",
            "Epoch 1/20\n",
            "91/91 [==============================] - 57s 607ms/step - loss: 3.9766 - accuracy: 0.5644 - val_loss: 2.4700 - val_accuracy: 0.7329\n",
            "— val_f1: 0.7230414564943254\n",
            "Epoch 2/20\n",
            "91/91 [==============================] - 52s 566ms/step - loss: 2.3649 - accuracy: 0.6893 - val_loss: 1.9376 - val_accuracy: 0.6871\n",
            "— val_f1: 0.6096996185237021\n",
            "Epoch 3/20\n",
            "91/91 [==============================] - 51s 565ms/step - loss: 1.7801 - accuracy: 0.7415 - val_loss: 1.4999 - val_accuracy: 0.7105\n",
            "— val_f1: 0.7101074532300184\n",
            "Epoch 4/20\n",
            "91/91 [==============================] - 51s 566ms/step - loss: 1.3557 - accuracy: 0.7783 - val_loss: 1.2439 - val_accuracy: 0.7027\n",
            "— val_f1: 0.6224969750780207\n",
            "Epoch 5/20\n",
            "91/91 [==============================] - 52s 567ms/step - loss: 1.0784 - accuracy: 0.7869 - val_loss: 1.0512 - val_accuracy: 0.7456\n",
            "— val_f1: 0.7044262224513156\n",
            "Epoch 6/20\n",
            "91/91 [==============================] - 51s 566ms/step - loss: 0.9047 - accuracy: 0.8036 - val_loss: 0.8888 - val_accuracy: 0.7680\n",
            "— val_f1: 0.7536371083928926\n",
            "Epoch 7/20\n",
            "91/91 [==============================] - 51s 566ms/step - loss: 0.7556 - accuracy: 0.8285 - val_loss: 1.2510 - val_accuracy: 0.6754\n",
            "— val_f1: 0.5566999474513925\n",
            "Epoch 8/20\n",
            "91/91 [==============================] - 51s 565ms/step - loss: 0.7044 - accuracy: 0.8198 - val_loss: 0.7722 - val_accuracy: 0.7671\n",
            "— val_f1: 0.7541593521887291\n",
            "Epoch 9/20\n",
            "91/91 [==============================] - 51s 565ms/step - loss: 0.6488 - accuracy: 0.8459 - val_loss: 0.8003 - val_accuracy: 0.7495\n",
            "— val_f1: 0.7483746296216773\n",
            "Epoch 10/20\n",
            "91/91 [==============================] - 51s 564ms/step - loss: 0.5988 - accuracy: 0.8574 - val_loss: 0.8298 - val_accuracy: 0.7632\n",
            "— val_f1: 0.7363798140517497\n",
            "Epoch 11/20\n",
            "91/91 [==============================] - 51s 563ms/step - loss: 0.5716 - accuracy: 0.8752 - val_loss: 0.7986 - val_accuracy: 0.7739\n",
            "— val_f1: 0.7593623758052188\n",
            "Epoch 12/20\n",
            "91/91 [==============================] - 51s 561ms/step - loss: 0.5659 - accuracy: 0.8842 - val_loss: 0.8294 - val_accuracy: 0.7573\n",
            "— val_f1: 0.7283494833861626\n",
            "Epoch 13/20\n",
            "91/91 [==============================] - 51s 564ms/step - loss: 0.4969 - accuracy: 0.9017 - val_loss: 0.7618 - val_accuracy: 0.7593\n",
            "— val_f1: 0.7546250708030151\n",
            "Epoch 14/20\n",
            "91/91 [==============================] - 51s 562ms/step - loss: 0.4923 - accuracy: 0.8993 - val_loss: 0.7647 - val_accuracy: 0.7807\n",
            "— val_f1: 0.7729988052568697\n",
            "Epoch 15/20\n",
            "91/91 [==============================] - 51s 566ms/step - loss: 0.5006 - accuracy: 0.9061 - val_loss: 0.8075 - val_accuracy: 0.7749\n",
            "— val_f1: 0.7576989961631535\n",
            "Epoch 16/20\n",
            "91/91 [==============================] - 51s 563ms/step - loss: 0.4389 - accuracy: 0.9342 - val_loss: 0.8075 - val_accuracy: 0.7612\n",
            "— val_f1: 0.7556314046260588\n",
            "Epoch 17/20\n",
            "91/91 [==============================] - 51s 561ms/step - loss: 0.4148 - accuracy: 0.9397 - val_loss: 0.8672 - val_accuracy: 0.7622\n",
            "— val_f1: 0.7424497438324313\n",
            "Epoch 18/20\n",
            "91/91 [==============================] - 51s 561ms/step - loss: 0.4115 - accuracy: 0.9401 - val_loss: 1.1842 - val_accuracy: 0.6959\n",
            "— val_f1: 0.6031636625096075\n",
            "Epoch 19/20\n",
            "91/91 [==============================] - 51s 561ms/step - loss: 0.4230 - accuracy: 0.9392 - val_loss: 0.8724 - val_accuracy: 0.7524\n",
            "— val_f1: 0.7325152215593939\n",
            "Epoch 20/20\n",
            "91/91 [==============================] - 51s 561ms/step - loss: 0.4148 - accuracy: 0.9459 - val_loss: 0.9045 - val_accuracy: 0.7612\n",
            "— val_f1: 0.7465177322629472\n",
            "33/33 [==============================] - 4s 114ms/step - loss: 0.9045 - accuracy: 0.7612\n",
            "f1_score test tweets: 0.7220035116669853\n",
            "f1_score test news: 0.6384906850193802\n",
            "--- Starting trial: run-13\n",
            "{'num_filters': 1024, 'dropout': 0.0006000000000000001, 'optimizer': 'nadam', 'L2_reg': 0.0002}\n",
            "Epoch 1/20\n",
            "91/91 [==============================] - 53s 569ms/step - loss: 3.9455 - accuracy: 0.5643 - val_loss: 2.5396 - val_accuracy: 0.7271\n",
            "— val_f1: 0.7171917638303151\n",
            "Epoch 2/20\n",
            "91/91 [==============================] - 52s 568ms/step - loss: 2.4117 - accuracy: 0.7037 - val_loss: 1.9541 - val_accuracy: 0.7466\n",
            "— val_f1: 0.7271276595744681\n",
            "Epoch 3/20\n",
            "91/91 [==============================] - 52s 568ms/step - loss: 1.8161 - accuracy: 0.7634 - val_loss: 1.5804 - val_accuracy: 0.7290\n",
            "— val_f1: 0.6804798157450184\n",
            "Epoch 4/20\n",
            "91/91 [==============================] - 52s 571ms/step - loss: 1.4151 - accuracy: 0.7778 - val_loss: 1.2842 - val_accuracy: 0.7446\n",
            "— val_f1: 0.7055083260297983\n",
            "Epoch 5/20\n",
            "91/91 [==============================] - 52s 567ms/step - loss: 1.1339 - accuracy: 0.8069 - val_loss: 1.0885 - val_accuracy: 0.7563\n",
            "— val_f1: 0.7529558614472452\n",
            "Epoch 6/20\n",
            "91/91 [==============================] - 52s 567ms/step - loss: 0.9516 - accuracy: 0.8178 - val_loss: 1.0130 - val_accuracy: 0.7632\n",
            "— val_f1: 0.7329644588823876\n",
            "Epoch 7/20\n",
            "91/91 [==============================] - 52s 568ms/step - loss: 0.8477 - accuracy: 0.8380 - val_loss: 1.2520 - val_accuracy: 0.5955\n",
            "— val_f1: 0.5822258329433165\n",
            "Epoch 8/20\n",
            "91/91 [==============================] - 52s 568ms/step - loss: 0.8168 - accuracy: 0.8074 - val_loss: 0.8648 - val_accuracy: 0.7612\n",
            "— val_f1: 0.7550255480178967\n",
            "Epoch 9/20\n",
            "91/91 [==============================] - 52s 567ms/step - loss: 0.7118 - accuracy: 0.8606 - val_loss: 0.8701 - val_accuracy: 0.7554\n",
            "— val_f1: 0.7532450982176992\n",
            "Epoch 10/20\n",
            "91/91 [==============================] - 52s 567ms/step - loss: 0.6636 - accuracy: 0.8674 - val_loss: 0.8304 - val_accuracy: 0.7651\n",
            "— val_f1: 0.76262106982089\n",
            "Epoch 11/20\n",
            "91/91 [==============================] - 51s 566ms/step - loss: 0.6502 - accuracy: 0.8724 - val_loss: 0.8223 - val_accuracy: 0.7661\n",
            "— val_f1: 0.7472584770639943\n",
            "Epoch 12/20\n",
            "91/91 [==============================] - 51s 565ms/step - loss: 0.5947 - accuracy: 0.8920 - val_loss: 0.7910 - val_accuracy: 0.7632\n",
            "— val_f1: 0.7594725564783844\n",
            "Epoch 13/20\n",
            "91/91 [==============================] - 51s 566ms/step - loss: 0.5699 - accuracy: 0.9039 - val_loss: 0.8639 - val_accuracy: 0.7339\n",
            "— val_f1: 0.7329110990963157\n",
            "Epoch 14/20\n",
            "91/91 [==============================] - 51s 565ms/step - loss: 0.5694 - accuracy: 0.8930 - val_loss: 0.8292 - val_accuracy: 0.7778\n",
            "— val_f1: 0.7676704274590815\n",
            "Epoch 15/20\n",
            "91/91 [==============================] - 51s 566ms/step - loss: 0.5122 - accuracy: 0.9268 - val_loss: 0.8542 - val_accuracy: 0.7749\n",
            "— val_f1: 0.7602772217541398\n",
            "Epoch 16/20\n",
            "91/91 [==============================] - 52s 567ms/step - loss: 0.5215 - accuracy: 0.9125 - val_loss: 0.8674 - val_accuracy: 0.7788\n",
            "— val_f1: 0.7677823454280236\n",
            "Epoch 17/20\n",
            "91/91 [==============================] - 51s 565ms/step - loss: 0.4760 - accuracy: 0.9401 - val_loss: 0.9544 - val_accuracy: 0.7583\n",
            "— val_f1: 0.7329527088012427\n",
            "Epoch 18/20\n",
            "91/91 [==============================] - 51s 566ms/step - loss: 0.4590 - accuracy: 0.9430 - val_loss: 0.8519 - val_accuracy: 0.7827\n",
            "— val_f1: 0.7692794052842336\n",
            "Epoch 19/20\n",
            "91/91 [==============================] - 51s 565ms/step - loss: 0.4741 - accuracy: 0.9434 - val_loss: 0.9138 - val_accuracy: 0.7719\n",
            "— val_f1: 0.7560201294266853\n",
            "Epoch 20/20\n",
            "91/91 [==============================] - 51s 565ms/step - loss: 0.4717 - accuracy: 0.9402 - val_loss: 1.1783 - val_accuracy: 0.7368\n",
            "— val_f1: 0.683866726921655\n",
            "33/33 [==============================] - 4s 114ms/step - loss: 1.1783 - accuracy: 0.7368\n",
            "f1_score test tweets: 0.6835487257990128\n",
            "f1_score test news: 0.5358649789029536\n",
            "--- Starting trial: run-14\n",
            "{'num_filters': 1024, 'dropout': 0.0006000000000000001, 'optimizer': 'nadam', 'L2_reg': 0.0004}\n",
            "Epoch 1/20\n",
            "91/91 [==============================] - 54s 575ms/step - loss: 3.7742 - accuracy: 0.5683 - val_loss: 2.6396 - val_accuracy: 0.6287\n",
            "— val_f1: 0.455133914570658\n",
            "Epoch 2/20\n",
            "91/91 [==============================] - 52s 568ms/step - loss: 2.4201 - accuracy: 0.6850 - val_loss: 1.8781 - val_accuracy: 0.7534\n",
            "— val_f1: 0.7397586447855584\n",
            "Epoch 3/20\n",
            "91/91 [==============================] - 52s 569ms/step - loss: 1.7496 - accuracy: 0.7468 - val_loss: 1.4329 - val_accuracy: 0.7534\n",
            "— val_f1: 0.7488007509519962\n",
            "Epoch 4/20\n",
            "91/91 [==============================] - 52s 571ms/step - loss: 1.3212 - accuracy: 0.7763 - val_loss: 1.2430 - val_accuracy: 0.6940\n",
            "— val_f1: 0.69334069448675\n",
            "Epoch 5/20\n",
            "91/91 [==============================] - 52s 568ms/step - loss: 1.0621 - accuracy: 0.8055 - val_loss: 1.0823 - val_accuracy: 0.7300\n",
            "— val_f1: 0.6701871982007805\n",
            "Epoch 6/20\n",
            "91/91 [==============================] - 52s 569ms/step - loss: 0.9154 - accuracy: 0.8016 - val_loss: 1.0209 - val_accuracy: 0.7018\n",
            "— val_f1: 0.7014639823820046\n",
            "Epoch 7/20\n",
            "91/91 [==============================] - 52s 571ms/step - loss: 0.8380 - accuracy: 0.8152 - val_loss: 0.8598 - val_accuracy: 0.7788\n",
            "— val_f1: 0.7677823454280236\n",
            "Epoch 8/20\n",
            "91/91 [==============================] - 52s 567ms/step - loss: 0.7456 - accuracy: 0.8379 - val_loss: 0.8611 - val_accuracy: 0.7485\n",
            "— val_f1: 0.7478395061728396\n",
            "Epoch 9/20\n",
            "91/91 [==============================] - 52s 568ms/step - loss: 0.7014 - accuracy: 0.8391 - val_loss: 0.8583 - val_accuracy: 0.7359\n",
            "— val_f1: 0.7354852519371547\n",
            "Epoch 10/20\n",
            "91/91 [==============================] - 52s 567ms/step - loss: 0.6508 - accuracy: 0.8620 - val_loss: 0.8034 - val_accuracy: 0.7739\n",
            "— val_f1: 0.7651321398124468\n",
            "Epoch 11/20\n",
            "91/91 [==============================] - 52s 566ms/step - loss: 0.6337 - accuracy: 0.8640 - val_loss: 0.8826 - val_accuracy: 0.7544\n",
            "— val_f1: 0.7220397000137608\n",
            "Epoch 12/20\n",
            "91/91 [==============================] - 52s 567ms/step - loss: 0.6313 - accuracy: 0.8640 - val_loss: 0.8253 - val_accuracy: 0.7583\n",
            "— val_f1: 0.7315099715099715\n",
            "Epoch 13/20\n",
            "91/91 [==============================] - 52s 569ms/step - loss: 0.5679 - accuracy: 0.9013 - val_loss: 0.8280 - val_accuracy: 0.7758\n",
            "— val_f1: 0.7619182139931313\n",
            "Epoch 14/20\n",
            "91/91 [==============================] - 52s 567ms/step - loss: 0.5366 - accuracy: 0.9054 - val_loss: 1.0932 - val_accuracy: 0.6511\n",
            "— val_f1: 0.6471625687311962\n",
            "Epoch 15/20\n",
            "91/91 [==============================] - 51s 566ms/step - loss: 0.5412 - accuracy: 0.9046 - val_loss: 1.1630 - val_accuracy: 0.7203\n",
            "— val_f1: 0.6582805988578484\n",
            "Epoch 16/20\n",
            "91/91 [==============================] - 52s 567ms/step - loss: 0.5103 - accuracy: 0.9212 - val_loss: 0.8619 - val_accuracy: 0.7739\n",
            "— val_f1: 0.7600870827285922\n",
            "Epoch 17/20\n",
            "91/91 [==============================] - 51s 566ms/step - loss: 0.4649 - accuracy: 0.9473 - val_loss: 0.8854 - val_accuracy: 0.7768\n",
            "— val_f1: 0.7592553694001826\n",
            "Epoch 18/20\n",
            "91/91 [==============================] - 52s 569ms/step - loss: 0.4489 - accuracy: 0.9449 - val_loss: 0.8307 - val_accuracy: 0.7612\n",
            "— val_f1: 0.7583805527920757\n",
            "Epoch 19/20\n",
            "91/91 [==============================] - 52s 569ms/step - loss: 0.4392 - accuracy: 0.9520 - val_loss: 0.8785 - val_accuracy: 0.7729\n",
            "— val_f1: 0.762474278429849\n",
            "Epoch 20/20\n",
            "91/91 [==============================] - 51s 564ms/step - loss: 0.4304 - accuracy: 0.9501 - val_loss: 1.0397 - val_accuracy: 0.7495\n",
            "— val_f1: 0.7122993077036384\n",
            "33/33 [==============================] - 4s 116ms/step - loss: 1.0397 - accuracy: 0.7495\n",
            "f1_score test tweets: 0.7235761184913727\n",
            "f1_score test news: 0.5717872310471857\n",
            "--- Starting trial: run-15\n",
            "{'num_filters': 1024, 'dropout': 0.0006000000000000001, 'optimizer': 'nadam', 'L2_reg': 0.0006000000000000001}\n",
            "Epoch 1/20\n",
            "91/91 [==============================] - 60s 604ms/step - loss: 3.9233 - accuracy: 0.5737 - val_loss: 2.7436 - val_accuracy: 0.7125\n",
            "— val_f1: 0.6861789983483106\n",
            "Epoch 2/20\n",
            "91/91 [==============================] - 51s 564ms/step - loss: 2.5957 - accuracy: 0.6836 - val_loss: 2.1323 - val_accuracy: 0.6608\n",
            "— val_f1: 0.6599452175867547\n",
            "Epoch 3/20\n",
            "91/91 [==============================] - 51s 566ms/step - loss: 1.9260 - accuracy: 0.7355 - val_loss: 1.5767 - val_accuracy: 0.7651\n",
            "— val_f1: 0.754107799722948\n",
            "Epoch 4/20\n",
            "91/91 [==============================] - 52s 570ms/step - loss: 1.4601 - accuracy: 0.7750 - val_loss: 1.4224 - val_accuracy: 0.6579\n",
            "— val_f1: 0.6548093632790073\n",
            "Epoch 5/20\n",
            "91/91 [==============================] - 51s 565ms/step - loss: 1.1646 - accuracy: 0.8033 - val_loss: 1.3221 - val_accuracy: 0.6998\n",
            "— val_f1: 0.6120373416882332\n",
            "Epoch 6/20\n",
            "91/91 [==============================] - 52s 566ms/step - loss: 1.0031 - accuracy: 0.8099 - val_loss: 1.0063 - val_accuracy: 0.7485\n",
            "— val_f1: 0.7464997529237358\n",
            "Epoch 7/20\n",
            "91/91 [==============================] - 51s 563ms/step - loss: 0.8925 - accuracy: 0.8285 - val_loss: 0.9107 - val_accuracy: 0.7758\n",
            "— val_f1: 0.7687096432729967\n",
            "Epoch 8/20\n",
            "91/91 [==============================] - 51s 565ms/step - loss: 0.7933 - accuracy: 0.8422 - val_loss: 1.0558 - val_accuracy: 0.7290\n",
            "— val_f1: 0.6645071138211383\n",
            "Epoch 9/20\n",
            "91/91 [==============================] - 51s 566ms/step - loss: 0.7417 - accuracy: 0.8430 - val_loss: 0.8514 - val_accuracy: 0.7739\n",
            "— val_f1: 0.7598479375930716\n",
            "Epoch 10/20\n",
            "91/91 [==============================] - 52s 569ms/step - loss: 0.7020 - accuracy: 0.8612 - val_loss: 0.8780 - val_accuracy: 0.7719\n",
            "— val_f1: 0.7532923941994674\n",
            "Epoch 11/20\n",
            "91/91 [==============================] - 52s 567ms/step - loss: 0.6529 - accuracy: 0.8659 - val_loss: 0.8403 - val_accuracy: 0.7515\n",
            "— val_f1: 0.7481874171669135\n",
            "Epoch 12/20\n",
            "91/91 [==============================] - 54s 590ms/step - loss: 0.7152 - accuracy: 0.8602 - val_loss: 0.8266 - val_accuracy: 0.7885\n",
            "— val_f1: 0.7789730439677278\n",
            "Epoch 13/20\n",
            "91/91 [==============================] - 52s 569ms/step - loss: 0.5931 - accuracy: 0.8905 - val_loss: 0.8300 - val_accuracy: 0.7749\n",
            "— val_f1: 0.765491747398459\n",
            "Epoch 14/20\n",
            "91/91 [==============================] - 52s 568ms/step - loss: 0.5801 - accuracy: 0.8939 - val_loss: 0.8852 - val_accuracy: 0.7788\n",
            "— val_f1: 0.7596854992235504\n",
            "Epoch 15/20\n",
            "91/91 [==============================] - 51s 565ms/step - loss: 0.5385 - accuracy: 0.9096 - val_loss: 0.9212 - val_accuracy: 0.7203\n",
            "— val_f1: 0.7201067248640989\n",
            "Epoch 16/20\n",
            "91/91 [==============================] - 51s 565ms/step - loss: 0.5191 - accuracy: 0.9137 - val_loss: 0.8179 - val_accuracy: 0.7534\n",
            "— val_f1: 0.7490668963537181\n",
            "Epoch 17/20\n",
            "91/91 [==============================] - 53s 585ms/step - loss: 0.4849 - accuracy: 0.9391 - val_loss: 0.8701 - val_accuracy: 0.7739\n",
            "— val_f1: 0.7614718614718614\n",
            "Epoch 18/20\n",
            "91/91 [==============================] - 52s 567ms/step - loss: 0.4785 - accuracy: 0.9314 - val_loss: 0.9998 - val_accuracy: 0.7563\n",
            "— val_f1: 0.7315069525568074\n",
            "Epoch 19/20\n",
            "91/91 [==============================] - 52s 567ms/step - loss: 0.4475 - accuracy: 0.9502 - val_loss: 0.8516 - val_accuracy: 0.7641\n",
            "— val_f1: 0.7542247386759582\n",
            "Epoch 20/20\n",
            "91/91 [==============================] - 52s 568ms/step - loss: 0.4360 - accuracy: 0.9493 - val_loss: 0.9459 - val_accuracy: 0.7495\n",
            "— val_f1: 0.7462124165172421\n",
            "33/33 [==============================] - 4s 116ms/step - loss: 0.9459 - accuracy: 0.7495\n",
            "f1_score test tweets: 0.6802437516559217\n",
            "f1_score test news: 0.6839338590012309\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUvnMoP9EsnU"
      },
      "source": [
        "### Test phase"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZVkUrF2luNH"
      },
      "source": [
        "csv_test_tweets_file = open(input_test_dir+\"test_dataset_tweets.csv\")\n",
        "\n",
        "testset_tweets = pd.read_csv(csv_test_tweets_file,sep=',')\n",
        "\n",
        "csv_test_news_file = open(input_test_dir+\"test_dataset_news.csv\")\n",
        "\n",
        "testset_news = pd.read_csv(csv_test_news_file,sep=',')"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEA-Q8phFM71",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd076e86-4c57-4a88-ea8c-f42930baeae5"
      },
      "source": [
        "X_test_news = get_data_to_emb2(testset_news[\"tokens\"], w2v, max_length , True)\n",
        "X_test_tweets = get_data_to_emb2(testset_tweets[\"tokens\"], w2v, max_length , True)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "500\n",
            "[[ 0.4473033  -1.85372221  1.80903184 ... -0.81329495 -0.37441084\n",
            "   0.67255157]\n",
            " [ 0.65353721  2.91942644  0.83319777 ...  0.10994434  0.79807943\n",
            "  -0.64684689]\n",
            " [ 0.27626377  0.63812095  1.54855597 ... -0.60746866  1.20815647\n",
            "   0.78223377]\n",
            " ...\n",
            " [ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]\n",
            " [ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]\n",
            " [ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]]\n",
            "1263\n",
            "[[ 0.85021353  0.94971675  0.95175791 ...  0.66373271  0.95456082\n",
            "   0.80749106]\n",
            " [ 1.86031258  0.98840606 -2.10821915 ...  1.14880133  0.14479998\n",
            "  -0.10640591]\n",
            " [-1.32805312  0.75008422  0.24781393 ... -0.08247134 -0.89805609\n",
            "  -0.75278544]\n",
            " ...\n",
            " [ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]\n",
            " [ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]\n",
            " [ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RL4fJuI-7egi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "b3ebd666-470c-4f57-8946-566fb838eac9"
      },
      "source": [
        "testset_tweets_other = testset_tweets\n",
        "testset_tweets_other = testset_tweets.drop(['text', 'id', 'hs', 'stereotype','tokens', 'hashtags'], axis=1)\n",
        "testset_tweets_other"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text_length</th>\n",
              "      <th>#C-L words</th>\n",
              "      <th>#?!</th>\n",
              "      <th>#.,</th>\n",
              "      <th>#bad_words</th>\n",
              "      <th>%bad_words</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>180</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>227</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>259</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>99</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>257</td>\n",
              "      <td>87</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1258</th>\n",
              "      <td>216</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1259</th>\n",
              "      <td>159</td>\n",
              "      <td>81</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1260</th>\n",
              "      <td>278</td>\n",
              "      <td>32</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1261</th>\n",
              "      <td>128</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1262</th>\n",
              "      <td>284</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1263 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      text_length  #C-L words  #?!  #.,  #bad_words  %bad_words\n",
              "0             180           4    1    4           0           0\n",
              "1             227           5    4    5           0           0\n",
              "2             259           2    2    4           1           2\n",
              "3              99           7    0    2           0           0\n",
              "4             257          87    2    0           0           0\n",
              "...           ...         ...  ...  ...         ...         ...\n",
              "1258          216           0    0    5           0           0\n",
              "1259          159          81    3    1           1           3\n",
              "1260          278          32    4    7           1           2\n",
              "1261          128           0    1    3           0           0\n",
              "1262          284           2    2    9           0           0\n",
              "\n",
              "[1263 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIXr4PJLF36A",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "aa00b285-04d4-4f36-fc51-d39ade6e98dc"
      },
      "source": [
        "testset_news_other = testset_news\n",
        "testset_news_other = testset_news.drop(['text', 'id', 'hs', 'stereotype','tokens', 'hashtags'], axis=1)\n",
        "testset_news_other"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text_length</th>\n",
              "      <th>#C-L words</th>\n",
              "      <th>#?!</th>\n",
              "      <th>#.,</th>\n",
              "      <th>#bad_words</th>\n",
              "      <th>%bad_words</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>102</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>108</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>48</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>112</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>117</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>495</th>\n",
              "      <td>80</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>496</th>\n",
              "      <td>60</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>497</th>\n",
              "      <td>86</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498</th>\n",
              "      <td>92</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499</th>\n",
              "      <td>67</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>500 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     text_length  #C-L words  #?!  #.,  #bad_words  %bad_words\n",
              "0            102           0    1    5           0           0\n",
              "1            108           0    0    1           0           0\n",
              "2             48           0    0    0           0           0\n",
              "3            112           0    0    5           0           0\n",
              "4            117           0    0    6           0           0\n",
              "..           ...         ...  ...  ...         ...         ...\n",
              "495           80           0    0    2           0           0\n",
              "496           60           0    0    0           0           0\n",
              "497           86           0    0    2           0           0\n",
              "498           92           0    0    0           0           0\n",
              "499           67           0    0    1           0           0\n",
              "\n",
              "[500 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CR69UbzM7nN8"
      },
      "source": [
        "input_test_tweets   = {\"text\": X_test_tweets, \"other\": testset_tweets_other.values}\n",
        "y_test_tweets = testset_tweets[['hs']]\n"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vhoi6YkbGJyj"
      },
      "source": [
        "input_test_news   = {\"text\": X_test_news, \"other\": testset_news_other.values}\n",
        "y_test_news = testset_news[['hs']]\n"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imavSMMX17qH"
      },
      "source": [
        "x_kfold = X_dev\n",
        "x_other_kfold = dataset_other\n",
        "y_kfold = dataset[['hs']]"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUsrgeL_xUkK"
      },
      "source": [
        "def train_test_model_with_kfold(hparams):\n",
        "  number_of_splits = 5\n",
        "  cv_kfold = StratifiedKFold(n_splits=number_of_splits, shuffle=True, random_state=100)\n",
        "  models = []\n",
        "  for train_index, validation_index in cv_kfold.split(x_kfold, y_kfold):\n",
        "    model = get_model(hparams)\n",
        "    model.compile(\n",
        "        optimizer=hparams[HP_OPTIMIZER],\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy'],\n",
        "    )\n",
        "\n",
        "    input_train_kfold = {\"text\": x_kfold[train_index], \"other\": x_other_kfold.loc[train_index]}\n",
        "    input_val_kfold   = {\"text\": x_kfold[validation_index], \"other\": x_other_kfold.loc[validation_index]}\n",
        "    y_train_kfold = y_kfold.loc[train_index]\n",
        "    y_valid_kfold = y_kfold.loc[validation_index]\n",
        "\n",
        "    f1_callback = FCallback(validation = (input_val_kfold, y_valid_kfold), verbose=True)                                   \n",
        "\n",
        "    #filepath = input_dir + \"model_output/biLSTM/HP_NUM_UNITS={0}/HP_DROPOUT={1}/HP_L2={2}/\".format(hparams[HP_NUM_UNITS],hparams[HP_DROPOUT],hparams[HP_L2])\n",
        "    #filepath += \"saved-model-{epoch:02d}-{val_accuracy:.2f}.hdf5\"\n",
        "    #checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=False, mode='max')\n",
        "\n",
        "\n",
        "    model.fit(input_train_kfold, y_train_kfold, batch_size=batch_size, validation_data=(input_val_kfold, y_valid_kfold), epochs=20, callbacks=[f1_callback]) # Run with 1 epoch to speed things up for demo purposes\n",
        "    _, accuracy = model.evaluate(input_val_kfold, y_valid_kfold)\n",
        "\n",
        "    #y_test_pred = np.where(model.predict(input_test)[0] > 0.5, 1, 0)\n",
        "    #y_test_pred_tweets = np.where(model.predict(input_test_tweets) > 0.5, 1, 0)\n",
        "    #y_test_pred_news = np.where(model.predict(input_test_news) > 0.5, 1, 0)\n",
        "\n",
        "    #print(\"f1_score test tweets: {}\".format(f1_score(y_test_tweets, y_test_pred_tweets,average=\"macro\")))\n",
        "    #print(\"f1_score test news: {}\".format(f1_score(y_test_news, y_test_pred_news,average=\"macro\")))\n",
        "    models.append(model)\n",
        "\n",
        "  return models"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MnwToktaH-uQ"
      },
      "source": [
        "def predict_with_ensemble(models, test_input):\n",
        "  # make predictions\n",
        "  results = []\n",
        "  y_predict = [np.squeeze(np.where(model.predict(test_input) > 0.5, 1,0).reshape(1,-1)) for model in models]\n",
        "  # sum across ensemble members\n",
        "  y_predict = np.array(y_predict)\n",
        "\n",
        "  for i in range(y_predict.shape[1]):\n",
        "    counts = np.bincount(y_predict[:,i])\n",
        "    results.append(np.argmax(counts))\n",
        "  # argmax across classes\n",
        "  return results"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T24mBhARv8Hx"
      },
      "source": [
        "def run_with_kfold(run_dir, hparams):\n",
        "  with tf.summary.create_file_writer(run_dir).as_default():\n",
        "    hp.hparams(hparams)  # record the values used in this trial\n",
        "    models = train_test_model_with_kfold(hparams)\n",
        "    y_test_pred_tweets = predict_with_ensemble(models, input_test_tweets)\n",
        "    y_test_pred_news = predict_with_ensemble(models, input_test_news)\n",
        "\n",
        "    print(\"f1_score test tweets: {}\".format(f1_score(y_test_tweets, y_test_pred_tweets,average=\"macro\")))\n",
        "    print(\"f1_score test news: {}\".format(f1_score(y_test_news, y_test_pred_news,average=\"macro\")))\n",
        "    return models\n"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_Y4HvcNcxJs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "8d976bda-1e9e-41bc-ff2a-3f39cbc10a2f"
      },
      "source": [
        "y_test_pred_tweets = predict_with_ensemble(models, input_test_tweets)\n",
        "y_test_pred_news = predict_with_ensemble(models, input_test_news)\n",
        "\n",
        "print(\"f1_score test tweets: {}\".format(f1_score(y_test_tweets, y_test_pred_tweets,average=\"macro\")))\n",
        "print(\"f1_score test news: {}\".format(f1_score(y_test_news, y_test_pred_news,average=\"macro\")))\n"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-196b7f44acee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_test_pred_tweets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_with_ensemble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_test_tweets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my_test_pred_news\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_with_ensemble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_test_news\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"f1_score test tweets: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test_tweets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_pred_tweets\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"macro\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"f1_score test news: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test_news\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_pred_news\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"macro\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'models' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISaRu-AfD6Vz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a1ef5bd-7b79-43a3-9ace-5d37c264e920"
      },
      "source": [
        "hparams = {\n",
        "  HP_NUM_FILTERS: 1024,\n",
        "  HP_L2_CONVOLUTION: 0.0,\n",
        "  HP_OPTIMIZER: 'nadam',\n",
        "  HP_L2_DENSE: 0.0002,\n",
        "}\n",
        "run_name = \"run-test\" \n",
        "print('--- Starting trial: %s' % run_name)\n",
        "print({h.name: hparams[h] for h in hparams})\n",
        "models = run_with_kfold('logs/hparam_tuning/' + run_name, hparams)\n"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--- Starting trial: run-test\n",
            "{'num_filters': 1024, 'dropout': 0.0, 'optimizer': 'nadam', 'L2_reg': 0.0002}\n",
            "Epoch 1/20\n",
            "86/86 [==============================] - 51s 571ms/step - loss: 1.3422 - accuracy: 0.5671 - val_loss: 0.6870 - val_accuracy: 0.7032\n",
            "— val_f1: 0.676961410414791\n",
            "Epoch 2/20\n",
            "86/86 [==============================] - 49s 568ms/step - loss: 0.6986 - accuracy: 0.6984 - val_loss: 0.6912 - val_accuracy: 0.6966\n",
            "— val_f1: 0.6966100290981186\n",
            "Epoch 3/20\n",
            "86/86 [==============================] - 49s 571ms/step - loss: 0.6294 - accuracy: 0.7486 - val_loss: 0.7031 - val_accuracy: 0.6396\n",
            "— val_f1: 0.49448594032837756\n",
            "Epoch 4/20\n",
            "86/86 [==============================] - 49s 574ms/step - loss: 0.6152 - accuracy: 0.7422 - val_loss: 0.6220 - val_accuracy: 0.7463\n",
            "— val_f1: 0.7426004460473083\n",
            "Epoch 5/20\n",
            "86/86 [==============================] - 49s 569ms/step - loss: 0.5409 - accuracy: 0.8015 - val_loss: 0.5924 - val_accuracy: 0.7654\n",
            "— val_f1: 0.7537436596260125\n",
            "Epoch 6/20\n",
            "86/86 [==============================] - 49s 570ms/step - loss: 0.4451 - accuracy: 0.8477 - val_loss: 0.6695 - val_accuracy: 0.7639\n",
            "— val_f1: 0.7457920525785597\n",
            "Epoch 7/20\n",
            "86/86 [==============================] - 49s 569ms/step - loss: 0.3943 - accuracy: 0.8642 - val_loss: 0.6555 - val_accuracy: 0.7697\n",
            "— val_f1: 0.756670911128867\n",
            "Epoch 8/20\n",
            "86/86 [==============================] - 49s 570ms/step - loss: 0.4007 - accuracy: 0.8868 - val_loss: 0.6685 - val_accuracy: 0.7675\n",
            "— val_f1: 0.7573797115933752\n",
            "Epoch 9/20\n",
            "86/86 [==============================] - 49s 569ms/step - loss: 0.3297 - accuracy: 0.9123 - val_loss: 0.7015 - val_accuracy: 0.7434\n",
            "— val_f1: 0.7427280467085267\n",
            "Epoch 10/20\n",
            "86/86 [==============================] - 49s 574ms/step - loss: 0.2580 - accuracy: 0.9269 - val_loss: 2.3227 - val_accuracy: 0.6243\n",
            "— val_f1: 0.45002831389946535\n",
            "Epoch 11/20\n",
            "86/86 [==============================] - 49s 567ms/step - loss: 0.2523 - accuracy: 0.9422 - val_loss: 0.8806 - val_accuracy: 0.7610\n",
            "— val_f1: 0.7359576857989958\n",
            "Epoch 12/20\n",
            "86/86 [==============================] - 49s 569ms/step - loss: 0.1628 - accuracy: 0.9712 - val_loss: 0.9175 - val_accuracy: 0.7610\n",
            "— val_f1: 0.7516454317374149\n",
            "Epoch 13/20\n",
            "86/86 [==============================] - 49s 568ms/step - loss: 0.1713 - accuracy: 0.9737 - val_loss: 0.8133 - val_accuracy: 0.7595\n",
            "— val_f1: 0.7469229346170347\n",
            "Epoch 14/20\n",
            "86/86 [==============================] - 49s 569ms/step - loss: 0.1487 - accuracy: 0.9749 - val_loss: 1.1952 - val_accuracy: 0.6857\n",
            "— val_f1: 0.6841813648536337\n",
            "Epoch 15/20\n",
            "86/86 [==============================] - 49s 567ms/step - loss: 0.1378 - accuracy: 0.9748 - val_loss: 0.8895 - val_accuracy: 0.7551\n",
            "— val_f1: 0.7463018967570287\n",
            "Epoch 16/20\n",
            "86/86 [==============================] - 49s 570ms/step - loss: 0.1083 - accuracy: 0.9860 - val_loss: 1.4507 - val_accuracy: 0.7266\n",
            "— val_f1: 0.6844551456004104\n",
            "Epoch 17/20\n",
            "86/86 [==============================] - 49s 568ms/step - loss: 0.1301 - accuracy: 0.9742 - val_loss: 1.1146 - val_accuracy: 0.7471\n",
            "— val_f1: 0.725928533708854\n",
            "Epoch 18/20\n",
            "86/86 [==============================] - 49s 566ms/step - loss: 0.1092 - accuracy: 0.9825 - val_loss: 0.9296 - val_accuracy: 0.7617\n",
            "— val_f1: 0.755602904040404\n",
            "Epoch 19/20\n",
            "86/86 [==============================] - 49s 567ms/step - loss: 0.1103 - accuracy: 0.9831 - val_loss: 0.9295 - val_accuracy: 0.7405\n",
            "— val_f1: 0.7393436789339305\n",
            "Epoch 20/20\n",
            "86/86 [==============================] - 49s 567ms/step - loss: 0.0887 - accuracy: 0.9906 - val_loss: 1.9184 - val_accuracy: 0.6301\n",
            "— val_f1: 0.6215349690648599\n",
            "43/43 [==============================] - 5s 108ms/step - loss: 1.9184 - accuracy: 0.6301\n",
            "Epoch 1/20\n",
            "86/86 [==============================] - 51s 573ms/step - loss: 1.5370 - accuracy: 0.5664 - val_loss: 0.6952 - val_accuracy: 0.6762\n",
            "— val_f1: 0.6107003069949759\n",
            "Epoch 2/20\n",
            "86/86 [==============================] - 49s 572ms/step - loss: 0.6975 - accuracy: 0.6905 - val_loss: 0.6713 - val_accuracy: 0.7061\n",
            "— val_f1: 0.7059989607190285\n",
            "Epoch 3/20\n",
            "86/86 [==============================] - 49s 569ms/step - loss: 0.6277 - accuracy: 0.7533 - val_loss: 0.6133 - val_accuracy: 0.7361\n",
            "— val_f1: 0.7324046614933706\n",
            "Epoch 4/20\n",
            "86/86 [==============================] - 49s 568ms/step - loss: 0.5718 - accuracy: 0.7792 - val_loss: 0.7853 - val_accuracy: 0.6374\n",
            "— val_f1: 0.6304474750555531\n",
            "Epoch 5/20\n",
            "86/86 [==============================] - 49s 573ms/step - loss: 0.4989 - accuracy: 0.8197 - val_loss: 0.7450 - val_accuracy: 0.7047\n",
            "— val_f1: 0.6343368902439024\n",
            "Epoch 6/20\n",
            "86/86 [==============================] - 49s 574ms/step - loss: 0.4562 - accuracy: 0.8394 - val_loss: 0.6644 - val_accuracy: 0.6879\n",
            "— val_f1: 0.6869741358290976\n",
            "Epoch 7/20\n",
            "86/86 [==============================] - 49s 572ms/step - loss: 0.3789 - accuracy: 0.8830 - val_loss: 0.8389 - val_accuracy: 0.6893\n",
            "— val_f1: 0.6040046342491721\n",
            "Epoch 8/20\n",
            "86/86 [==============================] - 49s 573ms/step - loss: 0.3698 - accuracy: 0.8907 - val_loss: 0.6611 - val_accuracy: 0.7654\n",
            "— val_f1: 0.7458430833038641\n",
            "Epoch 9/20\n",
            "86/86 [==============================] - 49s 569ms/step - loss: 0.3085 - accuracy: 0.9187 - val_loss: 1.1767 - val_accuracy: 0.6842\n",
            "— val_f1: 0.5913933292770617\n",
            "Epoch 10/20\n",
            "86/86 [==============================] - 49s 570ms/step - loss: 0.2417 - accuracy: 0.9451 - val_loss: 0.9811 - val_accuracy: 0.7405\n",
            "— val_f1: 0.69879858069902\n",
            "Epoch 11/20\n",
            "86/86 [==============================] - 49s 568ms/step - loss: 0.2043 - accuracy: 0.9519 - val_loss: 0.7943 - val_accuracy: 0.7493\n",
            "— val_f1: 0.7443900238764114\n",
            "Epoch 12/20\n",
            "86/86 [==============================] - 49s 569ms/step - loss: 0.2311 - accuracy: 0.9490 - val_loss: 0.9036 - val_accuracy: 0.7602\n",
            "— val_f1: 0.7472551489192958\n",
            "Epoch 13/20\n",
            "86/86 [==============================] - 49s 568ms/step - loss: 0.2674 - accuracy: 0.9479 - val_loss: 1.1330 - val_accuracy: 0.6827\n",
            "— val_f1: 0.6817663353430015\n",
            "Epoch 14/20\n",
            "86/86 [==============================] - 49s 569ms/step - loss: 0.1426 - accuracy: 0.9787 - val_loss: 0.6647 - val_accuracy: 0.7734\n",
            "— val_f1: 0.7622614092996556\n",
            "Epoch 15/20\n",
            "86/86 [==============================] - 49s 568ms/step - loss: 0.1429 - accuracy: 0.9816 - val_loss: 0.9553 - val_accuracy: 0.7683\n",
            "— val_f1: 0.7536794213122715\n",
            "Epoch 16/20\n",
            "86/86 [==============================] - 49s 568ms/step - loss: 0.1143 - accuracy: 0.9853 - val_loss: 0.9787 - val_accuracy: 0.7500\n",
            "— val_f1: 0.7446507515473032\n",
            "Epoch 17/20\n",
            "86/86 [==============================] - 49s 572ms/step - loss: 0.1120 - accuracy: 0.9869 - val_loss: 0.9150 - val_accuracy: 0.7573\n",
            "— val_f1: 0.7519004490281982\n",
            "Epoch 18/20\n",
            "86/86 [==============================] - 49s 568ms/step - loss: 0.1529 - accuracy: 0.9735 - val_loss: 1.0985 - val_accuracy: 0.7610\n",
            "— val_f1: 0.7354292260641271\n",
            "Epoch 19/20\n",
            "86/86 [==============================] - 49s 570ms/step - loss: 0.0951 - accuracy: 0.9869 - val_loss: 1.0198 - val_accuracy: 0.7507\n",
            "— val_f1: 0.7470511587957698\n",
            "Epoch 20/20\n",
            "86/86 [==============================] - 49s 573ms/step - loss: 0.0966 - accuracy: 0.9898 - val_loss: 0.8886 - val_accuracy: 0.7529\n",
            "— val_f1: 0.7488610367010147\n",
            "43/43 [==============================] - 5s 110ms/step - loss: 0.8886 - accuracy: 0.7529\n",
            "Epoch 1/20\n",
            "86/86 [==============================] - 51s 575ms/step - loss: 1.9879 - accuracy: 0.5818 - val_loss: 0.7080 - val_accuracy: 0.6832\n",
            "— val_f1: 0.6365497986293657\n",
            "Epoch 2/20\n",
            "86/86 [==============================] - 49s 569ms/step - loss: 0.6948 - accuracy: 0.7036 - val_loss: 0.7437 - val_accuracy: 0.6576\n",
            "— val_f1: 0.5523427004030452\n",
            "Epoch 3/20\n",
            "86/86 [==============================] - 49s 569ms/step - loss: 0.6360 - accuracy: 0.7378 - val_loss: 0.6641 - val_accuracy: 0.7118\n",
            "— val_f1: 0.6744293727936554\n",
            "Epoch 4/20\n",
            "86/86 [==============================] - 49s 569ms/step - loss: 0.5977 - accuracy: 0.7652 - val_loss: 0.6272 - val_accuracy: 0.7330\n",
            "— val_f1: 0.729376669514163\n",
            "Epoch 5/20\n",
            "86/86 [==============================] - 49s 568ms/step - loss: 0.5450 - accuracy: 0.8013 - val_loss: 0.6219 - val_accuracy: 0.7396\n",
            "— val_f1: 0.722078307748538\n",
            "Epoch 6/20\n",
            "86/86 [==============================] - 49s 573ms/step - loss: 0.4359 - accuracy: 0.8553 - val_loss: 0.6798 - val_accuracy: 0.7381\n",
            "— val_f1: 0.7361800539083558\n",
            "Epoch 7/20\n",
            "86/86 [==============================] - 49s 569ms/step - loss: 0.4430 - accuracy: 0.8520 - val_loss: 0.9701 - val_accuracy: 0.6511\n",
            "— val_f1: 0.6451790894443257\n",
            "Epoch 8/20\n",
            "86/86 [==============================] - 49s 568ms/step - loss: 0.3827 - accuracy: 0.8825 - val_loss: 0.6937 - val_accuracy: 0.7454\n",
            "— val_f1: 0.7237421602787457\n",
            "Epoch 9/20\n",
            "86/86 [==============================] - 49s 568ms/step - loss: 0.2710 - accuracy: 0.9376 - val_loss: 0.7105 - val_accuracy: 0.7579\n",
            "— val_f1: 0.7402472971429194\n",
            "Epoch 10/20\n",
            "86/86 [==============================] - 49s 569ms/step - loss: 0.2285 - accuracy: 0.9467 - val_loss: 0.8845 - val_accuracy: 0.7184\n",
            "— val_f1: 0.7183318321235349\n",
            "Epoch 11/20\n",
            "86/86 [==============================] - 49s 569ms/step - loss: 0.2607 - accuracy: 0.9407 - val_loss: 0.8508 - val_accuracy: 0.7520\n",
            "— val_f1: 0.7354533388517034\n",
            "Epoch 12/20\n",
            "86/86 [==============================] - 49s 573ms/step - loss: 0.2470 - accuracy: 0.9466 - val_loss: 0.7803 - val_accuracy: 0.7476\n",
            "— val_f1: 0.7442924429325624\n",
            "Epoch 13/20\n",
            "86/86 [==============================] - 49s 570ms/step - loss: 0.1455 - accuracy: 0.9796 - val_loss: 0.8818 - val_accuracy: 0.7352\n",
            "— val_f1: 0.7337330130729927\n",
            "Epoch 14/20\n",
            "86/86 [==============================] - 50s 577ms/step - loss: 0.1632 - accuracy: 0.9778 - val_loss: 0.8931 - val_accuracy: 0.7579\n",
            "— val_f1: 0.7462876207297755\n",
            "Epoch 15/20\n",
            "86/86 [==============================] - 49s 571ms/step - loss: 0.1559 - accuracy: 0.9748 - val_loss: 0.9115 - val_accuracy: 0.7454\n",
            "— val_f1: 0.7319064042740244\n",
            "Epoch 16/20\n",
            "86/86 [==============================] - 49s 572ms/step - loss: 0.1250 - accuracy: 0.9793 - val_loss: 0.9133 - val_accuracy: 0.7520\n",
            "— val_f1: 0.7420991560300858\n",
            "Epoch 17/20\n",
            "86/86 [==============================] - 49s 570ms/step - loss: 0.1305 - accuracy: 0.9770 - val_loss: 1.1944 - val_accuracy: 0.7440\n",
            "— val_f1: 0.7219064159436059\n",
            "Epoch 18/20\n",
            "86/86 [==============================] - 49s 572ms/step - loss: 0.2479 - accuracy: 0.9462 - val_loss: 0.9371 - val_accuracy: 0.7484\n",
            "— val_f1: 0.7445415036940459\n",
            "Epoch 19/20\n",
            "86/86 [==============================] - 49s 573ms/step - loss: 0.0997 - accuracy: 0.9890 - val_loss: 1.0842 - val_accuracy: 0.7491\n",
            "— val_f1: 0.7321220348124065\n",
            "Epoch 20/20\n",
            "86/86 [==============================] - 49s 574ms/step - loss: 0.1378 - accuracy: 0.9790 - val_loss: 0.9726 - val_accuracy: 0.7484\n",
            "— val_f1: 0.7430170284390234\n",
            "43/43 [==============================] - 5s 111ms/step - loss: 0.9726 - accuracy: 0.7484\n",
            "Epoch 1/20\n",
            "86/86 [==============================] - 51s 578ms/step - loss: 1.9289 - accuracy: 0.5719 - val_loss: 0.7495 - val_accuracy: 0.6562\n",
            "— val_f1: 0.6533751267830552\n",
            "Epoch 2/20\n",
            "86/86 [==============================] - 49s 574ms/step - loss: 0.6906 - accuracy: 0.6921 - val_loss: 0.7142 - val_accuracy: 0.6525\n",
            "— val_f1: 0.5309270642423857\n",
            "Epoch 3/20\n",
            "86/86 [==============================] - 50s 585ms/step - loss: 0.6225 - accuracy: 0.7410 - val_loss: 0.6315 - val_accuracy: 0.7388\n",
            "— val_f1: 0.7116219510970053\n",
            "Epoch 4/20\n",
            "86/86 [==============================] - 50s 578ms/step - loss: 0.5968 - accuracy: 0.7533 - val_loss: 0.5944 - val_accuracy: 0.7615\n",
            "— val_f1: 0.7448937768191206\n",
            "Epoch 5/20\n",
            "86/86 [==============================] - 50s 578ms/step - loss: 0.5139 - accuracy: 0.8068 - val_loss: 1.1400 - val_accuracy: 0.5545\n",
            "— val_f1: 0.5254892572864923\n",
            "Epoch 6/20\n",
            "86/86 [==============================] - 50s 579ms/step - loss: 0.4798 - accuracy: 0.8173 - val_loss: 0.5840 - val_accuracy: 0.7608\n",
            "— val_f1: 0.7559761440093895\n",
            "Epoch 7/20\n",
            "86/86 [==============================] - 49s 574ms/step - loss: 0.3930 - accuracy: 0.8788 - val_loss: 0.7635 - val_accuracy: 0.7067\n",
            "— val_f1: 0.6360801574735193\n",
            "Epoch 8/20\n",
            "86/86 [==============================] - 49s 575ms/step - loss: 0.3427 - accuracy: 0.9059 - val_loss: 0.5915 - val_accuracy: 0.7688\n",
            "— val_f1: 0.7621624359668944\n",
            "Epoch 9/20\n",
            "86/86 [==============================] - 50s 579ms/step - loss: 0.2774 - accuracy: 0.9327 - val_loss: 0.6056 - val_accuracy: 0.7674\n",
            "— val_f1: 0.7648000259706531\n",
            "Epoch 10/20\n",
            "86/86 [==============================] - 49s 574ms/step - loss: 0.2433 - accuracy: 0.9437 - val_loss: 0.7625 - val_accuracy: 0.7674\n",
            "— val_f1: 0.7473321150573333\n",
            "Epoch 11/20\n",
            "86/86 [==============================] - 49s 576ms/step - loss: 0.2363 - accuracy: 0.9436 - val_loss: 0.7671 - val_accuracy: 0.7630\n",
            "— val_f1: 0.7485991281445827\n",
            "Epoch 12/20\n",
            "86/86 [==============================] - 49s 572ms/step - loss: 0.2342 - accuracy: 0.9510 - val_loss: 0.7753 - val_accuracy: 0.7513\n",
            "— val_f1: 0.7507165598263094\n",
            "Epoch 13/20\n",
            "86/86 [==============================] - 49s 576ms/step - loss: 0.1678 - accuracy: 0.9718 - val_loss: 0.7612 - val_accuracy: 0.7571\n",
            "— val_f1: 0.7359714239173434\n",
            "Epoch 14/20\n",
            "86/86 [==============================] - 49s 575ms/step - loss: 0.1228 - accuracy: 0.9858 - val_loss: 1.9868 - val_accuracy: 0.5691\n",
            "— val_f1: 0.5444789866284975\n",
            "Epoch 15/20\n",
            "86/86 [==============================] - 49s 573ms/step - loss: 0.3153 - accuracy: 0.9329 - val_loss: 1.1794 - val_accuracy: 0.7293\n",
            "— val_f1: 0.6829220893201935\n",
            "Epoch 16/20\n",
            "86/86 [==============================] - 49s 572ms/step - loss: 0.1776 - accuracy: 0.9635 - val_loss: 0.7511 - val_accuracy: 0.7783\n",
            "— val_f1: 0.769759526579592\n",
            "Epoch 17/20\n",
            "86/86 [==============================] - 49s 576ms/step - loss: 0.1027 - accuracy: 0.9906 - val_loss: 0.8825 - val_accuracy: 0.7762\n",
            "— val_f1: 0.765218357670133\n",
            "Epoch 18/20\n",
            "86/86 [==============================] - 49s 573ms/step - loss: 0.0939 - accuracy: 0.9904 - val_loss: 0.9499 - val_accuracy: 0.7608\n",
            "— val_f1: 0.746176974115683\n",
            "Epoch 19/20\n",
            "86/86 [==============================] - 50s 583ms/step - loss: 0.0961 - accuracy: 0.9867 - val_loss: 0.9423 - val_accuracy: 0.7630\n",
            "— val_f1: 0.7447898659954917\n",
            "Epoch 20/20\n",
            "86/86 [==============================] - 49s 575ms/step - loss: 0.0957 - accuracy: 0.9876 - val_loss: 1.6552 - val_accuracy: 0.6672\n",
            "— val_f1: 0.6630978735113253\n",
            "43/43 [==============================] - 5s 111ms/step - loss: 1.6552 - accuracy: 0.6672\n",
            "Epoch 1/20\n",
            "86/86 [==============================] - 52s 584ms/step - loss: 2.4506 - accuracy: 0.5582 - val_loss: 0.7099 - val_accuracy: 0.6489\n",
            "— val_f1: 0.5408643081056874\n",
            "Epoch 2/20\n",
            "86/86 [==============================] - 49s 574ms/step - loss: 0.7238 - accuracy: 0.6706 - val_loss: 0.6840 - val_accuracy: 0.7045\n",
            "— val_f1: 0.7042456568772357\n",
            "Epoch 3/20\n",
            "86/86 [==============================] - 50s 578ms/step - loss: 0.6549 - accuracy: 0.7289 - val_loss: 0.6353 - val_accuracy: 0.7198\n",
            "— val_f1: 0.6680206380235991\n",
            "Epoch 4/20\n",
            "86/86 [==============================] - 49s 574ms/step - loss: 0.5838 - accuracy: 0.7712 - val_loss: 0.5829 - val_accuracy: 0.7740\n",
            "— val_f1: 0.7719581818329054\n",
            "Epoch 5/20\n",
            "86/86 [==============================] - 49s 573ms/step - loss: 0.6080 - accuracy: 0.7748 - val_loss: 0.5662 - val_accuracy: 0.7740\n",
            "— val_f1: 0.7601488837973885\n",
            "Epoch 6/20\n",
            "86/86 [==============================] - 49s 570ms/step - loss: 0.4741 - accuracy: 0.8458 - val_loss: 1.4238 - val_accuracy: 0.4909\n",
            "— val_f1: 0.43349068512334893\n",
            "Epoch 7/20\n",
            "86/86 [==============================] - 49s 575ms/step - loss: 0.4627 - accuracy: 0.8489 - val_loss: 0.6059 - val_accuracy: 0.7586\n",
            "— val_f1: 0.7581138121404765\n",
            "Epoch 8/20\n",
            "86/86 [==============================] - 49s 575ms/step - loss: 0.3711 - accuracy: 0.8916 - val_loss: 0.6037 - val_accuracy: 0.7710\n",
            "— val_f1: 0.7680102453272233\n",
            "Epoch 9/20\n",
            "86/86 [==============================] - 49s 571ms/step - loss: 0.3108 - accuracy: 0.9220 - val_loss: 0.6473 - val_accuracy: 0.7762\n",
            "— val_f1: 0.7614838450695873\n",
            "Epoch 10/20\n",
            "86/86 [==============================] - 49s 572ms/step - loss: 0.3409 - accuracy: 0.9146 - val_loss: 0.6471 - val_accuracy: 0.7754\n",
            "— val_f1: 0.7598577465473783\n",
            "Epoch 11/20\n",
            "86/86 [==============================] - 49s 572ms/step - loss: 0.2222 - accuracy: 0.9535 - val_loss: 1.2077 - val_accuracy: 0.6920\n",
            "— val_f1: 0.6166999566419995\n",
            "Epoch 12/20\n",
            "86/86 [==============================] - 49s 570ms/step - loss: 0.2487 - accuracy: 0.9425 - val_loss: 0.8436 - val_accuracy: 0.7659\n",
            "— val_f1: 0.7624498768371253\n",
            "Epoch 13/20\n",
            "86/86 [==============================] - 50s 580ms/step - loss: 0.1878 - accuracy: 0.9691 - val_loss: 0.6988 - val_accuracy: 0.7644\n",
            "— val_f1: 0.7609651885673572\n",
            "Epoch 14/20\n",
            "86/86 [==============================] - 49s 572ms/step - loss: 0.2329 - accuracy: 0.9572 - val_loss: 0.7239 - val_accuracy: 0.7710\n",
            "— val_f1: 0.7664236485472138\n",
            "Epoch 15/20\n",
            "86/86 [==============================] - 49s 572ms/step - loss: 0.1617 - accuracy: 0.9737 - val_loss: 0.7228 - val_accuracy: 0.7703\n",
            "— val_f1: 0.7620188682592767\n",
            "Epoch 16/20\n",
            "86/86 [==============================] - 49s 571ms/step - loss: 0.1141 - accuracy: 0.9912 - val_loss: 0.9824 - val_accuracy: 0.7688\n",
            "— val_f1: 0.7584859666778486\n",
            "Epoch 17/20\n",
            "86/86 [==============================] - 49s 571ms/step - loss: 0.2699 - accuracy: 0.9490 - val_loss: 1.1038 - val_accuracy: 0.7469\n",
            "— val_f1: 0.7198080167576585\n",
            "Epoch 18/20\n",
            "86/86 [==============================] - 49s 573ms/step - loss: 0.1242 - accuracy: 0.9797 - val_loss: 0.9808 - val_accuracy: 0.7769\n",
            "— val_f1: 0.7708399174455385\n",
            "Epoch 19/20\n",
            "86/86 [==============================] - 50s 584ms/step - loss: 0.1060 - accuracy: 0.9878 - val_loss: 0.9645 - val_accuracy: 0.7696\n",
            "— val_f1: 0.7611933097191419\n",
            "Epoch 20/20\n",
            "86/86 [==============================] - 49s 576ms/step - loss: 0.1002 - accuracy: 0.9902 - val_loss: 0.7605 - val_accuracy: 0.7703\n",
            "— val_f1: 0.7653267639391872\n",
            "43/43 [==============================] - 5s 109ms/step - loss: 0.7605 - accuracy: 0.7703\n",
            "f1_score test tweets: 0.6779313694834324\n",
            "f1_score test news: 0.6832140727489564\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_C5IjGnydPvu"
      },
      "source": [
        "for i in range(len(models)):\n",
        "  models[i].save(input_dir+\"model_output/kimCNN/{0}_{1}_{2}_{3}/model_{4}.h5\".format(hparams[HP_NUM_FILTERS],hparams[HP_L2_CONVOLUTION],hparams[HP_OPTIMIZER],hparams[HP_L2_DENSE],i))"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYp53DG5lKjj"
      },
      "source": [
        "f1_score test tweets: 0.7603277015648642\n",
        "f1_score test news: 0.6831647909673162"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}