{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM_grid.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GiovanniSorice/Hate_Speech_Detection/blob/main/LSTM_grid.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h0mBfEzg_53t"
      },
      "source": [
        "#Bidirectional LSTM Hate Speech Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OymXBcAV-Uk_"
      },
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Embedding, SpatialDropout1D, LSTM\n",
        "from tensorflow.keras.layers import Bidirectional # new! \n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "import os\n",
        "from sklearn.metrics import roc_auc_score \n",
        "import matplotlib.pyplot as plt\n",
        "from keras.preprocessing.text import one_hot\n",
        "from tensorboard.plugins.hparams import api as hp\n",
        "import numpy as np\n",
        "from sklearn.metrics import f1_score\n",
        "import ast \n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FwrQH01T_nIS",
        "outputId": "f00113bf-cabd-4297-9be9-4fb43a7a68f2"
      },
      "source": [
        "from google.colab import drive\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ewn7ge0AB8n"
      },
      "source": [
        "# directory name \n",
        "input_dir = '/content/drive/My Drive/HLT/clean_dataset_training/' \n",
        "input_test_dir = \"/content/drive/My Drive/HLT/dataset_test_evalita_preprocessed/\"\n",
        "# Spec\n",
        "pd.set_option(\"display.max_colwidth\", None)"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJL3UvhtALOr"
      },
      "source": [
        "tsv_file = open(input_dir+\"training_dataset.csv\")\n",
        "\n",
        "dataset = pd.read_csv(tsv_file,sep=',')"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "niRStx_sEI14"
      },
      "source": [
        "### Vector-space embedding: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rA44wzytEILB"
      },
      "source": [
        "p_train=0.85 # percentage of training set \n",
        "\n",
        "n_dim = 64 \n",
        "n_unique_words = 25000 \n",
        "max_length = 64 # doubled!\n",
        "pad_type = trunc_type = 'pre'\n",
        "\n",
        "# training \n",
        "batch_size = 64"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cP42BiElvcKH"
      },
      "source": [
        "#### Preprocess data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KU0jvqjPHTsM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6129b079-af80-44c5-8731-3109b2ad76e3"
      },
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "all_words = []\n",
        "for index, row in dataset.iterrows():\n",
        "  tokenize_word = word_tokenize(row[\"text\"])\n",
        "  for word in tokenize_word:\n",
        "      all_words.append(word)"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iaqpZHjMG6Dn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6378bfb-8e39-4af4-f422-4d2118e7076a"
      },
      "source": [
        "unique_words = set(all_words)\n",
        "print(len(unique_words))"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "24773\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fAjg3KCQEHl3"
      },
      "source": [
        "def sentence_to_emb2(sentence, w2v, truncate = None, padding = False):\n",
        "  pad_token = [0]*128\n",
        "  s_emb = [ w2v[word] for word in sentence if word in w2v.vocab]\n",
        "  if truncate is not None:\n",
        "    s_emb = s_emb[:truncate] #truncate\n",
        "  if padding:\n",
        "    s_emb += [pad_token] * (truncate - len(s_emb))\n",
        "  return np.array(s_emb)\n",
        "\n",
        "def get_data_to_emb2(data, w2v, truncate = None, padding = False):\n",
        "  X = [sentence_to_emb2(ast.literal_eval(sentence), w2v, truncate, padding) for sentence in data]\n",
        "  print(len(X))\n",
        "  print(X[0])\n",
        "  return np.array(X)"
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dd6KYgWqEKXs"
      },
      "source": [
        "from gensim.models import KeyedVectors\n",
        "from gensim.test.utils import datapath\n",
        "w2v_felice_path = \"/content/drive/My Drive/HLT/w2v/twitter128.bin\"\n",
        "w2v = KeyedVectors.load_word2vec_format(datapath(w2v_felice_path), binary=True)"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V97RhoGzTonm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77dd888f-3eff-4d41-bfb6-0f736af50d0a"
      },
      "source": [
        "X_dev = get_data_to_emb2(dataset[\"tokens\"], w2v, max_length , True)"
      ],
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6837\n",
            "[[ 0.97042489  0.79645807  0.10190873 ...  1.01973236  1.16674519\n",
            "   0.17082037]\n",
            " [-2.10587931  1.7696439  -1.04741096 ... -1.11571276 -0.25399542\n",
            "  -0.97522277]\n",
            " [ 0.89639139  1.24942708  0.72824973 ...  0.68920714  0.98506999\n",
            "  -0.36202168]\n",
            " ...\n",
            " [ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]\n",
            " [ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]\n",
            " [ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMnXywTcqSy1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "a74b2adc-b74b-47df-9c66-975234298c3c"
      },
      "source": [
        "dataset_other = dataset\n",
        "dataset_other = dataset.drop(['text', 'id', 'hs', 'stereotype','tokens', 'hashtags'], axis=1)\n",
        "dataset_other"
      ],
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text_length</th>\n",
              "      <th>#C-L words</th>\n",
              "      <th>#?!</th>\n",
              "      <th>#.,</th>\n",
              "      <th>#bad_words</th>\n",
              "      <th>%bad_words</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>120</td>\n",
              "      <td>10</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>101</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>86</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>118</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>138</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6832</th>\n",
              "      <td>285</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6833</th>\n",
              "      <td>277</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6834</th>\n",
              "      <td>233</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6835</th>\n",
              "      <td>206</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6836</th>\n",
              "      <td>285</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6837 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      text_length  #C-L words  #?!  #.,  #bad_words  %bad_words\n",
              "0             120          10    0    5           0           0\n",
              "1             101           0    0    0           1           6\n",
              "2              86           8    0    1           3          25\n",
              "3             118           0    0    2           0           0\n",
              "4             138           0    1    1           1           4\n",
              "...           ...         ...  ...  ...         ...         ...\n",
              "6832          285           2    0    4           0           0\n",
              "6833          277           0    2    3           0           0\n",
              "6834          233           0    0    4           0           0\n",
              "6835          206           2    0    2           0           0\n",
              "6836          285           7    1    5           0           0\n",
              "\n",
              "[6837 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7TX3TS1yTlR"
      },
      "source": [
        "x_train, x_valid, x_train_extra, x_valid_extra, y_train, y_valid = train_test_split(X_dev, dataset_other.values , dataset[['hs']], test_size=0.15, random_state=128)"
      ],
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRF1dwdVpKSo"
      },
      "source": [
        "input_train = {\"text\": x_train, \"other\": x_train_extra}\n",
        "input_val   = {\"text\": x_valid, \"other\": x_valid_extra}"
      ],
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXitI_XKIZN7"
      },
      "source": [
        "max_sent = 0 "
      ],
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCxWTGMOHVzc"
      },
      "source": [
        "\n",
        "def comment_length(text):\n",
        "    global max_sent \n",
        "    text = ast.literal_eval(text)\n",
        "    if len(text)>max_sent: \n",
        "      max_sent = len(text)"
      ],
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vmnRA9uGIKjJ",
        "outputId": "f3b48238-7149-4323-dea7-51db98aee0ac"
      },
      "source": [
        "dataset['tokens'].apply(comment_length)\n",
        "print(max_sent)"
      ],
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "119\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oVbNT3FOisHf",
        "outputId": "6e30e5eb-a38d-40bb-e2b6-166c59970f99"
      },
      "source": [
        "x_train_extra.shape"
      ],
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5811, 6)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 164
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uAUJfLg_BGTX"
      },
      "source": [
        "### Design grid search parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PC8zF9NNBJso",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6aab5b9a-6afe-4e29-a494-4dd9f3ba95d4"
      },
      "source": [
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard\n",
        "\n",
        "# Clear any logs from previous runs\n",
        "!rm -rf ./logs/\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorboard.plugins.hparams import api as hp"
      ],
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JJ6QHGwBXVJ"
      },
      "source": [
        "HP_NUM_UNITS = hp.HParam('num_units', hp.Discrete([64, 128, 256, 512]))\n",
        "HP_DROPOUT = hp.HParam('dropout', hp.RealInterval(0.0, 0.7))\n",
        "HP_OPTIMIZER = hp.HParam('optimizer', hp.Discrete(['nadam']))\n",
        "\n",
        "METRIC_ACCURACY = 'accuracy'\n",
        "\n",
        "with tf.summary.create_file_writer('logs/hparam_tuning').as_default():\n",
        "  hp.hparams_config(\n",
        "    hparams=[HP_NUM_UNITS, HP_DROPOUT, HP_OPTIMIZER],\n",
        "    metrics=[hp.Metric(METRIC_ACCURACY, display_name='Accuracy')],\n",
        "  )"
      ],
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LXFVlKlA7CUr"
      },
      "source": [
        "class FCallback(tf.keras.callbacks.Callback):\n",
        "  \n",
        "    def __init__(self, validation = (), verbose = 0):\n",
        "        self.validation = validation\n",
        "        self.verbose = verbose\n",
        "\n",
        "    def on_train_begin(self, logs={}):\n",
        "        self.f1 = []\n",
        "        self.val_f1 = []\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        y_t =  self.validation[1]\n",
        "        y_p =  np.where(self.model.predict(self.validation[0]) > 0.5, 1, 0)\n",
        "        logs['val_f1'] =  f1_score(y_t, y_p, average='macro')\n",
        "        if self.verbose >0:\n",
        "          print(\"— val_f1: {}\".format(logs['val_f1']))"
      ],
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4nNvvQRCcFP"
      },
      "source": [
        "def train_test_model(hparams):\n",
        "  lstml1_in = tf.keras.layers.Input(name=\"text\", shape =(max_length,128,))\n",
        "  lstml1_bd1 = tf.keras.layers.Bidirectional(LSTM(hparams[HP_NUM_UNITS], dropout = hparams[HP_DROPOUT]))(lstml1_in)\n",
        "  #lstml1_bd2 = tf.keras.layers.Bidirectional(LSTM(hparams[HP_NUM_UNITS], dropout = hparams[HP_DROPOUT]))(lstml1_bd1)\n",
        "  \n",
        "  other_in = tf.keras.layers.Input(name=\"other\", shape =(6,))\n",
        "\n",
        "  lconcat = tf.keras.layers.Concatenate(axis=1)([lstml1_bd1, other_in])\n",
        "  dense1_layer = Dense(256, activation=\"relu\", kernel_regularizer=tf.keras.regularizers.l2(0.007))(lconcat)\n",
        "  dense2_layer = Dense(64, activation=\"relu\", kernel_regularizer=tf.keras.regularizers.l2(0.007))(dense1_layer)\n",
        "\n",
        "  lstml1_out = tf.keras.layers.Dense(1, activation='sigmoid')(dense2_layer)\n",
        "\n",
        "\n",
        "  model = tf.keras.Model(inputs = [lstml1_in, other_in], outputs = lstml1_out)\n",
        "  \n",
        "  model.summary()\n",
        "  \n",
        "  model.compile(\n",
        "      optimizer=hparams[HP_OPTIMIZER],\n",
        "      loss='binary_crossentropy',\n",
        "      metrics=['accuracy'],\n",
        "  )\n",
        "  \n",
        "  f1_callback = FCallback(validation = (input_val, y_valid), verbose=True)                                   \n",
        "\n",
        "  model.fit(input_train, y_train, batch_size=batch_size, validation_data=(input_val, y_valid), epochs=10, callbacks=[f1_callback]) # Run with 1 epoch to speed things up for demo purposes\n",
        "  _, accuracy = model.evaluate(input_val, y_valid)\n",
        "\n",
        "  #y_test_pred = np.where(model.predict(input_test)[0] > 0.5, 1, 0)\n",
        "  y_test_pred = np.where(model.predict(input_test) > 0.5, 1, 0)\n",
        "\n",
        "  print(y_test_pred)\n",
        "  print(len(y_test_pred))\n",
        "\n",
        "  print(\"f1_score test: {}\".format(f1_score(y_test, y_test_pred,average=\"macro\")))\n",
        "  return accuracy"
      ],
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OaO2zq3-Adck"
      },
      "source": [
        "def run(run_dir, hparams):\n",
        "  with tf.summary.create_file_writer(run_dir).as_default():\n",
        "    hp.hparams(hparams)  # record the values used in this trial\n",
        "    accuracy = train_test_model(hparams)\n",
        "    tf.summary.scalar(METRIC_ACCURACY, accuracy, step=1)"
      ],
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9CaPr2dcL4tD",
        "outputId": "563f6eb6-9cb9-4500-c278-a00c36b7f554"
      },
      "source": [
        "session_num = 0\n",
        "\n",
        "for num_units in HP_NUM_UNITS.domain.values:\n",
        "  for dropout_rate in (HP_DROPOUT.domain.min_value, HP_DROPOUT.domain.max_value):\n",
        "    for optimizer in HP_OPTIMIZER.domain.values:\n",
        "      hparams = {\n",
        "          HP_NUM_UNITS: num_units,\n",
        "          HP_DROPOUT: dropout_rate,\n",
        "          HP_OPTIMIZER: optimizer,\n",
        "      }\n",
        "      run_name = \"run-%d\" % session_num\n",
        "      print('--- Starting trial: %s' % run_name)\n",
        "      print({h.name: hparams[h] for h in hparams})\n",
        "      run('logs/hparam_tuning/' + run_name, hparams)\n",
        "      session_num += 1\n"
      ],
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--- Starting trial: run-0\n",
            "{'num_units': 64, 'dropout': 0.0, 'optimizer': 'nadam'}\n",
            "Model: \"model_34\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "text (InputLayer)               [(None, 64, 128)]    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_34 (Bidirectional (None, 128)          98816       text[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "other (InputLayer)              [(None, 6)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_34 (Concatenate)    (None, 134)          0           bidirectional_34[0][0]           \n",
            "                                                                 other[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_102 (Dense)               (None, 256)          34560       concatenate_34[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dense_103 (Dense)               (None, 64)           16448       dense_102[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_104 (Dense)               (None, 1)            65          dense_103[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 149,889\n",
            "Trainable params: 149,889\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/10\n",
            "91/91 [==============================] - 4s 19ms/step - loss: 2.3501 - accuracy: 0.5537 - val_loss: 1.1664 - val_accuracy: 0.6365\n",
            "— val_f1: 0.478222812430551\n",
            "Epoch 2/10\n",
            "91/91 [==============================] - 1s 11ms/step - loss: 1.0332 - accuracy: 0.6999 - val_loss: 0.8235 - val_accuracy: 0.7183\n",
            "— val_f1: 0.7162835958423397\n",
            "Epoch 3/10\n",
            "91/91 [==============================] - 1s 11ms/step - loss: 0.8503 - accuracy: 0.7145 - val_loss: 1.2015 - val_accuracy: 0.6296\n",
            "— val_f1: 0.4539128680919725\n",
            "Epoch 4/10\n",
            "91/91 [==============================] - 1s 11ms/step - loss: 0.7590 - accuracy: 0.7431 - val_loss: 0.8669 - val_accuracy: 0.6969\n",
            "— val_f1: 0.6967540520891247\n",
            "Epoch 5/10\n",
            "91/91 [==============================] - 1s 11ms/step - loss: 0.7050 - accuracy: 0.7595 - val_loss: 0.7588 - val_accuracy: 0.7222\n",
            "— val_f1: 0.7196116504854368\n",
            "Epoch 6/10\n",
            "91/91 [==============================] - 1s 11ms/step - loss: 0.6413 - accuracy: 0.7949 - val_loss: 0.6876 - val_accuracy: 0.7544\n",
            "— val_f1: 0.7378066588785046\n",
            "Epoch 7/10\n",
            "91/91 [==============================] - 1s 13ms/step - loss: 0.5443 - accuracy: 0.8284 - val_loss: 0.7169 - val_accuracy: 0.7524\n",
            "— val_f1: 0.7351671490358038\n",
            "Epoch 8/10\n",
            "91/91 [==============================] - 1s 12ms/step - loss: 0.4872 - accuracy: 0.8644 - val_loss: 0.7609 - val_accuracy: 0.7437\n",
            "— val_f1: 0.7198743868573357\n",
            "Epoch 9/10\n",
            "91/91 [==============================] - 1s 12ms/step - loss: 0.4325 - accuracy: 0.8882 - val_loss: 0.7101 - val_accuracy: 0.7554\n",
            "— val_f1: 0.7389834253471677\n",
            "Epoch 10/10\n",
            "91/91 [==============================] - 1s 12ms/step - loss: 0.3806 - accuracy: 0.9140 - val_loss: 0.7881 - val_accuracy: 0.7456\n",
            "— val_f1: 0.7285843586279313\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.7881 - accuracy: 0.7456\n",
            "[[0]\n",
            " [1]\n",
            " [0]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]]\n",
            "1263\n",
            "f1_score test: 0.6926328835722637\n",
            "--- Starting trial: run-1\n",
            "{'num_units': 64, 'dropout': 0.7, 'optimizer': 'nadam'}\n",
            "Model: \"model_35\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "text (InputLayer)               [(None, 64, 128)]    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_35 (Bidirectional (None, 128)          98816       text[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "other (InputLayer)              [(None, 6)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_35 (Concatenate)    (None, 134)          0           bidirectional_35[0][0]           \n",
            "                                                                 other[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_105 (Dense)               (None, 256)          34560       concatenate_35[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dense_106 (Dense)               (None, 64)           16448       dense_105[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_107 (Dense)               (None, 1)            65          dense_106[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 149,889\n",
            "Trainable params: 149,889\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/10\n",
            "91/91 [==============================] - 6s 19ms/step - loss: 2.3443 - accuracy: 0.5570 - val_loss: 1.1579 - val_accuracy: 0.6140\n",
            "— val_f1: 0.6119056261343013\n",
            "Epoch 2/10\n",
            "91/91 [==============================] - 1s 12ms/step - loss: 1.0896 - accuracy: 0.6162 - val_loss: 0.9750 - val_accuracy: 0.6676\n",
            "— val_f1: 0.6659502533544279\n",
            "Epoch 3/10\n",
            "91/91 [==============================] - 1s 12ms/step - loss: 0.9343 - accuracy: 0.6385 - val_loss: 0.7992 - val_accuracy: 0.7018\n",
            "— val_f1: 0.6777545582565925\n",
            "Epoch 4/10\n",
            "91/91 [==============================] - 1s 12ms/step - loss: 0.8356 - accuracy: 0.6610 - val_loss: 0.8194 - val_accuracy: 0.7076\n",
            "— val_f1: 0.7010408208459438\n",
            "Epoch 5/10\n",
            "91/91 [==============================] - 1s 12ms/step - loss: 0.7820 - accuracy: 0.6797 - val_loss: 0.8081 - val_accuracy: 0.6930\n",
            "— val_f1: 0.6279334818422008\n",
            "Epoch 6/10\n",
            "91/91 [==============================] - 1s 12ms/step - loss: 0.7616 - accuracy: 0.6822 - val_loss: 0.8062 - val_accuracy: 0.7018\n",
            "— val_f1: 0.6588102327805428\n",
            "Epoch 7/10\n",
            "91/91 [==============================] - 1s 12ms/step - loss: 0.7717 - accuracy: 0.6688 - val_loss: 0.7017 - val_accuracy: 0.7329\n",
            "— val_f1: 0.7198263490241102\n",
            "Epoch 8/10\n",
            "91/91 [==============================] - 1s 12ms/step - loss: 0.7079 - accuracy: 0.7031 - val_loss: 0.7114 - val_accuracy: 0.7310\n",
            "— val_f1: 0.7199216663699484\n",
            "Epoch 9/10\n",
            "91/91 [==============================] - 1s 12ms/step - loss: 0.7145 - accuracy: 0.7073 - val_loss: 0.6966 - val_accuracy: 0.7251\n",
            "— val_f1: 0.7171984533160263\n",
            "Epoch 10/10\n",
            "91/91 [==============================] - 1s 12ms/step - loss: 0.6810 - accuracy: 0.7147 - val_loss: 0.6737 - val_accuracy: 0.7446\n",
            "— val_f1: 0.7339127336078556\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.6737 - accuracy: 0.7446\n",
            "[[0]\n",
            " [1]\n",
            " [0]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]]\n",
            "1263\n",
            "f1_score test: 0.683258182186645\n",
            "--- Starting trial: run-2\n",
            "{'num_units': 128, 'dropout': 0.0, 'optimizer': 'nadam'}\n",
            "Model: \"model_36\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "text (InputLayer)               [(None, 64, 128)]    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_36 (Bidirectional (None, 256)          263168      text[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "other (InputLayer)              [(None, 6)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_36 (Concatenate)    (None, 262)          0           bidirectional_36[0][0]           \n",
            "                                                                 other[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_108 (Dense)               (None, 256)          67328       concatenate_36[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dense_109 (Dense)               (None, 64)           16448       dense_108[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_110 (Dense)               (None, 1)            65          dense_109[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 347,009\n",
            "Trainable params: 347,009\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/10\n",
            "91/91 [==============================] - 5s 20ms/step - loss: 2.6471 - accuracy: 0.5718 - val_loss: 1.0319 - val_accuracy: 0.7057\n",
            "— val_f1: 0.70223030321668\n",
            "Epoch 2/10\n",
            "91/91 [==============================] - 1s 14ms/step - loss: 1.0770 - accuracy: 0.6811 - val_loss: 1.0122 - val_accuracy: 0.6404\n",
            "— val_f1: 0.4945846544071021\n",
            "Epoch 3/10\n",
            "91/91 [==============================] - 1s 13ms/step - loss: 0.8338 - accuracy: 0.7114 - val_loss: 0.7117 - val_accuracy: 0.7466\n",
            "— val_f1: 0.7286211316608681\n",
            "Epoch 4/10\n",
            "91/91 [==============================] - 1s 13ms/step - loss: 0.7160 - accuracy: 0.7625 - val_loss: 0.8531 - val_accuracy: 0.7086\n",
            "— val_f1: 0.7084548603686439\n",
            "Epoch 5/10\n",
            "91/91 [==============================] - 1s 14ms/step - loss: 0.6411 - accuracy: 0.7891 - val_loss: 0.7132 - val_accuracy: 0.7583\n",
            "— val_f1: 0.7288583509513743\n",
            "Epoch 6/10\n",
            "91/91 [==============================] - 1s 13ms/step - loss: 0.5602 - accuracy: 0.8364 - val_loss: 0.8990 - val_accuracy: 0.6832\n",
            "— val_f1: 0.5861193272158348\n",
            "Epoch 7/10\n",
            "91/91 [==============================] - 1s 13ms/step - loss: 0.4728 - accuracy: 0.8707 - val_loss: 0.7066 - val_accuracy: 0.7456\n",
            "— val_f1: 0.7395146236431533\n",
            "Epoch 8/10\n",
            "91/91 [==============================] - 1s 13ms/step - loss: 0.3830 - accuracy: 0.9136 - val_loss: 0.8402 - val_accuracy: 0.7310\n",
            "— val_f1: 0.7284141957808562\n",
            "Epoch 9/10\n",
            "91/91 [==============================] - 1s 14ms/step - loss: 0.3205 - accuracy: 0.9410 - val_loss: 0.8517 - val_accuracy: 0.7456\n",
            "— val_f1: 0.7320304408519835\n",
            "Epoch 10/10\n",
            "91/91 [==============================] - 1s 13ms/step - loss: 0.2572 - accuracy: 0.9686 - val_loss: 0.9120 - val_accuracy: 0.7398\n",
            "— val_f1: 0.7330278421256262\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.9120 - accuracy: 0.7398\n",
            "[[0]\n",
            " [1]\n",
            " [0]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]]\n",
            "1263\n",
            "f1_score test: 0.6784026858718237\n",
            "--- Starting trial: run-3\n",
            "{'num_units': 128, 'dropout': 0.7, 'optimizer': 'nadam'}\n",
            "Model: \"model_37\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "text (InputLayer)               [(None, 64, 128)]    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_37 (Bidirectional (None, 256)          263168      text[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "other (InputLayer)              [(None, 6)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_37 (Concatenate)    (None, 262)          0           bidirectional_37[0][0]           \n",
            "                                                                 other[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_111 (Dense)               (None, 256)          67328       concatenate_37[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dense_112 (Dense)               (None, 64)           16448       dense_111[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_113 (Dense)               (None, 1)            65          dense_112[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 347,009\n",
            "Trainable params: 347,009\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/10\n",
            "91/91 [==============================] - 5s 21ms/step - loss: 2.8945 - accuracy: 0.5297 - val_loss: 1.2198 - val_accuracy: 0.6559\n",
            "— val_f1: 0.6559372479577752\n",
            "Epoch 2/10\n",
            "91/91 [==============================] - 1s 13ms/step - loss: 1.2207 - accuracy: 0.6072 - val_loss: 0.8832 - val_accuracy: 0.6901\n",
            "— val_f1: 0.6851582372535926\n",
            "Epoch 3/10\n",
            "91/91 [==============================] - 1s 13ms/step - loss: 0.9291 - accuracy: 0.6562 - val_loss: 1.0722 - val_accuracy: 0.6501\n",
            "— val_f1: 0.6494817891051523\n",
            "Epoch 4/10\n",
            "91/91 [==============================] - 1s 14ms/step - loss: 0.9228 - accuracy: 0.6510 - val_loss: 0.8097 - val_accuracy: 0.7203\n",
            "— val_f1: 0.7058753609609777\n",
            "Epoch 5/10\n",
            "91/91 [==============================] - 1s 13ms/step - loss: 0.8164 - accuracy: 0.7034 - val_loss: 0.8998 - val_accuracy: 0.6881\n",
            "— val_f1: 0.687842278203724\n",
            "Epoch 6/10\n",
            "91/91 [==============================] - 1s 13ms/step - loss: 0.8716 - accuracy: 0.6732 - val_loss: 0.7224 - val_accuracy: 0.7388\n",
            "— val_f1: 0.7271417400658111\n",
            "Epoch 7/10\n",
            "91/91 [==============================] - 1s 14ms/step - loss: 0.7942 - accuracy: 0.6861 - val_loss: 0.7362 - val_accuracy: 0.7320\n",
            "— val_f1: 0.7275268827588205\n",
            "Epoch 8/10\n",
            "91/91 [==============================] - 1s 13ms/step - loss: 0.7726 - accuracy: 0.7120 - val_loss: 0.7064 - val_accuracy: 0.7398\n",
            "— val_f1: 0.7340046122102196\n",
            "Epoch 9/10\n",
            "91/91 [==============================] - 1s 13ms/step - loss: 0.7140 - accuracy: 0.7265 - val_loss: 0.7201 - val_accuracy: 0.7271\n",
            "— val_f1: 0.7222147015026399\n",
            "Epoch 10/10\n",
            "91/91 [==============================] - 1s 14ms/step - loss: 0.7218 - accuracy: 0.7142 - val_loss: 0.8515 - val_accuracy: 0.6676\n",
            "— val_f1: 0.667375586475065\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.8515 - accuracy: 0.6676\n",
            "[[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]]\n",
            "1263\n",
            "f1_score test: 0.5498144786793631\n",
            "--- Starting trial: run-4\n",
            "{'num_units': 256, 'dropout': 0.0, 'optimizer': 'nadam'}\n",
            "Model: \"model_38\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "text (InputLayer)               [(None, 64, 128)]    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_38 (Bidirectional (None, 512)          788480      text[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "other (InputLayer)              [(None, 6)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_38 (Concatenate)    (None, 518)          0           bidirectional_38[0][0]           \n",
            "                                                                 other[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_114 (Dense)               (None, 256)          132864      concatenate_38[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dense_115 (Dense)               (None, 64)           16448       dense_114[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_116 (Dense)               (None, 1)            65          dense_115[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 937,857\n",
            "Trainable params: 937,857\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/10\n",
            "91/91 [==============================] - 5s 26ms/step - loss: 3.1998 - accuracy: 0.5826 - val_loss: 1.6209 - val_accuracy: 0.5448\n",
            "— val_f1: 0.5191784904672019\n",
            "Epoch 2/10\n",
            "91/91 [==============================] - 2s 19ms/step - loss: 1.1310 - accuracy: 0.6565 - val_loss: 0.9385 - val_accuracy: 0.6520\n",
            "— val_f1: 0.5194127178854695\n",
            "Epoch 3/10\n",
            "91/91 [==============================] - 2s 19ms/step - loss: 0.8427 - accuracy: 0.7363 - val_loss: 0.8812 - val_accuracy: 0.6745\n",
            "— val_f1: 0.6740626605033384\n",
            "Epoch 4/10\n",
            "91/91 [==============================] - 2s 19ms/step - loss: 0.6833 - accuracy: 0.7805 - val_loss: 0.7118 - val_accuracy: 0.7446\n",
            "— val_f1: 0.7355711722488038\n",
            "Epoch 5/10\n",
            "91/91 [==============================] - 2s 19ms/step - loss: 0.6069 - accuracy: 0.8109 - val_loss: 0.7419 - val_accuracy: 0.7437\n",
            "— val_f1: 0.7250442485991766\n",
            "Epoch 6/10\n",
            "91/91 [==============================] - 2s 19ms/step - loss: 0.4780 - accuracy: 0.8847 - val_loss: 0.8275 - val_accuracy: 0.7232\n",
            "— val_f1: 0.6813009410560302\n",
            "Epoch 7/10\n",
            "91/91 [==============================] - 2s 19ms/step - loss: 0.4216 - accuracy: 0.9186 - val_loss: 0.8347 - val_accuracy: 0.7310\n",
            "— val_f1: 0.726183062909745\n",
            "Epoch 8/10\n",
            "91/91 [==============================] - 2s 19ms/step - loss: 0.3131 - accuracy: 0.9613 - val_loss: 0.8755 - val_accuracy: 0.7222\n",
            "— val_f1: 0.7138988171823129\n",
            "Epoch 9/10\n",
            "91/91 [==============================] - 2s 19ms/step - loss: 0.2399 - accuracy: 0.9809 - val_loss: 1.0116 - val_accuracy: 0.7310\n",
            "— val_f1: 0.711609907120743\n",
            "Epoch 10/10\n",
            "91/91 [==============================] - 2s 19ms/step - loss: 0.2035 - accuracy: 0.9912 - val_loss: 1.0555 - val_accuracy: 0.7329\n",
            "— val_f1: 0.7252211922290468\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 1.0555 - accuracy: 0.7329\n",
            "[[0]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]]\n",
            "1263\n",
            "f1_score test: 0.6822143092440667\n",
            "--- Starting trial: run-5\n",
            "{'num_units': 256, 'dropout': 0.7, 'optimizer': 'nadam'}\n",
            "Model: \"model_39\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "text (InputLayer)               [(None, 64, 128)]    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_39 (Bidirectional (None, 512)          788480      text[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "other (InputLayer)              [(None, 6)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_39 (Concatenate)    (None, 518)          0           bidirectional_39[0][0]           \n",
            "                                                                 other[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_117 (Dense)               (None, 256)          132864      concatenate_39[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dense_118 (Dense)               (None, 64)           16448       dense_117[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_119 (Dense)               (None, 1)            65          dense_118[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 937,857\n",
            "Trainable params: 937,857\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/10\n",
            "91/91 [==============================] - 6s 38ms/step - loss: 2.9822 - accuracy: 0.5538 - val_loss: 1.0745 - val_accuracy: 0.6979\n",
            "— val_f1: 0.6543502358234258\n",
            "Epoch 2/10\n",
            "91/91 [==============================] - 2s 19ms/step - loss: 1.0727 - accuracy: 0.6411 - val_loss: 0.8393 - val_accuracy: 0.7037\n",
            "— val_f1: 0.6823529411764706\n",
            "Epoch 3/10\n",
            "91/91 [==============================] - 2s 19ms/step - loss: 0.8732 - accuracy: 0.6615 - val_loss: 0.7585 - val_accuracy: 0.7096\n",
            "— val_f1: 0.705386050383892\n",
            "Epoch 4/10\n",
            "91/91 [==============================] - 2s 19ms/step - loss: 0.7950 - accuracy: 0.6864 - val_loss: 0.9506 - val_accuracy: 0.6326\n",
            "— val_f1: 0.4774322982457326\n",
            "Epoch 5/10\n",
            "91/91 [==============================] - 2s 19ms/step - loss: 0.7961 - accuracy: 0.6775 - val_loss: 0.7488 - val_accuracy: 0.7290\n",
            "— val_f1: 0.699031339031339\n",
            "Epoch 6/10\n",
            "91/91 [==============================] - 2s 19ms/step - loss: 0.7267 - accuracy: 0.7223 - val_loss: 0.7818 - val_accuracy: 0.7105\n",
            "— val_f1: 0.7090534464699856\n",
            "Epoch 7/10\n",
            "91/91 [==============================] - 2s 19ms/step - loss: 0.7063 - accuracy: 0.7224 - val_loss: 0.7201 - val_accuracy: 0.7466\n",
            "— val_f1: 0.7211303649683871\n",
            "Epoch 8/10\n",
            "91/91 [==============================] - 2s 19ms/step - loss: 0.7179 - accuracy: 0.7131 - val_loss: 0.6991 - val_accuracy: 0.7398\n",
            "— val_f1: 0.7302198976391212\n",
            "Epoch 9/10\n",
            "91/91 [==============================] - 2s 19ms/step - loss: 0.6915 - accuracy: 0.7318 - val_loss: 0.8852 - val_accuracy: 0.6910\n",
            "— val_f1: 0.6909036479493649\n",
            "Epoch 10/10\n",
            "91/91 [==============================] - 2s 19ms/step - loss: 0.6913 - accuracy: 0.7222 - val_loss: 0.6798 - val_accuracy: 0.7446\n",
            "— val_f1: 0.7221328658317243\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.6798 - accuracy: 0.7446\n",
            "[[0]\n",
            " [1]\n",
            " [0]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]]\n",
            "1263\n",
            "f1_score test: 0.7179110240711484\n",
            "--- Starting trial: run-6\n",
            "{'num_units': 512, 'dropout': 0.0, 'optimizer': 'nadam'}\n",
            "Model: \"model_40\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "text (InputLayer)               [(None, 64, 128)]    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_40 (Bidirectional (None, 1024)         2625536     text[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "other (InputLayer)              [(None, 6)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_40 (Concatenate)    (None, 1030)         0           bidirectional_40[0][0]           \n",
            "                                                                 other[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_120 (Dense)               (None, 256)          263936      concatenate_40[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dense_121 (Dense)               (None, 64)           16448       dense_120[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_122 (Dense)               (None, 1)            65          dense_121[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 2,905,985\n",
            "Trainable params: 2,905,985\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/10\n",
            "91/91 [==============================] - 6s 39ms/step - loss: 3.1282 - accuracy: 0.5775 - val_loss: 0.9743 - val_accuracy: 0.7135\n",
            "— val_f1: 0.7083254365777718\n",
            "Epoch 2/10\n",
            "91/91 [==============================] - 3s 33ms/step - loss: 1.0100 - accuracy: 0.6813 - val_loss: 0.8416 - val_accuracy: 0.7008\n",
            "— val_f1: 0.7003467614195814\n",
            "Epoch 3/10\n",
            "91/91 [==============================] - 3s 33ms/step - loss: 0.7255 - accuracy: 0.7651 - val_loss: 0.7250 - val_accuracy: 0.7388\n",
            "— val_f1: 0.7355263157894737\n",
            "Epoch 4/10\n",
            "91/91 [==============================] - 3s 33ms/step - loss: 0.6505 - accuracy: 0.7858 - val_loss: 0.7260 - val_accuracy: 0.7427\n",
            "— val_f1: 0.7172054641203075\n",
            "Epoch 5/10\n",
            "91/91 [==============================] - 3s 33ms/step - loss: 0.5829 - accuracy: 0.8238 - val_loss: 0.9464 - val_accuracy: 0.6579\n",
            "— val_f1: 0.6573475611206523\n",
            "Epoch 6/10\n",
            "91/91 [==============================] - 3s 33ms/step - loss: 0.5064 - accuracy: 0.8588 - val_loss: 0.8056 - val_accuracy: 0.7495\n",
            "— val_f1: 0.7295111480404377\n",
            "Epoch 7/10\n",
            "91/91 [==============================] - 3s 33ms/step - loss: 0.4255 - accuracy: 0.9031 - val_loss: 0.8206 - val_accuracy: 0.7456\n",
            "— val_f1: 0.7330008465053488\n",
            "Epoch 8/10\n",
            "91/91 [==============================] - 3s 33ms/step - loss: 0.2799 - accuracy: 0.9654 - val_loss: 0.9545 - val_accuracy: 0.7261\n",
            "— val_f1: 0.7147323853634935\n",
            "Epoch 9/10\n",
            "91/91 [==============================] - 3s 33ms/step - loss: 0.2103 - accuracy: 0.9881 - val_loss: 1.0315 - val_accuracy: 0.7329\n",
            "— val_f1: 0.7221743461623604\n",
            "Epoch 10/10\n",
            "91/91 [==============================] - 3s 33ms/step - loss: 0.1831 - accuracy: 0.9924 - val_loss: 1.1508 - val_accuracy: 0.7115\n",
            "— val_f1: 0.6917029752019134\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 1.1508 - accuracy: 0.7115\n",
            "[[0]\n",
            " [1]\n",
            " [0]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]]\n",
            "1263\n",
            "f1_score test: 0.6895716292134833\n",
            "--- Starting trial: run-7\n",
            "{'num_units': 512, 'dropout': 0.7, 'optimizer': 'nadam'}\n",
            "Model: \"model_41\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "text (InputLayer)               [(None, 64, 128)]    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_41 (Bidirectional (None, 1024)         2625536     text[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "other (InputLayer)              [(None, 6)]          0                                            \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_41 (Concatenate)    (None, 1030)         0           bidirectional_41[0][0]           \n",
            "                                                                 other[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_123 (Dense)               (None, 256)          263936      concatenate_41[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dense_124 (Dense)               (None, 64)           16448       dense_123[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_125 (Dense)               (None, 1)            65          dense_124[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 2,905,985\n",
            "Trainable params: 2,905,985\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/10\n",
            "91/91 [==============================] - 6s 40ms/step - loss: 3.0344 - accuracy: 0.5944 - val_loss: 0.9889 - val_accuracy: 0.7193\n",
            "— val_f1: 0.696710172476793\n",
            "Epoch 2/10\n",
            "91/91 [==============================] - 3s 33ms/step - loss: 1.0377 - accuracy: 0.6383 - val_loss: 1.1272 - val_accuracy: 0.6150\n",
            "— val_f1: 0.40769656853646524\n",
            "Epoch 3/10\n",
            "91/91 [==============================] - 3s 33ms/step - loss: 0.8657 - accuracy: 0.6686 - val_loss: 0.7482 - val_accuracy: 0.7144\n",
            "— val_f1: 0.7105309022979928\n",
            "Epoch 4/10\n",
            "91/91 [==============================] - 3s 33ms/step - loss: 0.7974 - accuracy: 0.6861 - val_loss: 0.7192 - val_accuracy: 0.7417\n",
            "— val_f1: 0.7268960529553867\n",
            "Epoch 5/10\n",
            "91/91 [==============================] - 3s 33ms/step - loss: 0.7757 - accuracy: 0.6775 - val_loss: 0.6971 - val_accuracy: 0.7359\n",
            "— val_f1: 0.7316248968422882\n",
            "Epoch 6/10\n",
            "91/91 [==============================] - 3s 33ms/step - loss: 0.8340 - accuracy: 0.6903 - val_loss: 0.6961 - val_accuracy: 0.7203\n",
            "— val_f1: 0.7187701458668202\n",
            "Epoch 7/10\n",
            "91/91 [==============================] - 3s 33ms/step - loss: 0.7592 - accuracy: 0.6945 - val_loss: 0.8303 - val_accuracy: 0.6452\n",
            "— val_f1: 0.6434683988040004\n",
            "Epoch 8/10\n",
            "91/91 [==============================] - 3s 33ms/step - loss: 0.6970 - accuracy: 0.7195 - val_loss: 0.6537 - val_accuracy: 0.7505\n",
            "— val_f1: 0.7430985915492958\n",
            "Epoch 9/10\n",
            "91/91 [==============================] - 3s 33ms/step - loss: 0.6599 - accuracy: 0.7322 - val_loss: 0.7271 - val_accuracy: 0.6940\n",
            "— val_f1: 0.6939280394004803\n",
            "Epoch 10/10\n",
            "91/91 [==============================] - 3s 33ms/step - loss: 0.6410 - accuracy: 0.7399 - val_loss: 0.6338 - val_accuracy: 0.7446\n",
            "— val_f1: 0.7339127336078556\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.6338 - accuracy: 0.7446\n",
            "[[0]\n",
            " [1]\n",
            " [0]\n",
            " ...\n",
            " [1]\n",
            " [1]\n",
            " [1]]\n",
            "1263\n",
            "f1_score test: 0.7095800181945204\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUvnMoP9EsnU"
      },
      "source": [
        "### Test phase"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZVkUrF2luNH"
      },
      "source": [
        "csv_test_file = open(input_test_dir+\"test_dataset_tweet.csv\")\n",
        "\n",
        "testset = pd.read_csv(csv_test_file,sep=',')"
      ],
      "execution_count": 171,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEA-Q8phFM71",
        "outputId": "9b681a70-dbc4-4b4b-96f6-212a6b6c8e20",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "X_test = get_data_to_emb2(testset[\"tokens\"], w2v, max_length , True)"
      ],
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1263\n",
            "[[-0.40181148  1.30801952 -0.19409141 ...  0.49553871 -0.02620392\n",
            "   1.63770258]\n",
            " [ 1.86031258  0.98840606 -2.10821915 ...  1.14880133  0.14479998\n",
            "  -0.10640591]\n",
            " [-1.32805312  0.75008422  0.24781393 ... -0.08247134 -0.89805609\n",
            "  -0.75278544]\n",
            " ...\n",
            " [ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]\n",
            " [ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]\n",
            " [ 0.          0.          0.         ...  0.          0.\n",
            "   0.        ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gIXr4PJLF36A",
        "outputId": "4a10acf6-031a-42a2-b948-d55378ed843f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "source": [
        "testset_other = testset\n",
        "testset_other = testset.drop(['text', 'id', 'hs', 'stereotype','tokens', 'hashtags'], axis=1)\n",
        "testset_other"
      ],
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text_length</th>\n",
              "      <th>#C-L words</th>\n",
              "      <th>#?!</th>\n",
              "      <th>#.,</th>\n",
              "      <th>#bad_words</th>\n",
              "      <th>%bad_words</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>180</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>227</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>259</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>99</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>257</td>\n",
              "      <td>87</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1258</th>\n",
              "      <td>216</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1259</th>\n",
              "      <td>159</td>\n",
              "      <td>81</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1260</th>\n",
              "      <td>278</td>\n",
              "      <td>32</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1261</th>\n",
              "      <td>128</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1262</th>\n",
              "      <td>284</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1263 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      text_length  #C-L words  #?!  #.,  #bad_words  %bad_words\n",
              "0             180           4    1    4           0           0\n",
              "1             227           5    4    5           0           0\n",
              "2             259           2    2    4           1           2\n",
              "3              99           7    0    2           0           0\n",
              "4             257          87    2    0           0           0\n",
              "...           ...         ...  ...  ...         ...         ...\n",
              "1258          216           0    0    5           0           0\n",
              "1259          159          81    3    1           1           3\n",
              "1260          278          32    4    7           0           0\n",
              "1261          128           0    1    3           0           0\n",
              "1262          284           2    2    9           0           0\n",
              "\n",
              "[1263 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 173
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vhoi6YkbGJyj",
        "outputId": "893b9c22-57ee-4d2d-8207-2d164f9d89b1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "input_test   = {\"text\": X_test, \"other\": testset_other.values}\n",
        "y_test = testset[['hs']]\n",
        "print(y_test)"
      ],
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      hs\n",
            "0      1\n",
            "1      1\n",
            "2      1\n",
            "3      1\n",
            "4      1\n",
            "...   ..\n",
            "1258   1\n",
            "1259   1\n",
            "1260   1\n",
            "1261   1\n",
            "1262   1\n",
            "\n",
            "[1263 rows x 1 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDvQQtPxGc0P",
        "outputId": "8fa5f266-e86c-4be5-caf1-cd5131c20f08",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "source": [
        "y_test_pred = np.where(model.predict(input_test)[0] > 0.5, 1, 0)"
      ],
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-175-2a6380d85251>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_test_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4joT-vrHqjz"
      },
      "source": [
        ""
      ],
      "execution_count": 175,
      "outputs": []
    }
  ]
}